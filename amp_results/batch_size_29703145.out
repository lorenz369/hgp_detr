| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=8, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Using mixed precision training
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [  0/248]  eta: 0:19:30  lr: 0.000100  class_error: 89.47  loss: 50.0728 (50.0728)  loss_ce: 2.5862 (2.5862)  loss_bbox: 3.1493 (3.1493)  loss_giou: 1.7414 (1.7414)  loss_ce_0: 3.9906 (3.9906)  loss_bbox_0: 3.5894 (3.5894)  loss_giou_0: 1.7501 (1.7501)  loss_ce_1: 3.8464 (3.8464)  loss_bbox_1: 3.4007 (3.4007)  loss_giou_1: 1.7302 (1.7302)  loss_ce_2: 3.6082 (3.6082)  loss_bbox_2: 3.3612 (3.3612)  loss_giou_2: 1.7312 (1.7312)  loss_ce_3: 2.6245 (2.6245)  loss_bbox_3: 3.4180 (3.4180)  loss_giou_3: 1.7372 (1.7372)  loss_ce_4: 2.7863 (2.7863)  loss_bbox_4: 3.2894 (3.2894)  loss_giou_4: 1.7325 (1.7325)  loss_ce_unscaled: 2.5862 (2.5862)  class_error_unscaled: 89.4737 (89.4737)  loss_bbox_unscaled: 0.6299 (0.6299)  loss_giou_unscaled: 0.8707 (0.8707)  cardinality_error_unscaled: 76.0000 (76.0000)  loss_ce_0_unscaled: 3.9906 (3.9906)  loss_bbox_0_unscaled: 0.7179 (0.7179)  loss_giou_0_unscaled: 0.8750 (0.8750)  cardinality_error_0_unscaled: 97.6250 (97.6250)  loss_ce_1_unscaled: 3.8464 (3.8464)  loss_bbox_1_unscaled: 0.6801 (0.6801)  loss_giou_1_unscaled: 0.8651 (0.8651)  cardinality_error_1_unscaled: 97.6250 (97.6250)  loss_ce_2_unscaled: 3.6082 (3.6082)  loss_bbox_2_unscaled: 0.6722 (0.6722)  loss_giou_2_unscaled: 0.8656 (0.8656)  cardinality_error_2_unscaled: 97.6250 (97.6250)  loss_ce_3_unscaled: 2.6245 (2.6245)  loss_bbox_3_unscaled: 0.6836 (0.6836)  loss_giou_3_unscaled: 0.8686 (0.8686)  cardinality_error_3_unscaled: 70.0000 (70.0000)  loss_ce_4_unscaled: 2.7863 (2.7863)  loss_bbox_4_unscaled: 0.6579 (0.6579)  loss_giou_4_unscaled: 0.8663 (0.8663)  cardinality_error_4_unscaled: 92.6250 (92.6250)  time: 4.7211  data: 1.5468  max mem: 7010
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 10/248]  eta: 0:02:49  lr: 0.000100  class_error: 100.00  loss: 50.2433 (50.5447)  loss_ce: 2.5862 (2.4561)  loss_bbox: 3.4748 (3.5208)  loss_giou: 1.8897 (1.8588)  loss_ce_0: 3.9441 (3.6132)  loss_bbox_0: 3.8539 (3.7812)  loss_giou_0: 1.8465 (1.8174)  loss_ce_1: 3.8652 (3.4920)  loss_bbox_1: 3.6878 (3.6644)  loss_giou_1: 1.8513 (1.8267)  loss_ce_2: 3.6082 (3.2108)  loss_bbox_2: 3.6315 (3.6424)  loss_giou_2: 1.8554 (1.8223)  loss_ce_3: 2.6198 (2.3491)  loss_bbox_3: 3.6920 (3.6960)  loss_giou_3: 1.8681 (1.8327)  loss_ce_4: 2.7863 (2.5485)  loss_bbox_4: 3.5356 (3.5768)  loss_giou_4: 1.8788 (1.8357)  loss_ce_unscaled: 2.5862 (2.4561)  class_error_unscaled: 94.1176 (93.3128)  loss_bbox_unscaled: 0.6950 (0.7042)  loss_giou_unscaled: 0.9449 (0.9294)  cardinality_error_unscaled: 76.0000 (64.1136)  loss_ce_0_unscaled: 3.9441 (3.6132)  loss_bbox_0_unscaled: 0.7708 (0.7562)  loss_giou_0_unscaled: 0.9233 (0.9087)  cardinality_error_0_unscaled: 97.6250 (83.6023)  loss_ce_1_unscaled: 3.8652 (3.4920)  loss_bbox_1_unscaled: 0.7376 (0.7329)  loss_giou_1_unscaled: 0.9256 (0.9133)  cardinality_error_1_unscaled: 97.6250 (80.4773)  loss_ce_2_unscaled: 3.6082 (3.2108)  loss_bbox_2_unscaled: 0.7263 (0.7285)  loss_giou_2_unscaled: 0.9277 (0.9112)  cardinality_error_2_unscaled: 97.6250 (80.4091)  loss_ce_3_unscaled: 2.6198 (2.3491)  loss_bbox_3_unscaled: 0.7384 (0.7392)  loss_giou_3_unscaled: 0.9341 (0.9163)  cardinality_error_3_unscaled: 73.8750 (63.7273)  loss_ce_4_unscaled: 2.7863 (2.5485)  loss_bbox_4_unscaled: 0.7071 (0.7154)  loss_giou_4_unscaled: 0.9394 (0.9178)  cardinality_error_4_unscaled: 92.7500 (77.0568)  time: 0.7136  data: 0.1666  max mem: 10800
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 20/248]  eta: 0:01:55  lr: 0.000100  class_error: 100.00  loss: 41.0039 (44.1635)  loss_ce: 1.0912 (1.6950)  loss_bbox: 3.4371 (3.4344)  loss_giou: 1.9402 (1.9259)  loss_ce_0: 1.1399 (2.2859)  loss_bbox_0: 3.5990 (3.6020)  loss_giou_0: 1.8699 (1.8963)  loss_ce_1: 1.0041 (2.2200)  loss_bbox_1: 3.5099 (3.5248)  loss_giou_1: 1.9044 (1.9171)  loss_ce_2: 0.9715 (2.0663)  loss_bbox_2: 3.5752 (3.5234)  loss_giou_2: 1.8888 (1.8983)  loss_ce_3: 0.9669 (1.6196)  loss_bbox_3: 3.6024 (3.5492)  loss_giou_3: 1.8904 (1.8996)  loss_ce_4: 0.9768 (1.7248)  loss_bbox_4: 3.4943 (3.4703)  loss_giou_4: 1.9094 (1.9106)  loss_ce_unscaled: 1.0912 (1.6950)  class_error_unscaled: 100.0000 (96.4972)  loss_bbox_unscaled: 0.6874 (0.6869)  loss_giou_unscaled: 0.9701 (0.9630)  cardinality_error_unscaled: 2.5000 (34.6726)  loss_ce_0_unscaled: 1.1399 (2.2859)  loss_bbox_0_unscaled: 0.7198 (0.7204)  loss_giou_0_unscaled: 0.9350 (0.9482)  cardinality_error_0_unscaled: 2.7500 (44.8810)  loss_ce_1_unscaled: 1.0041 (2.2200)  loss_bbox_1_unscaled: 0.7020 (0.7050)  loss_giou_1_unscaled: 0.9522 (0.9586)  cardinality_error_1_unscaled: 2.7500 (43.2440)  loss_ce_2_unscaled: 0.9715 (2.0663)  loss_bbox_2_unscaled: 0.7150 (0.7047)  loss_giou_2_unscaled: 0.9444 (0.9491)  cardinality_error_2_unscaled: 2.5000 (43.2083)  loss_ce_3_unscaled: 0.9669 (1.6196)  loss_bbox_3_unscaled: 0.7205 (0.7098)  loss_giou_3_unscaled: 0.9452 (0.9498)  cardinality_error_3_unscaled: 2.5000 (34.4702)  loss_ce_4_unscaled: 0.9768 (1.7248)  loss_bbox_4_unscaled: 0.6989 (0.6941)  loss_giou_4_unscaled: 0.9547 (0.9553)  cardinality_error_4_unscaled: 2.5000 (41.4524)  time: 0.2966  data: 0.0306  max mem: 10800
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 30/248]  eta: 0:01:35  lr: 0.000100  class_error: 100.00  loss: 36.6123 (41.1419)  loss_ce: 0.7882 (1.3868)  loss_bbox: 3.2098 (3.2971)  loss_giou: 2.0242 (1.9678)  loss_ce_0: 0.7554 (1.7870)  loss_bbox_0: 3.1743 (3.4093)  loss_giou_0: 2.0369 (1.9517)  loss_ce_1: 0.7598 (1.7458)  loss_bbox_1: 3.1427 (3.3457)  loss_giou_1: 2.0485 (1.9681)  loss_ce_2: 0.7568 (1.6375)  loss_bbox_2: 3.1891 (3.3528)  loss_giou_2: 2.0113 (1.9464)  loss_ce_3: 0.7650 (1.3363)  loss_bbox_3: 3.2187 (3.3749)  loss_giou_3: 2.0223 (1.9507)  loss_ce_4: 0.7675 (1.4089)  loss_bbox_4: 3.1789 (3.3155)  loss_giou_4: 2.0297 (1.9594)  loss_ce_unscaled: 0.7882 (1.3868)  class_error_unscaled: 100.0000 (97.6271)  loss_bbox_unscaled: 0.6420 (0.6594)  loss_giou_unscaled: 1.0121 (0.9839)  cardinality_error_unscaled: 2.2500 (24.1976)  loss_ce_0_unscaled: 0.7554 (1.7870)  loss_bbox_0_unscaled: 0.6349 (0.6819)  loss_giou_0_unscaled: 1.0184 (0.9759)  cardinality_error_0_unscaled: 2.2500 (31.1129)  loss_ce_1_unscaled: 0.7598 (1.7458)  loss_bbox_1_unscaled: 0.6285 (0.6691)  loss_giou_1_unscaled: 1.0243 (0.9840)  cardinality_error_1_unscaled: 2.2500 (30.0040)  loss_ce_2_unscaled: 0.7568 (1.6375)  loss_bbox_2_unscaled: 0.6378 (0.6706)  loss_giou_2_unscaled: 1.0056 (0.9732)  cardinality_error_2_unscaled: 2.2500 (29.9798)  loss_ce_3_unscaled: 0.7650 (1.3363)  loss_bbox_3_unscaled: 0.6437 (0.6750)  loss_giou_3_unscaled: 1.0111 (0.9754)  cardinality_error_3_unscaled: 2.2500 (24.0605)  loss_ce_4_unscaled: 0.7675 (1.4089)  loss_bbox_4_unscaled: 0.6358 (0.6631)  loss_giou_4_unscaled: 1.0149 (0.9797)  cardinality_error_4_unscaled: 2.2500 (28.7903)  time: 0.2839  data: 0.0322  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 40/248]  eta: 0:01:22  lr: 0.000100  class_error: 100.00  loss: 35.4563 (39.7737)  loss_ce: 0.7219 (1.2246)  loss_bbox: 3.0070 (3.2264)  loss_giou: 2.1413 (2.0227)  loss_ce_0: 0.7234 (1.5262)  loss_bbox_0: 3.0280 (3.3158)  loss_giou_0: 2.1526 (2.0077)  loss_ce_1: 0.7326 (1.4957)  loss_bbox_1: 3.0312 (3.2625)  loss_giou_1: 2.1394 (2.0234)  loss_ce_2: 0.7328 (1.4159)  loss_bbox_2: 2.9970 (3.2663)  loss_giou_2: 2.1315 (2.0050)  loss_ce_3: 0.7286 (1.1883)  loss_bbox_3: 3.0401 (3.2882)  loss_giou_3: 2.1342 (2.0081)  loss_ce_4: 0.7305 (1.2411)  loss_bbox_4: 2.9916 (3.2390)  loss_giou_4: 2.1346 (2.0169)  loss_ce_unscaled: 0.7219 (1.2246)  class_error_unscaled: 100.0000 (98.2059)  loss_bbox_unscaled: 0.6014 (0.6453)  loss_giou_unscaled: 1.0706 (1.0114)  cardinality_error_unscaled: 2.2500 (18.8506)  loss_ce_0_unscaled: 0.7234 (1.5262)  loss_bbox_0_unscaled: 0.6056 (0.6632)  loss_giou_0_unscaled: 1.0763 (1.0038)  cardinality_error_0_unscaled: 2.2500 (24.0793)  loss_ce_1_unscaled: 0.7326 (1.4957)  loss_bbox_1_unscaled: 0.6062 (0.6525)  loss_giou_1_unscaled: 1.0697 (1.0117)  cardinality_error_1_unscaled: 2.2500 (23.2409)  loss_ce_2_unscaled: 0.7328 (1.4159)  loss_bbox_2_unscaled: 0.5994 (0.6533)  loss_giou_2_unscaled: 1.0657 (1.0025)  cardinality_error_2_unscaled: 2.2500 (23.2226)  loss_ce_3_unscaled: 0.7286 (1.1883)  loss_bbox_3_unscaled: 0.6080 (0.6576)  loss_giou_3_unscaled: 1.0671 (1.0041)  cardinality_error_3_unscaled: 2.2500 (18.7470)  loss_ce_4_unscaled: 0.7305 (1.2411)  loss_bbox_4_unscaled: 0.5983 (0.6478)  loss_giou_4_unscaled: 1.0673 (1.0084)  cardinality_error_4_unscaled: 2.2500 (22.3232)  time: 0.2824  data: 0.0304  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 50/248]  eta: 0:01:14  lr: 0.000100  class_error: 100.00  loss: 34.8179 (38.4856)  loss_ce: 0.7311 (1.1363)  loss_bbox: 2.8039 (3.1075)  loss_giou: 2.2159 (2.0452)  loss_ce_0: 0.7137 (1.3681)  loss_bbox_0: 2.8712 (3.1853)  loss_giou_0: 2.2013 (2.0324)  loss_ce_1: 0.7326 (1.3482)  loss_bbox_1: 2.7951 (3.1389)  loss_giou_1: 2.1857 (2.0451)  loss_ce_2: 0.7455 (1.2887)  loss_bbox_2: 2.7938 (3.1448)  loss_giou_2: 2.1880 (2.0299)  loss_ce_3: 0.7316 (1.1060)  loss_bbox_3: 2.8094 (3.1620)  loss_giou_3: 2.2022 (2.0342)  loss_ce_4: 0.7344 (1.1510)  loss_bbox_4: 2.8085 (3.1188)  loss_giou_4: 2.2153 (2.0433)  loss_ce_unscaled: 0.7311 (1.1363)  class_error_unscaled: 100.0000 (98.5577)  loss_bbox_unscaled: 0.5608 (0.6215)  loss_giou_unscaled: 1.1080 (1.0226)  cardinality_error_unscaled: 2.2500 (15.6005)  loss_ce_0_unscaled: 0.7137 (1.3681)  loss_bbox_0_unscaled: 0.5742 (0.6371)  loss_giou_0_unscaled: 1.1007 (1.0162)  cardinality_error_0_unscaled: 2.2500 (19.8039)  loss_ce_1_unscaled: 0.7326 (1.3482)  loss_bbox_1_unscaled: 0.5590 (0.6278)  loss_giou_1_unscaled: 1.0929 (1.0226)  cardinality_error_1_unscaled: 2.2500 (19.1299)  loss_ce_2_unscaled: 0.7455 (1.2887)  loss_bbox_2_unscaled: 0.5588 (0.6290)  loss_giou_2_unscaled: 1.0940 (1.0149)  cardinality_error_2_unscaled: 2.2500 (19.1152)  loss_ce_3_unscaled: 0.7316 (1.1060)  loss_bbox_3_unscaled: 0.5619 (0.6324)  loss_giou_3_unscaled: 1.1011 (1.0171)  cardinality_error_3_unscaled: 2.2500 (15.5172)  loss_ce_4_unscaled: 0.7344 (1.1510)  loss_bbox_4_unscaled: 0.5617 (0.6238)  loss_giou_4_unscaled: 1.1076 (1.0216)  cardinality_error_4_unscaled: 2.2500 (18.3922)  time: 0.2779  data: 0.0293  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 60/248]  eta: 0:01:07  lr: 0.000100  class_error: 100.00  loss: 32.6157 (37.5178)  loss_ce: 0.7432 (1.0714)  loss_bbox: 2.5577 (3.0136)  loss_giou: 2.2081 (2.0589)  loss_ce_0: 0.7178 (1.2628)  loss_bbox_0: 2.6007 (3.0815)  loss_giou_0: 2.1846 (2.0484)  loss_ce_1: 0.7293 (1.2463)  loss_bbox_1: 2.5836 (3.0440)  loss_giou_1: 2.1857 (2.0603)  loss_ce_2: 0.7367 (1.1968)  loss_bbox_2: 2.6259 (3.0493)  loss_giou_2: 2.1880 (2.0445)  loss_ce_3: 0.7422 (1.0444)  loss_bbox_3: 2.6110 (3.0655)  loss_giou_3: 2.2022 (2.0530)  loss_ce_4: 0.7470 (1.0847)  loss_bbox_4: 2.6014 (3.0296)  loss_giou_4: 2.2172 (2.0629)  loss_ce_unscaled: 0.7432 (1.0714)  class_error_unscaled: 100.0000 (98.7941)  loss_bbox_unscaled: 0.5115 (0.6027)  loss_giou_unscaled: 1.1040 (1.0295)  cardinality_error_unscaled: 2.2500 (13.4221)  loss_ce_0_unscaled: 0.7178 (1.2628)  loss_bbox_0_unscaled: 0.5201 (0.6163)  loss_giou_0_unscaled: 1.0923 (1.0242)  cardinality_error_0_unscaled: 2.2500 (16.9365)  loss_ce_1_unscaled: 0.7293 (1.2463)  loss_bbox_1_unscaled: 0.5167 (0.6088)  loss_giou_1_unscaled: 1.0929 (1.0301)  cardinality_error_1_unscaled: 2.2500 (16.3730)  loss_ce_2_unscaled: 0.7367 (1.1968)  loss_bbox_2_unscaled: 0.5252 (0.6099)  loss_giou_2_unscaled: 1.0940 (1.0222)  cardinality_error_2_unscaled: 2.2500 (16.3607)  loss_ce_3_unscaled: 0.7422 (1.0444)  loss_bbox_3_unscaled: 0.5222 (0.6131)  loss_giou_3_unscaled: 1.1011 (1.0265)  cardinality_error_3_unscaled: 2.2500 (13.3525)  loss_ce_4_unscaled: 0.7470 (1.0847)  loss_bbox_4_unscaled: 0.5203 (0.6059)  loss_giou_4_unscaled: 1.1086 (1.0315)  cardinality_error_4_unscaled: 2.2500 (15.7561)  time: 0.2789  data: 0.0300  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 70/248]  eta: 0:01:01  lr: 0.000100  class_error: 100.00  loss: 31.9843 (36.7449)  loss_ce: 0.7137 (1.0178)  loss_bbox: 2.5515 (2.9716)  loss_giou: 2.0136 (2.0430)  loss_ce_0: 0.6949 (1.1806)  loss_bbox_0: 2.5840 (3.0281)  loss_giou_0: 2.0023 (2.0329)  loss_ce_1: 0.6955 (1.1662)  loss_bbox_1: 2.5773 (2.9922)  loss_giou_1: 1.9984 (2.0467)  loss_ce_2: 0.7019 (1.1249)  loss_bbox_2: 2.5927 (3.0011)  loss_giou_2: 1.9733 (2.0322)  loss_ce_3: 0.6908 (0.9939)  loss_bbox_3: 2.5669 (3.0132)  loss_giou_3: 2.0410 (2.0402)  loss_ce_4: 0.7113 (1.0284)  loss_bbox_4: 2.6013 (2.9855)  loss_giou_4: 2.0366 (2.0463)  loss_ce_unscaled: 0.7137 (1.0178)  class_error_unscaled: 100.0000 (98.9640)  loss_bbox_unscaled: 0.5103 (0.5943)  loss_giou_unscaled: 1.0068 (1.0215)  cardinality_error_unscaled: 2.1250 (11.8363)  loss_ce_0_unscaled: 0.6949 (1.1806)  loss_bbox_0_unscaled: 0.5168 (0.6056)  loss_giou_0_unscaled: 1.0011 (1.0165)  cardinality_error_0_unscaled: 2.1250 (14.8556)  loss_ce_1_unscaled: 0.6955 (1.1662)  loss_bbox_1_unscaled: 0.5155 (0.5984)  loss_giou_1_unscaled: 0.9992 (1.0234)  cardinality_error_1_unscaled: 2.1250 (14.3715)  loss_ce_2_unscaled: 0.7019 (1.1249)  loss_bbox_2_unscaled: 0.5185 (0.6002)  loss_giou_2_unscaled: 0.9867 (1.0161)  cardinality_error_2_unscaled: 2.1250 (14.3609)  loss_ce_3_unscaled: 0.6908 (0.9939)  loss_bbox_3_unscaled: 0.5134 (0.6026)  loss_giou_3_unscaled: 1.0205 (1.0201)  cardinality_error_3_unscaled: 2.1250 (11.7764)  loss_ce_4_unscaled: 0.7113 (1.0284)  loss_bbox_4_unscaled: 0.5203 (0.5971)  loss_giou_4_unscaled: 1.0183 (1.0231)  cardinality_error_4_unscaled: 2.1250 (13.8415)  time: 0.2755  data: 0.0306  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 80/248]  eta: 0:00:57  lr: 0.000100  class_error: 100.00  loss: 30.8804 (36.0297)  loss_ce: 0.6870 (0.9780)  loss_bbox: 2.4202 (2.8997)  loss_giou: 1.9989 (2.0456)  loss_ce_0: 0.6817 (1.1209)  loss_bbox_0: 2.4093 (2.9487)  loss_giou_0: 1.9856 (2.0359)  loss_ce_1: 0.6855 (1.1089)  loss_bbox_1: 2.3913 (2.9180)  loss_giou_1: 2.0165 (2.0515)  loss_ce_2: 0.6890 (1.0721)  loss_bbox_2: 2.3978 (2.9241)  loss_giou_2: 2.0440 (2.0413)  loss_ce_3: 0.6736 (0.9562)  loss_bbox_3: 2.4133 (2.9369)  loss_giou_3: 1.9774 (2.0440)  loss_ce_4: 0.6846 (0.9874)  loss_bbox_4: 2.4086 (2.9101)  loss_giou_4: 2.0149 (2.0505)  loss_ce_unscaled: 0.6870 (0.9780)  class_error_unscaled: 100.0000 (99.0919)  loss_bbox_unscaled: 0.4840 (0.5799)  loss_giou_unscaled: 0.9995 (1.0228)  cardinality_error_unscaled: 2.1250 (10.6466)  loss_ce_0_unscaled: 0.6817 (1.1209)  loss_bbox_0_unscaled: 0.4819 (0.5897)  loss_giou_0_unscaled: 0.9928 (1.0180)  cardinality_error_0_unscaled: 2.1250 (13.2932)  loss_ce_1_unscaled: 0.6855 (1.1089)  loss_bbox_1_unscaled: 0.4783 (0.5836)  loss_giou_1_unscaled: 1.0083 (1.0258)  cardinality_error_1_unscaled: 2.1250 (12.8688)  loss_ce_2_unscaled: 0.6890 (1.0721)  loss_bbox_2_unscaled: 0.4796 (0.5848)  loss_giou_2_unscaled: 1.0220 (1.0206)  cardinality_error_2_unscaled: 2.1250 (12.8596)  loss_ce_3_unscaled: 0.6736 (0.9562)  loss_bbox_3_unscaled: 0.4827 (0.5874)  loss_giou_3_unscaled: 0.9887 (1.0220)  cardinality_error_3_unscaled: 2.1250 (10.5941)  loss_ce_4_unscaled: 0.6846 (0.9874)  loss_bbox_4_unscaled: 0.4817 (0.5820)  loss_giou_4_unscaled: 1.0075 (1.0253)  cardinality_error_4_unscaled: 2.1250 (12.4043)  time: 0.2841  data: 0.0375  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 90/248]  eta: 0:00:52  lr: 0.000100  class_error: 100.00  loss: 30.7445 (35.4720)  loss_ce: 0.6962 (0.9489)  loss_bbox: 2.3095 (2.8509)  loss_giou: 2.0365 (2.0410)  loss_ce_0: 0.6947 (1.0752)  loss_bbox_0: 2.3066 (2.8852)  loss_giou_0: 2.0228 (2.0322)  loss_ce_1: 0.6949 (1.0638)  loss_bbox_1: 2.3325 (2.8664)  loss_giou_1: 2.0352 (2.0450)  loss_ce_2: 0.7017 (1.0325)  loss_bbox_2: 2.3114 (2.8754)  loss_giou_2: 2.0654 (2.0367)  loss_ce_3: 0.6876 (0.9283)  loss_bbox_3: 2.3454 (2.8874)  loss_giou_3: 2.0236 (2.0378)  loss_ce_4: 0.6895 (0.9564)  loss_bbox_4: 2.3303 (2.8627)  loss_giou_4: 2.0395 (2.0462)  loss_ce_unscaled: 0.6962 (0.9489)  class_error_unscaled: 100.0000 (99.1917)  loss_bbox_unscaled: 0.4619 (0.5702)  loss_giou_unscaled: 1.0183 (1.0205)  cardinality_error_unscaled: 2.1250 (9.7266)  loss_ce_0_unscaled: 0.6947 (1.0752)  loss_bbox_0_unscaled: 0.4613 (0.5770)  loss_giou_0_unscaled: 1.0114 (1.0161)  cardinality_error_0_unscaled: 2.1250 (12.0824)  loss_ce_1_unscaled: 0.6949 (1.0638)  loss_bbox_1_unscaled: 0.4665 (0.5733)  loss_giou_1_unscaled: 1.0176 (1.0225)  cardinality_error_1_unscaled: 2.1250 (11.7047)  loss_ce_2_unscaled: 0.7017 (1.0325)  loss_bbox_2_unscaled: 0.4623 (0.5751)  loss_giou_2_unscaled: 1.0327 (1.0183)  cardinality_error_2_unscaled: 2.1250 (11.6964)  loss_ce_3_unscaled: 0.6876 (0.9283)  loss_bbox_3_unscaled: 0.4691 (0.5775)  loss_giou_3_unscaled: 1.0118 (1.0189)  cardinality_error_3_unscaled: 2.1250 (9.6799)  loss_ce_4_unscaled: 0.6895 (0.9564)  loss_bbox_4_unscaled: 0.4661 (0.5725)  loss_giou_4_unscaled: 1.0197 (1.0231)  cardinality_error_4_unscaled: 2.1250 (11.2912)  time: 0.2932  data: 0.0366  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [100/248]  eta: 0:00:48  lr: 0.000100  class_error: 100.00  loss: 31.0116 (35.0240)  loss_ce: 0.7054 (0.9240)  loss_bbox: 2.3095 (2.8055)  loss_giou: 2.0365 (2.0423)  loss_ce_0: 0.7003 (1.0380)  loss_bbox_0: 2.2633 (2.8294)  loss_giou_0: 2.0191 (2.0338)  loss_ce_1: 0.6944 (1.0271)  loss_bbox_1: 2.3267 (2.8196)  loss_giou_1: 1.9769 (2.0461)  loss_ce_2: 0.7017 (0.9994)  loss_bbox_2: 2.3519 (2.8274)  loss_giou_2: 1.9811 (2.0435)  loss_ce_3: 0.6989 (0.9052)  loss_bbox_3: 2.3519 (2.8416)  loss_giou_3: 1.9569 (2.0442)  loss_ce_4: 0.6904 (0.9299)  loss_bbox_4: 2.3530 (2.8168)  loss_giou_4: 2.0395 (2.0499)  loss_ce_unscaled: 0.7054 (0.9240)  class_error_unscaled: 100.0000 (99.2717)  loss_bbox_unscaled: 0.4619 (0.5611)  loss_giou_unscaled: 1.0183 (1.0211)  cardinality_error_unscaled: 2.2500 (8.9901)  loss_ce_0_unscaled: 0.7003 (1.0380)  loss_bbox_0_unscaled: 0.4527 (0.5659)  loss_giou_0_unscaled: 1.0095 (1.0169)  cardinality_error_0_unscaled: 2.2500 (11.1126)  loss_ce_1_unscaled: 0.6944 (1.0271)  loss_bbox_1_unscaled: 0.4653 (0.5639)  loss_giou_1_unscaled: 0.9884 (1.0231)  cardinality_error_1_unscaled: 2.2500 (10.7723)  loss_ce_2_unscaled: 0.7017 (0.9994)  loss_bbox_2_unscaled: 0.4704 (0.5655)  loss_giou_2_unscaled: 0.9905 (1.0218)  cardinality_error_2_unscaled: 2.2500 (10.7649)  loss_ce_3_unscaled: 0.6989 (0.9052)  loss_bbox_3_unscaled: 0.4704 (0.5683)  loss_giou_3_unscaled: 0.9785 (1.0221)  cardinality_error_3_unscaled: 2.2500 (8.9480)  loss_ce_4_unscaled: 0.6904 (0.9299)  loss_bbox_4_unscaled: 0.4706 (0.5634)  loss_giou_4_unscaled: 1.0197 (1.0249)  cardinality_error_4_unscaled: 2.2500 (10.3998)  time: 0.2881  data: 0.0290  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [110/248]  eta: 0:00:45  lr: 0.000100  class_error: 100.00  loss: 29.8931 (34.6456)  loss_ce: 0.6935 (0.9026)  loss_bbox: 2.2759 (2.7710)  loss_giou: 2.0244 (2.0359)  loss_ce_0: 0.6884 (1.0064)  loss_bbox_0: 2.3119 (2.7947)  loss_giou_0: 2.0656 (2.0276)  loss_ce_1: 0.6788 (0.9960)  loss_bbox_1: 2.2714 (2.7857)  loss_giou_1: 2.0933 (2.0413)  loss_ce_2: 0.6800 (0.9708)  loss_bbox_2: 2.3338 (2.7941)  loss_giou_2: 2.1488 (2.0434)  loss_ce_3: 0.6837 (0.8858)  loss_bbox_3: 2.3519 (2.8093)  loss_giou_3: 2.1174 (2.0427)  loss_ce_4: 0.6903 (0.9079)  loss_bbox_4: 2.3091 (2.7840)  loss_giou_4: 2.1263 (2.0465)  loss_ce_unscaled: 0.6935 (0.9026)  class_error_unscaled: 100.0000 (99.3373)  loss_bbox_unscaled: 0.4552 (0.5542)  loss_giou_unscaled: 1.0122 (1.0179)  cardinality_error_unscaled: 2.2500 (8.3874)  loss_ce_0_unscaled: 0.6884 (1.0064)  loss_bbox_0_unscaled: 0.4624 (0.5589)  loss_giou_0_unscaled: 1.0328 (1.0138)  cardinality_error_0_unscaled: 2.2500 (10.3187)  loss_ce_1_unscaled: 0.6788 (0.9960)  loss_bbox_1_unscaled: 0.4543 (0.5571)  loss_giou_1_unscaled: 1.0466 (1.0206)  cardinality_error_1_unscaled: 2.2500 (10.0090)  loss_ce_2_unscaled: 0.6800 (0.9708)  loss_bbox_2_unscaled: 0.4668 (0.5588)  loss_giou_2_unscaled: 1.0744 (1.0217)  cardinality_error_2_unscaled: 2.2500 (10.0023)  loss_ce_3_unscaled: 0.6837 (0.8858)  loss_bbox_3_unscaled: 0.4704 (0.5619)  loss_giou_3_unscaled: 1.0587 (1.0213)  cardinality_error_3_unscaled: 2.2500 (8.3491)  loss_ce_4_unscaled: 0.6903 (0.9079)  loss_bbox_4_unscaled: 0.4618 (0.5568)  loss_giou_4_unscaled: 1.0631 (1.0232)  cardinality_error_4_unscaled: 2.2500 (9.6700)  time: 0.2892  data: 0.0294  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [120/248]  eta: 0:00:41  lr: 0.000100  class_error: 100.00  loss: 29.2722 (34.1702)  loss_ce: 0.6855 (0.8851)  loss_bbox: 2.1963 (2.7210)  loss_giou: 1.9271 (2.0265)  loss_ce_0: 0.6823 (0.9796)  loss_bbox_0: 2.2692 (2.7390)  loss_giou_0: 1.9437 (2.0191)  loss_ce_1: 0.6733 (0.9696)  loss_bbox_1: 2.2674 (2.7362)  loss_giou_1: 1.9977 (2.0344)  loss_ce_2: 0.6816 (0.9471)  loss_bbox_2: 2.2712 (2.7458)  loss_giou_2: 1.9940 (2.0374)  loss_ce_3: 0.6797 (0.8691)  loss_bbox_3: 2.2429 (2.7624)  loss_giou_3: 1.9794 (2.0350)  loss_ce_4: 0.6903 (0.8895)  loss_bbox_4: 2.1805 (2.7351)  loss_giou_4: 1.9477 (2.0382)  loss_ce_unscaled: 0.6855 (0.8851)  class_error_unscaled: 100.0000 (99.3921)  loss_bbox_unscaled: 0.4393 (0.5442)  loss_giou_unscaled: 0.9635 (1.0133)  cardinality_error_unscaled: 2.2500 (7.8781)  loss_ce_0_unscaled: 0.6823 (0.9796)  loss_bbox_0_unscaled: 0.4538 (0.5478)  loss_giou_0_unscaled: 0.9718 (1.0095)  cardinality_error_0_unscaled: 2.2500 (9.6498)  loss_ce_1_unscaled: 0.6733 (0.9696)  loss_bbox_1_unscaled: 0.4535 (0.5472)  loss_giou_1_unscaled: 0.9989 (1.0172)  cardinality_error_1_unscaled: 2.2500 (9.3657)  loss_ce_2_unscaled: 0.6816 (0.9471)  loss_bbox_2_unscaled: 0.4542 (0.5492)  loss_giou_2_unscaled: 0.9970 (1.0187)  cardinality_error_2_unscaled: 2.2500 (9.3595)  loss_ce_3_unscaled: 0.6797 (0.8691)  loss_bbox_3_unscaled: 0.4486 (0.5525)  loss_giou_3_unscaled: 0.9897 (1.0175)  cardinality_error_3_unscaled: 2.2500 (7.8430)  loss_ce_4_unscaled: 0.6903 (0.8895)  loss_bbox_4_unscaled: 0.4361 (0.5470)  loss_giou_4_unscaled: 0.9739 (1.0191)  cardinality_error_4_unscaled: 2.2500 (9.0548)  time: 0.2929  data: 0.0391  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [130/248]  eta: 0:00:38  lr: 0.000100  class_error: 100.00  loss: 27.5408 (33.6434)  loss_ce: 0.6759 (0.8693)  loss_bbox: 1.9492 (2.6705)  loss_giou: 1.8188 (2.0086)  loss_ce_0: 0.6823 (0.9565)  loss_bbox_0: 2.0400 (2.6901)  loss_giou_0: 1.8237 (1.9985)  loss_ce_1: 0.6648 (0.9472)  loss_bbox_1: 2.0629 (2.6858)  loss_giou_1: 1.7772 (2.0139)  loss_ce_2: 0.6785 (0.9260)  loss_bbox_2: 2.0947 (2.6978)  loss_giou_2: 1.8505 (2.0206)  loss_ce_3: 0.6794 (0.8544)  loss_bbox_3: 2.1051 (2.7113)  loss_giou_3: 1.8190 (2.0156)  loss_ce_4: 0.6781 (0.8735)  loss_bbox_4: 1.9925 (2.6838)  loss_giou_4: 1.8350 (2.0201)  loss_ce_unscaled: 0.6759 (0.8693)  class_error_unscaled: 100.0000 (99.4385)  loss_bbox_unscaled: 0.3898 (0.5341)  loss_giou_unscaled: 0.9094 (1.0043)  cardinality_error_unscaled: 2.1250 (7.4427)  loss_ce_0_unscaled: 0.6823 (0.9565)  loss_bbox_0_unscaled: 0.4080 (0.5380)  loss_giou_0_unscaled: 0.9118 (0.9993)  cardinality_error_0_unscaled: 2.1250 (9.0792)  loss_ce_1_unscaled: 0.6648 (0.9472)  loss_bbox_1_unscaled: 0.4126 (0.5372)  loss_giou_1_unscaled: 0.8886 (1.0069)  cardinality_error_1_unscaled: 2.1250 (8.8168)  loss_ce_2_unscaled: 0.6785 (0.9260)  loss_bbox_2_unscaled: 0.4189 (0.5396)  loss_giou_2_unscaled: 0.9252 (1.0103)  cardinality_error_2_unscaled: 2.1250 (8.8111)  loss_ce_3_unscaled: 0.6794 (0.8544)  loss_bbox_3_unscaled: 0.4210 (0.5423)  loss_giou_3_unscaled: 0.9095 (1.0078)  cardinality_error_3_unscaled: 2.1250 (7.4103)  loss_ce_4_unscaled: 0.6781 (0.8735)  loss_bbox_4_unscaled: 0.3985 (0.5368)  loss_giou_4_unscaled: 0.9175 (1.0101)  cardinality_error_4_unscaled: 2.1250 (8.5296)  time: 0.3134  data: 0.0379  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [140/248]  eta: 0:00:35  lr: 0.000100  class_error: 100.00  loss: 27.9492 (33.3069)  loss_ce: 0.6884 (0.8582)  loss_bbox: 2.1499 (2.6425)  loss_giou: 1.8388 (2.0021)  loss_ce_0: 0.6813 (0.9376)  loss_bbox_0: 2.0453 (2.6464)  loss_giou_0: 1.8324 (1.9860)  loss_ce_1: 0.6824 (0.9294)  loss_bbox_1: 2.0777 (2.6446)  loss_giou_1: 1.8681 (2.0048)  loss_ce_2: 0.6697 (0.9089)  loss_bbox_2: 2.1673 (2.6651)  loss_giou_2: 1.8505 (2.0163)  loss_ce_3: 0.6905 (0.8443)  loss_bbox_3: 2.2075 (2.6769)  loss_giou_3: 1.8388 (2.0100)  loss_ce_4: 0.6810 (0.8617)  loss_bbox_4: 2.1871 (2.6580)  loss_giou_4: 1.8380 (2.0142)  loss_ce_unscaled: 0.6884 (0.8582)  class_error_unscaled: 100.0000 (99.4783)  loss_bbox_unscaled: 0.4300 (0.5285)  loss_giou_unscaled: 0.9194 (1.0010)  cardinality_error_unscaled: 2.1250 (7.0736)  loss_ce_0_unscaled: 0.6813 (0.9376)  loss_bbox_0_unscaled: 0.4091 (0.5293)  loss_giou_0_unscaled: 0.9162 (0.9930)  cardinality_error_0_unscaled: 2.1250 (8.5940)  loss_ce_1_unscaled: 0.6824 (0.9294)  loss_bbox_1_unscaled: 0.4155 (0.5289)  loss_giou_1_unscaled: 0.9340 (1.0024)  cardinality_error_1_unscaled: 2.1250 (8.3502)  loss_ce_2_unscaled: 0.6697 (0.9089)  loss_bbox_2_unscaled: 0.4335 (0.5330)  loss_giou_2_unscaled: 0.9252 (1.0082)  cardinality_error_2_unscaled: 2.1250 (8.3449)  loss_ce_3_unscaled: 0.6905 (0.8443)  loss_bbox_3_unscaled: 0.4415 (0.5354)  loss_giou_3_unscaled: 0.9194 (1.0050)  cardinality_error_3_unscaled: 2.1250 (7.0434)  loss_ce_4_unscaled: 0.6810 (0.8617)  loss_bbox_4_unscaled: 0.4374 (0.5316)  loss_giou_4_unscaled: 0.9190 (1.0071)  cardinality_error_4_unscaled: 2.1250 (8.0833)  time: 0.3520  data: 0.0549  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [150/248]  eta: 0:00:31  lr: 0.000100  class_error: 100.00  loss: 27.5890 (32.7884)  loss_ce: 0.6884 (0.8469)  loss_bbox: 2.1499 (2.5947)  loss_giou: 1.8855 (1.9900)  loss_ce_0: 0.6851 (0.9209)  loss_bbox_0: 1.9873 (2.5920)  loss_giou_0: 1.7543 (1.9640)  loss_ce_1: 0.6854 (0.9130)  loss_bbox_1: 1.9258 (2.5855)  loss_giou_1: 1.7100 (1.9776)  loss_ce_2: 0.6750 (0.8939)  loss_bbox_2: 2.0467 (2.6115)  loss_giou_2: 1.8101 (1.9958)  loss_ce_3: 0.6943 (0.8339)  loss_bbox_3: 2.1296 (2.6212)  loss_giou_3: 1.8385 (1.9907)  loss_ce_4: 0.6788 (0.8498)  loss_bbox_4: 2.1423 (2.6074)  loss_giou_4: 1.8745 (1.9994)  loss_ce_unscaled: 0.6884 (0.8469)  class_error_unscaled: 100.0000 (99.5129)  loss_bbox_unscaled: 0.4300 (0.5189)  loss_giou_unscaled: 0.9428 (0.9950)  cardinality_error_unscaled: 2.1250 (6.7508)  loss_ce_0_unscaled: 0.6851 (0.9209)  loss_bbox_0_unscaled: 0.3975 (0.5184)  loss_giou_0_unscaled: 0.8771 (0.9820)  cardinality_error_0_unscaled: 2.1250 (8.1705)  loss_ce_1_unscaled: 0.6854 (0.9130)  loss_bbox_1_unscaled: 0.3852 (0.5171)  loss_giou_1_unscaled: 0.8550 (0.9888)  cardinality_error_1_unscaled: 2.1250 (7.9429)  loss_ce_2_unscaled: 0.6750 (0.8939)  loss_bbox_2_unscaled: 0.4093 (0.5223)  loss_giou_2_unscaled: 0.9050 (0.9979)  cardinality_error_2_unscaled: 2.1250 (7.9379)  loss_ce_3_unscaled: 0.6943 (0.8339)  loss_bbox_3_unscaled: 0.4259 (0.5242)  loss_giou_3_unscaled: 0.9193 (0.9953)  cardinality_error_3_unscaled: 2.1250 (6.7227)  loss_ce_4_unscaled: 0.6788 (0.8498)  loss_bbox_4_unscaled: 0.4285 (0.5215)  loss_giou_4_unscaled: 0.9372 (0.9997)  cardinality_error_4_unscaled: 2.1250 (7.6937)  time: 0.3256  data: 0.0557  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [160/248]  eta: 0:00:28  lr: 0.000100  class_error: 100.00  loss: 24.4174 (32.2451)  loss_ce: 0.6869 (0.8377)  loss_bbox: 1.6545 (2.5397)  loss_giou: 1.7457 (1.9658)  loss_ce_0: 0.6953 (0.9073)  loss_bbox_0: 1.6519 (2.5354)  loss_giou_0: 1.6477 (1.9393)  loss_ce_1: 0.6979 (0.9005)  loss_bbox_1: 1.5986 (2.5248)  loss_giou_1: 1.6095 (1.9499)  loss_ce_2: 0.6986 (0.8820)  loss_bbox_2: 1.7116 (2.5581)  loss_giou_2: 1.7660 (1.9758)  loss_ce_3: 0.7018 (0.8261)  loss_bbox_3: 1.6701 (2.5659)  loss_giou_3: 1.6756 (1.9684)  loss_ce_4: 0.6983 (0.8413)  loss_bbox_4: 1.7704 (2.5527)  loss_giou_4: 1.7179 (1.9743)  loss_ce_unscaled: 0.6869 (0.8377)  class_error_unscaled: 100.0000 (99.5431)  loss_bbox_unscaled: 0.3309 (0.5079)  loss_giou_unscaled: 0.8729 (0.9829)  cardinality_error_unscaled: 2.2500 (6.4720)  loss_ce_0_unscaled: 0.6953 (0.9073)  loss_bbox_0_unscaled: 0.3304 (0.5071)  loss_giou_0_unscaled: 0.8238 (0.9697)  cardinality_error_0_unscaled: 2.2500 (7.8036)  loss_ce_1_unscaled: 0.6979 (0.9005)  loss_bbox_1_unscaled: 0.3197 (0.5050)  loss_giou_1_unscaled: 0.8047 (0.9750)  cardinality_error_1_unscaled: 2.2500 (7.5901)  loss_ce_2_unscaled: 0.6986 (0.8820)  loss_bbox_2_unscaled: 0.3423 (0.5116)  loss_giou_2_unscaled: 0.8830 (0.9879)  cardinality_error_2_unscaled: 2.2500 (7.5854)  loss_ce_3_unscaled: 0.7018 (0.8261)  loss_bbox_3_unscaled: 0.3340 (0.5132)  loss_giou_3_unscaled: 0.8378 (0.9842)  cardinality_error_3_unscaled: 2.2500 (6.4457)  loss_ce_4_unscaled: 0.6983 (0.8413)  loss_bbox_4_unscaled: 0.3541 (0.5105)  loss_giou_4_unscaled: 0.8589 (0.9872)  cardinality_error_4_unscaled: 2.2500 (7.3564)  time: 0.2911  data: 0.0288  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [170/248]  eta: 0:00:25  lr: 0.000100  class_error: 100.00  loss: 23.1896 (31.7021)  loss_ce: 0.7097 (0.8311)  loss_bbox: 1.6021 (2.4882)  loss_giou: 1.4781 (1.9378)  loss_ce_0: 0.6983 (0.8954)  loss_bbox_0: 1.5100 (2.4844)  loss_giou_0: 1.4896 (1.9088)  loss_ce_1: 0.7205 (0.8907)  loss_bbox_1: 1.4321 (2.4691)  loss_giou_1: 1.4204 (1.9170)  loss_ce_2: 0.7052 (0.8725)  loss_bbox_2: 1.5606 (2.5056)  loss_giou_2: 1.5255 (1.9473)  loss_ce_3: 0.7260 (0.8206)  loss_bbox_3: 1.5852 (2.5129)  loss_giou_3: 1.5705 (1.9398)  loss_ce_4: 0.7200 (0.8348)  loss_bbox_4: 1.6459 (2.5008)  loss_giou_4: 1.5518 (1.9453)  loss_ce_unscaled: 0.7097 (0.8311)  class_error_unscaled: 100.0000 (99.5698)  loss_bbox_unscaled: 0.3204 (0.4976)  loss_giou_unscaled: 0.7390 (0.9689)  cardinality_error_unscaled: 2.3750 (6.2288)  loss_ce_0_unscaled: 0.6983 (0.8954)  loss_bbox_0_unscaled: 0.3020 (0.4969)  loss_giou_0_unscaled: 0.7448 (0.9544)  cardinality_error_0_unscaled: 2.3750 (7.4825)  loss_ce_1_unscaled: 0.7205 (0.8907)  loss_bbox_1_unscaled: 0.2864 (0.4938)  loss_giou_1_unscaled: 0.7102 (0.9585)  cardinality_error_1_unscaled: 2.3750 (7.2814)  loss_ce_2_unscaled: 0.7052 (0.8725)  loss_bbox_2_unscaled: 0.3121 (0.5011)  loss_giou_2_unscaled: 0.7628 (0.9736)  cardinality_error_2_unscaled: 2.3750 (7.2770)  loss_ce_3_unscaled: 0.7260 (0.8206)  loss_bbox_3_unscaled: 0.3170 (0.5026)  loss_giou_3_unscaled: 0.7852 (0.9699)  cardinality_error_3_unscaled: 2.3750 (6.2039)  loss_ce_4_unscaled: 0.7200 (0.8348)  loss_bbox_4_unscaled: 0.3292 (0.5002)  loss_giou_4_unscaled: 0.7759 (0.9727)  cardinality_error_4_unscaled: 2.3750 (7.0614)  time: 0.3005  data: 0.0295  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [180/248]  eta: 0:00:21  lr: 0.000100  class_error: 100.00  loss: 21.4473 (31.1414)  loss_ce: 0.7191 (0.8244)  loss_bbox: 1.5273 (2.4350)  loss_giou: 1.3743 (1.9056)  loss_ce_0: 0.6989 (0.8846)  loss_bbox_0: 1.4541 (2.4242)  loss_giou_0: 1.3085 (1.8745)  loss_ce_1: 0.7244 (0.8818)  loss_bbox_1: 1.4105 (2.4085)  loss_giou_1: 1.3593 (1.8838)  loss_ce_2: 0.7157 (0.8639)  loss_bbox_2: 1.5601 (2.4522)  loss_giou_2: 1.3998 (1.9162)  loss_ce_3: 0.7234 (0.8149)  loss_bbox_3: 1.5504 (2.4615)  loss_giou_3: 1.3869 (1.9110)  loss_ce_4: 0.7194 (0.8281)  loss_bbox_4: 1.5356 (2.4523)  loss_giou_4: 1.4361 (1.9188)  loss_ce_unscaled: 0.7191 (0.8244)  class_error_unscaled: 100.0000 (99.5936)  loss_bbox_unscaled: 0.3055 (0.4870)  loss_giou_unscaled: 0.6872 (0.9528)  cardinality_error_unscaled: 2.3750 (6.0124)  loss_ce_0_unscaled: 0.6989 (0.8846)  loss_bbox_0_unscaled: 0.2908 (0.4848)  loss_giou_0_unscaled: 0.6542 (0.9372)  cardinality_error_0_unscaled: 2.3750 (7.1968)  loss_ce_1_unscaled: 0.7244 (0.8818)  loss_bbox_1_unscaled: 0.2821 (0.4817)  loss_giou_1_unscaled: 0.6796 (0.9419)  cardinality_error_1_unscaled: 2.3750 (7.0069)  loss_ce_2_unscaled: 0.7157 (0.8639)  loss_bbox_2_unscaled: 0.3120 (0.4904)  loss_giou_2_unscaled: 0.6999 (0.9581)  cardinality_error_2_unscaled: 2.3750 (7.0028)  loss_ce_3_unscaled: 0.7234 (0.8149)  loss_bbox_3_unscaled: 0.3101 (0.4923)  loss_giou_3_unscaled: 0.6934 (0.9555)  cardinality_error_3_unscaled: 2.3750 (5.9890)  loss_ce_4_unscaled: 0.7194 (0.8281)  loss_bbox_4_unscaled: 0.3071 (0.4905)  loss_giou_4_unscaled: 0.7180 (0.9594)  cardinality_error_4_unscaled: 2.3750 (6.7990)  time: 0.3233  data: 0.0643  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [190/248]  eta: 0:00:18  lr: 0.000100  class_error: 100.00  loss: 21.1830 (30.5765)  loss_ce: 0.7201 (0.8191)  loss_bbox: 1.3946 (2.3759)  loss_giou: 1.3097 (1.8727)  loss_ce_0: 0.7238 (0.8775)  loss_bbox_0: 1.3427 (2.3687)  loss_giou_0: 1.2997 (1.8443)  loss_ce_1: 0.7375 (0.8761)  loss_bbox_1: 1.3932 (2.3533)  loss_giou_1: 1.2758 (1.8522)  loss_ce_2: 0.7179 (0.8566)  loss_bbox_2: 1.4933 (2.3968)  loss_giou_2: 1.3373 (1.8853)  loss_ce_3: 0.7205 (0.8103)  loss_bbox_3: 1.4989 (2.4041)  loss_giou_3: 1.3815 (1.8813)  loss_ce_4: 0.7194 (0.8228)  loss_bbox_4: 1.4138 (2.3936)  loss_giou_4: 1.3546 (1.8860)  loss_ce_unscaled: 0.7201 (0.8191)  class_error_unscaled: 100.0000 (99.6149)  loss_bbox_unscaled: 0.2789 (0.4752)  loss_giou_unscaled: 0.6548 (0.9364)  cardinality_error_unscaled: 2.3750 (5.8213)  loss_ce_0_unscaled: 0.7238 (0.8775)  loss_bbox_0_unscaled: 0.2685 (0.4737)  loss_giou_0_unscaled: 0.6499 (0.9222)  cardinality_error_0_unscaled: 2.3750 (6.9437)  loss_ce_1_unscaled: 0.7375 (0.8761)  loss_bbox_1_unscaled: 0.2786 (0.4707)  loss_giou_1_unscaled: 0.6379 (0.9261)  cardinality_error_1_unscaled: 2.3750 (6.7637)  loss_ce_2_unscaled: 0.7179 (0.8566)  loss_bbox_2_unscaled: 0.2987 (0.4794)  loss_giou_2_unscaled: 0.6687 (0.9427)  cardinality_error_2_unscaled: 2.3750 (6.7598)  loss_ce_3_unscaled: 0.7205 (0.8103)  loss_bbox_3_unscaled: 0.2998 (0.4808)  loss_giou_3_unscaled: 0.6907 (0.9406)  cardinality_error_3_unscaled: 2.3750 (5.7991)  loss_ce_4_unscaled: 0.7194 (0.8228)  loss_bbox_4_unscaled: 0.2828 (0.4787)  loss_giou_4_unscaled: 0.6773 (0.9430)  cardinality_error_4_unscaled: 2.3750 (6.5668)  time: 0.3082  data: 0.0621  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [200/248]  eta: 0:00:15  lr: 0.000100  class_error: 100.00  loss: 19.0278 (29.9890)  loss_ce: 0.7175 (0.8134)  loss_bbox: 1.2547 (2.3177)  loss_giou: 1.1937 (1.8346)  loss_ce_0: 0.7202 (0.8691)  loss_bbox_0: 1.2431 (2.3138)  loss_giou_0: 1.2595 (1.8114)  loss_ce_1: 0.7401 (0.8691)  loss_bbox_1: 1.2198 (2.2980)  loss_giou_1: 1.2758 (1.8198)  loss_ce_2: 0.7101 (0.8492)  loss_bbox_2: 1.3283 (2.3421)  loss_giou_2: 1.2895 (1.8513)  loss_ce_3: 0.7207 (0.8054)  loss_bbox_3: 1.2641 (2.3447)  loss_giou_3: 1.3478 (1.8447)  loss_ce_4: 0.7298 (0.8175)  loss_bbox_4: 1.2593 (2.3367)  loss_giou_4: 1.2286 (1.8503)  loss_ce_unscaled: 0.7175 (0.8134)  class_error_unscaled: 100.0000 (99.6340)  loss_bbox_unscaled: 0.2509 (0.4635)  loss_giou_unscaled: 0.5968 (0.9173)  cardinality_error_unscaled: 2.2500 (5.6443)  loss_ce_0_unscaled: 0.7202 (0.8691)  loss_bbox_0_unscaled: 0.2486 (0.4628)  loss_giou_0_unscaled: 0.6297 (0.9057)  cardinality_error_0_unscaled: 2.2500 (6.7108)  loss_ce_1_unscaled: 0.7401 (0.8691)  loss_bbox_1_unscaled: 0.2440 (0.4596)  loss_giou_1_unscaled: 0.6379 (0.9099)  cardinality_error_1_unscaled: 2.2500 (6.5398)  loss_ce_2_unscaled: 0.7101 (0.8492)  loss_bbox_2_unscaled: 0.2657 (0.4684)  loss_giou_2_unscaled: 0.6447 (0.9256)  cardinality_error_2_unscaled: 2.2500 (6.5361)  loss_ce_3_unscaled: 0.7207 (0.8054)  loss_bbox_3_unscaled: 0.2528 (0.4689)  loss_giou_3_unscaled: 0.6739 (0.9223)  cardinality_error_3_unscaled: 2.2500 (5.6231)  loss_ce_4_unscaled: 0.7298 (0.8175)  loss_bbox_4_unscaled: 0.2519 (0.4673)  loss_giou_4_unscaled: 0.6143 (0.9251)  cardinality_error_4_unscaled: 2.2500 (6.3526)  time: 0.3025  data: 0.0275  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [210/248]  eta: 0:00:12  lr: 0.000100  class_error: 100.00  loss: 18.4069 (29.4827)  loss_ce: 0.6877 (0.8074)  loss_bbox: 1.1825 (2.2666)  loss_giou: 1.0513 (1.7987)  loss_ce_0: 0.7005 (0.8604)  loss_bbox_0: 1.3029 (2.2722)  loss_giou_0: 1.1939 (1.7853)  loss_ce_1: 0.7076 (0.8604)  loss_bbox_1: 1.2306 (2.2585)  loss_giou_1: 1.1658 (1.7959)  loss_ce_2: 0.6894 (0.8410)  loss_bbox_2: 1.3414 (2.2967)  loss_giou_2: 1.1264 (1.8211)  loss_ce_3: 0.6904 (0.7993)  loss_bbox_3: 1.2831 (2.2974)  loss_giou_3: 1.1207 (1.8116)  loss_ce_4: 0.6816 (0.8112)  loss_bbox_4: 1.2156 (2.2853)  loss_giou_4: 1.0997 (1.8136)  loss_ce_unscaled: 0.6877 (0.8074)  class_error_unscaled: 100.0000 (99.6514)  loss_bbox_unscaled: 0.2365 (0.4533)  loss_giou_unscaled: 0.5257 (0.8994)  cardinality_error_unscaled: 2.1250 (5.4745)  loss_ce_0_unscaled: 0.7005 (0.8604)  loss_bbox_0_unscaled: 0.2606 (0.4544)  loss_giou_0_unscaled: 0.5970 (0.8927)  cardinality_error_0_unscaled: 2.1250 (6.4905)  loss_ce_1_unscaled: 0.7076 (0.8604)  loss_bbox_1_unscaled: 0.2461 (0.4517)  loss_giou_1_unscaled: 0.5829 (0.8980)  cardinality_error_1_unscaled: 2.1250 (6.3276)  loss_ce_2_unscaled: 0.6894 (0.8410)  loss_bbox_2_unscaled: 0.2683 (0.4593)  loss_giou_2_unscaled: 0.5632 (0.9105)  cardinality_error_2_unscaled: 2.1250 (6.3241)  loss_ce_3_unscaled: 0.6904 (0.7993)  loss_bbox_3_unscaled: 0.2566 (0.4595)  loss_giou_3_unscaled: 0.5604 (0.9058)  cardinality_error_3_unscaled: 2.1250 (5.4544)  loss_ce_4_unscaled: 0.6816 (0.8112)  loss_bbox_4_unscaled: 0.2431 (0.4571)  loss_giou_4_unscaled: 0.5498 (0.9068)  cardinality_error_4_unscaled: 2.1250 (6.1493)  time: 0.3002  data: 0.0288  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [220/248]  eta: 0:00:08  lr: 0.000100  class_error: 100.00  loss: 18.5608 (29.0035)  loss_ce: 0.6850 (0.8032)  loss_bbox: 1.1772 (2.2162)  loss_giou: 1.1199 (1.7701)  loss_ce_0: 0.6960 (0.8535)  loss_bbox_0: 1.3029 (2.2249)  loss_giou_0: 1.2139 (1.7607)  loss_ce_1: 0.7012 (0.8541)  loss_bbox_1: 1.2700 (2.2134)  loss_giou_1: 1.1472 (1.7713)  loss_ce_2: 0.6896 (0.8358)  loss_bbox_2: 1.2590 (2.2469)  loss_giou_2: 1.1554 (1.7943)  loss_ce_3: 0.7041 (0.7958)  loss_bbox_3: 1.2198 (2.2438)  loss_giou_3: 1.1409 (1.7825)  loss_ce_4: 0.6956 (0.8078)  loss_bbox_4: 1.2018 (2.2386)  loss_giou_4: 1.1330 (1.7908)  loss_ce_unscaled: 0.6850 (0.8032)  class_error_unscaled: 100.0000 (99.6672)  loss_bbox_unscaled: 0.2354 (0.4432)  loss_giou_unscaled: 0.5599 (0.8850)  cardinality_error_unscaled: 2.1250 (5.3314)  loss_ce_0_unscaled: 0.6960 (0.8535)  loss_bbox_0_unscaled: 0.2606 (0.4450)  loss_giou_0_unscaled: 0.6070 (0.8803)  cardinality_error_0_unscaled: 2.1250 (6.3015)  loss_ce_1_unscaled: 0.7012 (0.8541)  loss_bbox_1_unscaled: 0.2540 (0.4427)  loss_giou_1_unscaled: 0.5736 (0.8856)  cardinality_error_1_unscaled: 2.1250 (6.1459)  loss_ce_2_unscaled: 0.6896 (0.8358)  loss_bbox_2_unscaled: 0.2518 (0.4494)  loss_giou_2_unscaled: 0.5777 (0.8971)  cardinality_error_2_unscaled: 2.1250 (6.1425)  loss_ce_3_unscaled: 0.7041 (0.7958)  loss_bbox_3_unscaled: 0.2440 (0.4488)  loss_giou_3_unscaled: 0.5704 (0.8913)  cardinality_error_3_unscaled: 2.1250 (5.3122)  loss_ce_4_unscaled: 0.6956 (0.8078)  loss_bbox_4_unscaled: 0.2404 (0.4477)  loss_giou_4_unscaled: 0.5665 (0.8954)  cardinality_error_4_unscaled: 2.1250 (5.9757)  time: 0.3013  data: 0.0586  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [230/248]  eta: 0:00:05  lr: 0.000100  class_error: 100.00  loss: 18.5366 (28.5602)  loss_ce: 0.7019 (0.7988)  loss_bbox: 1.2152 (2.1745)  loss_giou: 1.1267 (1.7441)  loss_ce_0: 0.6922 (0.8462)  loss_bbox_0: 1.2784 (2.1854)  loss_giou_0: 1.1673 (1.7380)  loss_ce_1: 0.7133 (0.8475)  loss_bbox_1: 1.2145 (2.1714)  loss_giou_1: 1.1472 (1.7442)  loss_ce_2: 0.7039 (0.8293)  loss_bbox_2: 1.2614 (2.2050)  loss_giou_2: 1.1433 (1.7664)  loss_ce_3: 0.7008 (0.7916)  loss_bbox_3: 1.2133 (2.2013)  loss_giou_3: 1.1326 (1.7554)  loss_ce_4: 0.7008 (0.8030)  loss_bbox_4: 1.2450 (2.1952)  loss_giou_4: 1.1959 (1.7629)  loss_ce_unscaled: 0.7019 (0.7988)  class_error_unscaled: 100.0000 (99.6816)  loss_bbox_unscaled: 0.2430 (0.4349)  loss_giou_unscaled: 0.5634 (0.8721)  cardinality_error_unscaled: 2.2500 (5.1948)  loss_ce_0_unscaled: 0.6922 (0.8462)  loss_bbox_0_unscaled: 0.2557 (0.4371)  loss_giou_0_unscaled: 0.5836 (0.8690)  cardinality_error_0_unscaled: 2.2500 (6.1234)  loss_ce_1_unscaled: 0.7133 (0.8475)  loss_bbox_1_unscaled: 0.2429 (0.4343)  loss_giou_1_unscaled: 0.5736 (0.8721)  cardinality_error_1_unscaled: 2.2500 (5.9746)  loss_ce_2_unscaled: 0.7039 (0.8293)  loss_bbox_2_unscaled: 0.2523 (0.4410)  loss_giou_2_unscaled: 0.5717 (0.8832)  cardinality_error_2_unscaled: 2.2500 (5.9713)  loss_ce_3_unscaled: 0.7008 (0.7916)  loss_bbox_3_unscaled: 0.2427 (0.4403)  loss_giou_3_unscaled: 0.5663 (0.8777)  cardinality_error_3_unscaled: 2.2500 (5.1769)  loss_ce_4_unscaled: 0.7008 (0.8030)  loss_bbox_4_unscaled: 0.2490 (0.4390)  loss_giou_4_unscaled: 0.5980 (0.8815)  cardinality_error_4_unscaled: 2.2500 (5.8117)  time: 0.3531  data: 0.0735  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:449: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved
  warnings.warn(
Epoch: [0]  [240/248]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 18.7849 (28.1805)  loss_ce: 0.7019 (0.7950)  loss_bbox: 1.2818 (2.1421)  loss_giou: 1.1107 (1.7203)  loss_ce_0: 0.6887 (0.8402)  loss_bbox_0: 1.3429 (2.1529)  loss_giou_0: 1.1422 (1.7139)  loss_ce_1: 0.7050 (0.8421)  loss_bbox_1: 1.2548 (2.1356)  loss_giou_1: 1.1754 (1.7180)  loss_ce_2: 0.6844 (0.8241)  loss_bbox_2: 1.2614 (2.1686)  loss_giou_2: 1.1187 (1.7406)  loss_ce_3: 0.6982 (0.7884)  loss_bbox_3: 1.2775 (2.1671)  loss_giou_3: 1.1293 (1.7314)  loss_ce_4: 0.6890 (0.7987)  loss_bbox_4: 1.3013 (2.1638)  loss_giou_4: 1.1311 (1.7376)  loss_ce_unscaled: 0.7019 (0.7950)  class_error_unscaled: 100.0000 (99.6948)  loss_bbox_unscaled: 0.2564 (0.4284)  loss_giou_unscaled: 0.5554 (0.8602)  cardinality_error_unscaled: 2.2500 (5.0742)  loss_ce_0_unscaled: 0.6887 (0.8402)  loss_bbox_0_unscaled: 0.2686 (0.4306)  loss_giou_0_unscaled: 0.5711 (0.8569)  cardinality_error_0_unscaled: 2.2500 (5.9642)  loss_ce_1_unscaled: 0.7050 (0.8421)  loss_bbox_1_unscaled: 0.2510 (0.4271)  loss_giou_1_unscaled: 0.5877 (0.8590)  cardinality_error_1_unscaled: 2.2500 (5.8216)  loss_ce_2_unscaled: 0.6844 (0.8241)  loss_bbox_2_unscaled: 0.2523 (0.4337)  loss_giou_2_unscaled: 0.5593 (0.8703)  cardinality_error_2_unscaled: 2.2500 (5.8185)  loss_ce_3_unscaled: 0.6982 (0.7884)  loss_bbox_3_unscaled: 0.2555 (0.4334)  loss_giou_3_unscaled: 0.5647 (0.8657)  cardinality_error_3_unscaled: 2.2500 (5.0571)  loss_ce_4_unscaled: 0.6890 (0.7987)  loss_bbox_4_unscaled: 0.2603 (0.4328)  loss_giou_4_unscaled: 0.5655 (0.8688)  cardinality_error_4_unscaled: 2.2500 (5.6655)  time: 0.3512  data: 0.0440  max mem: 17613
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [247/248]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 19.2483 (27.9290)  loss_ce: 0.7048 (0.7933)  loss_bbox: 1.2486 (2.1147)  loss_giou: 1.1491 (1.7063)  loss_ce_0: 0.7058 (0.8367)  loss_bbox_0: 1.2446 (2.1267)  loss_giou_0: 1.1241 (1.6982)  loss_ce_1: 0.7152 (0.8392)  loss_bbox_1: 1.2306 (2.1095)  loss_giou_1: 1.1352 (1.7028)  loss_ce_2: 0.6944 (0.8214)  loss_bbox_2: 1.2518 (2.1440)  loss_giou_2: 1.1414 (1.7279)  loss_ce_3: 0.7048 (0.7868)  loss_bbox_3: 1.2793 (2.1421)  loss_giou_3: 1.1750 (1.7195)  loss_ce_4: 0.7083 (0.7971)  loss_bbox_4: 1.3051 (2.1381)  loss_giou_4: 1.1442 (1.7247)  loss_ce_unscaled: 0.7048 (0.7933)  class_error_unscaled: 100.0000 (99.7034)  loss_bbox_unscaled: 0.2497 (0.4229)  loss_giou_unscaled: 0.5745 (0.8531)  cardinality_error_unscaled: 2.2500 (4.9980)  loss_ce_0_unscaled: 0.7058 (0.8367)  loss_bbox_0_unscaled: 0.2489 (0.4253)  loss_giou_0_unscaled: 0.5621 (0.8491)  cardinality_error_0_unscaled: 2.2500 (5.8629)  loss_ce_1_unscaled: 0.7152 (0.8392)  loss_bbox_1_unscaled: 0.2461 (0.4219)  loss_giou_1_unscaled: 0.5676 (0.8514)  cardinality_error_1_unscaled: 2.2500 (5.7238)  loss_ce_2_unscaled: 0.6944 (0.8214)  loss_bbox_2_unscaled: 0.2504 (0.4288)  loss_giou_2_unscaled: 0.5707 (0.8640)  cardinality_error_2_unscaled: 2.2500 (5.7213)  loss_ce_3_unscaled: 0.7048 (0.7868)  loss_bbox_3_unscaled: 0.2559 (0.4284)  loss_giou_3_unscaled: 0.5875 (0.8598)  cardinality_error_3_unscaled: 2.2500 (4.9814)  loss_ce_4_unscaled: 0.7083 (0.7971)  loss_bbox_4_unscaled: 0.2610 (0.4276)  loss_giou_4_unscaled: 0.5721 (0.8624)  cardinality_error_4_unscaled: 2.2500 (5.5726)  time: 0.3146  data: 0.0281  max mem: 17613
Epoch: [0] Total time: 0:01:19 (0.3212 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 19.2483 (27.9290)  loss_ce: 0.7048 (0.7933)  loss_bbox: 1.2486 (2.1147)  loss_giou: 1.1491 (1.7063)  loss_ce_0: 0.7058 (0.8367)  loss_bbox_0: 1.2446 (2.1267)  loss_giou_0: 1.1241 (1.6982)  loss_ce_1: 0.7152 (0.8392)  loss_bbox_1: 1.2306 (2.1095)  loss_giou_1: 1.1352 (1.7028)  loss_ce_2: 0.6944 (0.8214)  loss_bbox_2: 1.2518 (2.1440)  loss_giou_2: 1.1414 (1.7279)  loss_ce_3: 0.7048 (0.7868)  loss_bbox_3: 1.2793 (2.1421)  loss_giou_3: 1.1750 (1.7195)  loss_ce_4: 0.7083 (0.7971)  loss_bbox_4: 1.3051 (2.1381)  loss_giou_4: 1.1442 (1.7247)  loss_ce_unscaled: 0.7048 (0.7933)  class_error_unscaled: 100.0000 (99.7034)  loss_bbox_unscaled: 0.2497 (0.4229)  loss_giou_unscaled: 0.5745 (0.8531)  cardinality_error_unscaled: 2.2500 (4.9980)  loss_ce_0_unscaled: 0.7058 (0.8367)  loss_bbox_0_unscaled: 0.2489 (0.4253)  loss_giou_0_unscaled: 0.5621 (0.8491)  cardinality_error_0_unscaled: 2.2500 (5.8629)  loss_ce_1_unscaled: 0.7152 (0.8392)  loss_bbox_1_unscaled: 0.2461 (0.4219)  loss_giou_1_unscaled: 0.5676 (0.8514)  cardinality_error_1_unscaled: 2.2500 (5.7238)  loss_ce_2_unscaled: 0.6944 (0.8214)  loss_bbox_2_unscaled: 0.2504 (0.4288)  loss_giou_2_unscaled: 0.5707 (0.8640)  cardinality_error_2_unscaled: 2.2500 (5.7213)  loss_ce_3_unscaled: 0.7048 (0.7868)  loss_bbox_3_unscaled: 0.2559 (0.4284)  loss_giou_3_unscaled: 0.5875 (0.8598)  cardinality_error_3_unscaled: 2.2500 (4.9814)  loss_ce_4_unscaled: 0.7083 (0.7971)  loss_bbox_4_unscaled: 0.2610 (0.4276)  loss_giou_4_unscaled: 0.5721 (0.8624)  cardinality_error_4_unscaled: 2.2500 (5.5726)

End of training epoch
Total execution time = 79.672 sec
Max memory used by tensors = 18468434432 bytes
Max memory cached = 21776826368 bytes
Total memory reserved = 21776826368 bytes
Total memory allocated = 773570048 bytes
Test:  [ 0/27]  eta: 0:00:28  class_error: 100.00  loss: 40.1619 (40.1619)  loss_ce: 0.6685 (0.6685)  loss_bbox: 3.7588 (3.7588)  loss_giou: 2.5980 (2.5980)  loss_ce_0: 0.6615 (0.6615)  loss_bbox_0: 2.9907 (2.9907)  loss_giou_0: 2.4221 (2.4221)  loss_ce_1: 0.6615 (0.6615)  loss_bbox_1: 2.9940 (2.9940)  loss_giou_1: 2.3859 (2.3859)  loss_ce_2: 0.6640 (0.6640)  loss_bbox_2: 3.5454 (3.5454)  loss_giou_2: 2.4860 (2.4860)  loss_ce_3: 0.6614 (0.6614)  loss_bbox_3: 3.8030 (3.8030)  loss_giou_3: 2.7062 (2.7062)  loss_ce_4: 0.6534 (0.6534)  loss_bbox_4: 3.8028 (3.8028)  loss_giou_4: 2.6986 (2.6986)  loss_ce_unscaled: 0.6685 (0.6685)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.7518 (0.7518)  loss_giou_unscaled: 1.2990 (1.2990)  cardinality_error_unscaled: 2.0000 (2.0000)  loss_ce_0_unscaled: 0.6615 (0.6615)  loss_bbox_0_unscaled: 0.5981 (0.5981)  loss_giou_0_unscaled: 1.2110 (1.2110)  cardinality_error_0_unscaled: 2.0000 (2.0000)  loss_ce_1_unscaled: 0.6615 (0.6615)  loss_bbox_1_unscaled: 0.5988 (0.5988)  loss_giou_1_unscaled: 1.1929 (1.1929)  cardinality_error_1_unscaled: 2.0000 (2.0000)  loss_ce_2_unscaled: 0.6640 (0.6640)  loss_bbox_2_unscaled: 0.7091 (0.7091)  loss_giou_2_unscaled: 1.2430 (1.2430)  cardinality_error_2_unscaled: 2.0000 (2.0000)  loss_ce_3_unscaled: 0.6614 (0.6614)  loss_bbox_3_unscaled: 0.7606 (0.7606)  loss_giou_3_unscaled: 1.3531 (1.3531)  cardinality_error_3_unscaled: 2.0000 (2.0000)  loss_ce_4_unscaled: 0.6534 (0.6534)  loss_bbox_4_unscaled: 0.7606 (0.7606)  loss_giou_4_unscaled: 1.3493 (1.3493)  cardinality_error_4_unscaled: 2.0000 (2.0000)  time: 1.0431  data: 0.8168  max mem: 17613
Test:  [10/27]  eta: 0:00:05  class_error: 100.00  loss: 37.3787 (36.8709)  loss_ce: 0.7123 (0.7171)  loss_bbox: 3.3208 (3.1093)  loss_giou: 2.5980 (2.5364)  loss_ce_0: 0.7057 (0.7100)  loss_bbox_0: 2.6827 (2.7165)  loss_giou_0: 2.3931 (2.3673)  loss_ce_1: 0.7003 (0.7053)  loss_bbox_1: 2.6728 (2.6720)  loss_giou_1: 2.3859 (2.3391)  loss_ce_2: 0.7043 (0.7063)  loss_bbox_2: 3.1850 (3.0091)  loss_giou_2: 2.4860 (2.4787)  loss_ce_3: 0.7043 (0.7047)  loss_bbox_3: 3.2384 (3.1660)  loss_giou_3: 2.7062 (2.5579)  loss_ce_4: 0.6974 (0.6983)  loss_bbox_4: 3.1709 (3.1358)  loss_giou_4: 2.6986 (2.5410)  loss_ce_unscaled: 0.7123 (0.7171)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.6642 (0.6219)  loss_giou_unscaled: 1.2990 (1.2682)  cardinality_error_unscaled: 2.2500 (2.2727)  loss_ce_0_unscaled: 0.7057 (0.7100)  loss_bbox_0_unscaled: 0.5365 (0.5433)  loss_giou_0_unscaled: 1.1966 (1.1836)  cardinality_error_0_unscaled: 2.2500 (2.2727)  loss_ce_1_unscaled: 0.7003 (0.7053)  loss_bbox_1_unscaled: 0.5346 (0.5344)  loss_giou_1_unscaled: 1.1929 (1.1695)  cardinality_error_1_unscaled: 2.2500 (2.2727)  loss_ce_2_unscaled: 0.7043 (0.7063)  loss_bbox_2_unscaled: 0.6370 (0.6018)  loss_giou_2_unscaled: 1.2430 (1.2394)  cardinality_error_2_unscaled: 2.2500 (2.2727)  loss_ce_3_unscaled: 0.7043 (0.7047)  loss_bbox_3_unscaled: 0.6477 (0.6332)  loss_giou_3_unscaled: 1.3531 (1.2790)  cardinality_error_3_unscaled: 2.2500 (2.2727)  loss_ce_4_unscaled: 0.6974 (0.6983)  loss_bbox_4_unscaled: 0.6342 (0.6272)  loss_giou_4_unscaled: 1.3493 (1.2705)  cardinality_error_4_unscaled: 2.2500 (2.2727)  time: 0.3233  data: 0.1685  max mem: 17613
Test:  [20/27]  eta: 0:00:02  class_error: 100.00  loss: 35.8330 (35.8919)  loss_ce: 0.6984 (0.7080)  loss_bbox: 2.8705 (2.9695)  loss_giou: 2.4332 (2.4774)  loss_ce_0: 0.7194 (0.7165)  loss_bbox_0: 2.6396 (2.6464)  loss_giou_0: 2.2487 (2.3495)  loss_ce_1: 0.7148 (0.7126)  loss_bbox_1: 2.6625 (2.6097)  loss_giou_1: 2.1912 (2.2999)  loss_ce_2: 0.6989 (0.7040)  loss_bbox_2: 2.7284 (2.9021)  loss_giou_2: 2.3655 (2.4203)  loss_ce_3: 0.6949 (0.7014)  loss_bbox_3: 2.9444 (3.0360)  loss_giou_3: 2.4926 (2.4792)  loss_ce_4: 0.6847 (0.6933)  loss_bbox_4: 2.9269 (2.9995)  loss_giou_4: 2.4641 (2.4667)  loss_ce_unscaled: 0.6984 (0.7080)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5741 (0.5939)  loss_giou_unscaled: 1.2166 (1.2387)  cardinality_error_unscaled: 2.2500 (2.2917)  loss_ce_0_unscaled: 0.7194 (0.7165)  loss_bbox_0_unscaled: 0.5279 (0.5293)  loss_giou_0_unscaled: 1.1243 (1.1747)  cardinality_error_0_unscaled: 2.2500 (2.2917)  loss_ce_1_unscaled: 0.7148 (0.7126)  loss_bbox_1_unscaled: 0.5325 (0.5219)  loss_giou_1_unscaled: 1.0956 (1.1499)  cardinality_error_1_unscaled: 2.2500 (2.2917)  loss_ce_2_unscaled: 0.6989 (0.7040)  loss_bbox_2_unscaled: 0.5457 (0.5804)  loss_giou_2_unscaled: 1.1827 (1.2101)  cardinality_error_2_unscaled: 2.2500 (2.2917)  loss_ce_3_unscaled: 0.6949 (0.7014)  loss_bbox_3_unscaled: 0.5889 (0.6072)  loss_giou_3_unscaled: 1.2463 (1.2396)  cardinality_error_3_unscaled: 2.2500 (2.2917)  loss_ce_4_unscaled: 0.6847 (0.6933)  loss_bbox_4_unscaled: 0.5854 (0.5999)  loss_giou_4_unscaled: 1.2320 (1.2334)  cardinality_error_4_unscaled: 2.2500 (2.2917)  time: 0.3027  data: 0.1541  max mem: 17613
Test:  [26/27]  eta: 0:00:00  class_error: 100.00  loss: 36.3016 (36.3344)  loss_ce: 0.7012 (0.7116)  loss_bbox: 2.9019 (3.0578)  loss_giou: 2.3257 (2.4471)  loss_ce_0: 0.7200 (0.7272)  loss_bbox_0: 2.6648 (2.7143)  loss_giou_0: 2.2178 (2.3096)  loss_ce_1: 0.7164 (0.7226)  loss_bbox_1: 2.6992 (2.6950)  loss_giou_1: 2.1678 (2.2419)  loss_ce_2: 0.6989 (0.7099)  loss_bbox_2: 2.8418 (3.0103)  loss_giou_2: 2.3016 (2.3900)  loss_ce_3: 0.6949 (0.7075)  loss_bbox_3: 2.9965 (3.1561)  loss_giou_3: 2.4176 (2.4612)  loss_ce_4: 0.6871 (0.6981)  loss_bbox_4: 2.9577 (3.1230)  loss_giou_4: 2.4110 (2.4510)  loss_ce_unscaled: 0.7012 (0.7116)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5804 (0.6116)  loss_giou_unscaled: 1.1629 (1.2236)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.7200 (0.7272)  loss_bbox_0_unscaled: 0.5330 (0.5429)  loss_giou_0_unscaled: 1.1089 (1.1548)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.7164 (0.7226)  loss_bbox_1_unscaled: 0.5398 (0.5390)  loss_giou_1_unscaled: 1.0839 (1.1209)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6989 (0.7099)  loss_bbox_2_unscaled: 0.5684 (0.6021)  loss_giou_2_unscaled: 1.1508 (1.1950)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6949 (0.7075)  loss_bbox_3_unscaled: 0.5993 (0.6312)  loss_giou_3_unscaled: 1.2088 (1.2306)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6871 (0.6981)  loss_bbox_4_unscaled: 0.5915 (0.6246)  loss_giou_4_unscaled: 1.2055 (1.2255)  cardinality_error_4_unscaled: 2.2500 (2.3380)  time: 0.2780  data: 0.1319  max mem: 17613
Test: Total time: 0:00:08 (0.3081 s / it)
Averaged stats: class_error: 100.00  loss: 36.3016 (36.3344)  loss_ce: 0.7012 (0.7116)  loss_bbox: 2.9019 (3.0578)  loss_giou: 2.3257 (2.4471)  loss_ce_0: 0.7200 (0.7272)  loss_bbox_0: 2.6648 (2.7143)  loss_giou_0: 2.2178 (2.3096)  loss_ce_1: 0.7164 (0.7226)  loss_bbox_1: 2.6992 (2.6950)  loss_giou_1: 2.1678 (2.2419)  loss_ce_2: 0.6989 (0.7099)  loss_bbox_2: 2.8418 (3.0103)  loss_giou_2: 2.3016 (2.3900)  loss_ce_3: 0.6949 (0.7075)  loss_bbox_3: 2.9965 (3.1561)  loss_giou_3: 2.4176 (2.4612)  loss_ce_4: 0.6871 (0.6981)  loss_bbox_4: 2.9577 (3.1230)  loss_giou_4: 2.4110 (2.4510)  loss_ce_unscaled: 0.7012 (0.7116)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5804 (0.6116)  loss_giou_unscaled: 1.1629 (1.2236)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.7200 (0.7272)  loss_bbox_0_unscaled: 0.5330 (0.5429)  loss_giou_0_unscaled: 1.1089 (1.1548)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.7164 (0.7226)  loss_bbox_1_unscaled: 0.5398 (0.5390)  loss_giou_1_unscaled: 1.0839 (1.1209)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6989 (0.7099)  loss_bbox_2_unscaled: 0.5684 (0.6021)  loss_giou_2_unscaled: 1.1508 (1.1950)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6949 (0.7075)  loss_bbox_3_unscaled: 0.5993 (0.6312)  loss_giou_3_unscaled: 1.2088 (1.2306)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6871 (0.6981)  loss_bbox_4_unscaled: 0.5915 (0.6246)  loss_giou_4_unscaled: 1.2055 (1.2255)  cardinality_error_4_unscaled: 2.2500 (2.3380)
Accumulating evaluation results...
DONE (t=0.04s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.016
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.084
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.115
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.115
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.087
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.120
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [  0/248]  eta: 0:05:42  lr: 0.000100  class_error: 100.00  loss: 21.0918 (21.0918)  loss_ce: 0.6402 (0.6402)  loss_bbox: 1.5255 (1.5255)  loss_giou: 1.2556 (1.2556)  loss_ce_0: 0.6343 (0.6343)  loss_bbox_0: 1.6051 (1.6051)  loss_giou_0: 1.4119 (1.4119)  loss_ce_1: 0.6835 (0.6835)  loss_bbox_1: 1.4229 (1.4229)  loss_giou_1: 1.2217 (1.2217)  loss_ce_2: 0.6786 (0.6786)  loss_bbox_2: 1.4168 (1.4168)  loss_giou_2: 1.2918 (1.2918)  loss_ce_3: 0.6492 (0.6492)  loss_bbox_3: 1.6536 (1.6536)  loss_giou_3: 1.4300 (1.4300)  loss_ce_4: 0.6466 (0.6466)  loss_bbox_4: 1.5701 (1.5701)  loss_giou_4: 1.3545 (1.3545)  loss_ce_unscaled: 0.6402 (0.6402)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.3051 (0.3051)  loss_giou_unscaled: 0.6278 (0.6278)  cardinality_error_unscaled: 1.8750 (1.8750)  loss_ce_0_unscaled: 0.6343 (0.6343)  loss_bbox_0_unscaled: 0.3210 (0.3210)  loss_giou_0_unscaled: 0.7059 (0.7059)  cardinality_error_0_unscaled: 1.8750 (1.8750)  loss_ce_1_unscaled: 0.6835 (0.6835)  loss_bbox_1_unscaled: 0.2846 (0.2846)  loss_giou_1_unscaled: 0.6109 (0.6109)  cardinality_error_1_unscaled: 1.8750 (1.8750)  loss_ce_2_unscaled: 0.6786 (0.6786)  loss_bbox_2_unscaled: 0.2834 (0.2834)  loss_giou_2_unscaled: 0.6459 (0.6459)  cardinality_error_2_unscaled: 1.8750 (1.8750)  loss_ce_3_unscaled: 0.6492 (0.6492)  loss_bbox_3_unscaled: 0.3307 (0.3307)  loss_giou_3_unscaled: 0.7150 (0.7150)  cardinality_error_3_unscaled: 1.8750 (1.8750)  loss_ce_4_unscaled: 0.6466 (0.6466)  loss_bbox_4_unscaled: 0.3140 (0.3140)  loss_giou_4_unscaled: 0.6772 (0.6772)  cardinality_error_4_unscaled: 1.8750 (1.8750)  time: 1.3800  data: 1.0678  max mem: 7670
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 10/248]  eta: 0:01:40  lr: 0.000100  class_error: 100.00  loss: 19.0276 (18.9727)  loss_ce: 0.7142 (0.7164)  loss_bbox: 1.3260 (1.3219)  loss_giou: 1.2556 (1.2532)  loss_ce_0: 0.7387 (0.7222)  loss_bbox_0: 1.1835 (1.2252)  loss_giou_0: 1.2513 (1.2346)  loss_ce_1: 0.7616 (0.7562)  loss_bbox_1: 1.1675 (1.2092)  loss_giou_1: 1.1503 (1.2065)  loss_ce_2: 0.7218 (0.7265)  loss_bbox_2: 1.1647 (1.1832)  loss_giou_2: 1.0708 (1.1242)  loss_ce_3: 0.7500 (0.7305)  loss_bbox_3: 1.1362 (1.2224)  loss_giou_3: 1.1853 (1.1829)  loss_ce_4: 0.7218 (0.7167)  loss_bbox_4: 1.1997 (1.2502)  loss_giou_4: 1.2027 (1.1905)  loss_ce_unscaled: 0.7142 (0.7164)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2652 (0.2644)  loss_giou_unscaled: 0.6278 (0.6266)  cardinality_error_unscaled: 2.2500 (2.3295)  loss_ce_0_unscaled: 0.7387 (0.7222)  loss_bbox_0_unscaled: 0.2367 (0.2450)  loss_giou_0_unscaled: 0.6256 (0.6173)  cardinality_error_0_unscaled: 2.2500 (2.3295)  loss_ce_1_unscaled: 0.7616 (0.7562)  loss_bbox_1_unscaled: 0.2335 (0.2418)  loss_giou_1_unscaled: 0.5751 (0.6033)  cardinality_error_1_unscaled: 2.2500 (2.3295)  loss_ce_2_unscaled: 0.7218 (0.7265)  loss_bbox_2_unscaled: 0.2329 (0.2366)  loss_giou_2_unscaled: 0.5354 (0.5621)  cardinality_error_2_unscaled: 2.2500 (2.3295)  loss_ce_3_unscaled: 0.7500 (0.7305)  loss_bbox_3_unscaled: 0.2272 (0.2445)  loss_giou_3_unscaled: 0.5927 (0.5915)  cardinality_error_3_unscaled: 2.2500 (2.3295)  loss_ce_4_unscaled: 0.7218 (0.7167)  loss_bbox_4_unscaled: 0.2399 (0.2500)  loss_giou_4_unscaled: 0.6013 (0.5953)  cardinality_error_4_unscaled: 2.2500 (2.3295)  time: 0.4206  data: 0.1221  max mem: 9416
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 20/248]  eta: 0:01:22  lr: 0.000100  class_error: 100.00  loss: 19.0124 (18.7971)  loss_ce: 0.7049 (0.6979)  loss_bbox: 1.2678 (1.2662)  loss_giou: 1.0889 (1.1759)  loss_ce_0: 0.7117 (0.7062)  loss_bbox_0: 1.2321 (1.2479)  loss_giou_0: 1.2006 (1.2100)  loss_ce_1: 0.7276 (0.7281)  loss_bbox_1: 1.1567 (1.2357)  loss_giou_1: 1.1403 (1.1893)  loss_ce_2: 0.7151 (0.7113)  loss_bbox_2: 1.1761 (1.2045)  loss_giou_2: 1.0708 (1.1379)  loss_ce_3: 0.7307 (0.7143)  loss_bbox_3: 1.1622 (1.2499)  loss_giou_3: 1.1415 (1.1633)  loss_ce_4: 0.7093 (0.7037)  loss_bbox_4: 1.2158 (1.2642)  loss_giou_4: 1.1537 (1.1908)  loss_ce_unscaled: 0.7049 (0.6979)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2536 (0.2532)  loss_giou_unscaled: 0.5444 (0.5879)  cardinality_error_unscaled: 2.2500 (2.2976)  loss_ce_0_unscaled: 0.7117 (0.7062)  loss_bbox_0_unscaled: 0.2464 (0.2496)  loss_giou_0_unscaled: 0.6003 (0.6050)  cardinality_error_0_unscaled: 2.2500 (2.2976)  loss_ce_1_unscaled: 0.7276 (0.7281)  loss_bbox_1_unscaled: 0.2313 (0.2471)  loss_giou_1_unscaled: 0.5702 (0.5947)  cardinality_error_1_unscaled: 2.2500 (2.2976)  loss_ce_2_unscaled: 0.7151 (0.7113)  loss_bbox_2_unscaled: 0.2352 (0.2409)  loss_giou_2_unscaled: 0.5354 (0.5690)  cardinality_error_2_unscaled: 2.2500 (2.2976)  loss_ce_3_unscaled: 0.7307 (0.7143)  loss_bbox_3_unscaled: 0.2324 (0.2500)  loss_giou_3_unscaled: 0.5707 (0.5816)  cardinality_error_3_unscaled: 2.2500 (2.2976)  loss_ce_4_unscaled: 0.7093 (0.7037)  loss_bbox_4_unscaled: 0.2432 (0.2528)  loss_giou_4_unscaled: 0.5768 (0.5954)  cardinality_error_4_unscaled: 2.2500 (2.2976)  time: 0.3127  data: 0.0284  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 30/248]  eta: 0:01:18  lr: 0.000100  class_error: 100.00  loss: 19.2394 (19.2193)  loss_ce: 0.6824 (0.7102)  loss_bbox: 1.2848 (1.3459)  loss_giou: 1.1398 (1.2144)  loss_ce_0: 0.7117 (0.7125)  loss_bbox_0: 1.2820 (1.2551)  loss_giou_0: 1.1566 (1.1769)  loss_ce_1: 0.7013 (0.7265)  loss_bbox_1: 1.2392 (1.2648)  loss_giou_1: 1.0975 (1.1644)  loss_ce_2: 0.7117 (0.7134)  loss_bbox_2: 1.2768 (1.2806)  loss_giou_2: 1.1425 (1.1565)  loss_ce_3: 0.7090 (0.7171)  loss_bbox_3: 1.3322 (1.3131)  loss_giou_3: 1.1197 (1.1761)  loss_ce_4: 0.6857 (0.7156)  loss_bbox_4: 1.3971 (1.3558)  loss_giou_4: 1.1910 (1.2204)  loss_ce_unscaled: 0.6824 (0.7102)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2570 (0.2692)  loss_giou_unscaled: 0.5699 (0.6072)  cardinality_error_unscaled: 2.2500 (2.3306)  loss_ce_0_unscaled: 0.7117 (0.7125)  loss_bbox_0_unscaled: 0.2564 (0.2510)  loss_giou_0_unscaled: 0.5783 (0.5884)  cardinality_error_0_unscaled: 2.2500 (2.3266)  loss_ce_1_unscaled: 0.7013 (0.7265)  loss_bbox_1_unscaled: 0.2478 (0.2530)  loss_giou_1_unscaled: 0.5487 (0.5822)  cardinality_error_1_unscaled: 2.2500 (2.3306)  loss_ce_2_unscaled: 0.7117 (0.7134)  loss_bbox_2_unscaled: 0.2554 (0.2561)  loss_giou_2_unscaled: 0.5712 (0.5783)  cardinality_error_2_unscaled: 2.2500 (2.3306)  loss_ce_3_unscaled: 0.7090 (0.7171)  loss_bbox_3_unscaled: 0.2664 (0.2626)  loss_giou_3_unscaled: 0.5598 (0.5880)  cardinality_error_3_unscaled: 2.2500 (2.3306)  loss_ce_4_unscaled: 0.6857 (0.7156)  loss_bbox_4_unscaled: 0.2794 (0.2712)  loss_giou_4_unscaled: 0.5955 (0.6102)  cardinality_error_4_unscaled: 2.2500 (2.3306)  time: 0.3296  data: 0.0293  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 40/248]  eta: 0:01:13  lr: 0.000100  class_error: 100.00  loss: 19.2317 (19.2620)  loss_ce: 0.6817 (0.7011)  loss_bbox: 1.4309 (1.4034)  loss_giou: 1.1977 (1.2207)  loss_ce_0: 0.6965 (0.7038)  loss_bbox_0: 1.3569 (1.2957)  loss_giou_0: 1.1375 (1.1672)  loss_ce_1: 0.7283 (0.7303)  loss_bbox_1: 1.2524 (1.2762)  loss_giou_1: 1.0714 (1.1334)  loss_ce_2: 0.6974 (0.7052)  loss_bbox_2: 1.3480 (1.3138)  loss_giou_2: 1.0980 (1.1468)  loss_ce_3: 0.6864 (0.7070)  loss_bbox_3: 1.3156 (1.3339)  loss_giou_3: 1.0601 (1.1534)  loss_ce_4: 0.6756 (0.7036)  loss_bbox_4: 1.4593 (1.3711)  loss_giou_4: 1.1542 (1.1952)  loss_ce_unscaled: 0.6817 (0.7011)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2862 (0.2807)  loss_giou_unscaled: 0.5988 (0.6104)  cardinality_error_unscaled: 2.1250 (2.2622)  loss_ce_0_unscaled: 0.6965 (0.7038)  loss_bbox_0_unscaled: 0.2714 (0.2591)  loss_giou_0_unscaled: 0.5687 (0.5836)  cardinality_error_0_unscaled: 2.1250 (2.2500)  loss_ce_1_unscaled: 0.7283 (0.7303)  loss_bbox_1_unscaled: 0.2505 (0.2552)  loss_giou_1_unscaled: 0.5357 (0.5667)  cardinality_error_1_unscaled: 2.1250 (2.2622)  loss_ce_2_unscaled: 0.6974 (0.7052)  loss_bbox_2_unscaled: 0.2696 (0.2628)  loss_giou_2_unscaled: 0.5490 (0.5734)  cardinality_error_2_unscaled: 2.1250 (2.2622)  loss_ce_3_unscaled: 0.6864 (0.7070)  loss_bbox_3_unscaled: 0.2631 (0.2668)  loss_giou_3_unscaled: 0.5300 (0.5767)  cardinality_error_3_unscaled: 2.1250 (2.2622)  loss_ce_4_unscaled: 0.6756 (0.7036)  loss_bbox_4_unscaled: 0.2919 (0.2742)  loss_giou_4_unscaled: 0.5771 (0.5976)  cardinality_error_4_unscaled: 2.1250 (2.2622)  time: 0.3450  data: 0.0294  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 50/248]  eta: 0:01:08  lr: 0.000100  class_error: 100.00  loss: 18.3087 (19.0924)  loss_ce: 0.6675 (0.6979)  loss_bbox: 1.4131 (1.3942)  loss_giou: 1.1601 (1.2223)  loss_ce_0: 0.6787 (0.6970)  loss_bbox_0: 1.2943 (1.2804)  loss_giou_0: 1.1624 (1.1698)  loss_ce_1: 0.7196 (0.7270)  loss_bbox_1: 1.1886 (1.2515)  loss_giou_1: 1.0478 (1.1291)  loss_ce_2: 0.6786 (0.7011)  loss_bbox_2: 1.2244 (1.2939)  loss_giou_2: 1.0323 (1.1433)  loss_ce_3: 0.6802 (0.7066)  loss_bbox_3: 1.2379 (1.3053)  loss_giou_3: 1.0598 (1.1504)  loss_ce_4: 0.6612 (0.6992)  loss_bbox_4: 1.2554 (1.3416)  loss_giou_4: 1.1044 (1.1818)  loss_ce_unscaled: 0.6675 (0.6979)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2826 (0.2788)  loss_giou_unscaled: 0.5800 (0.6111)  cardinality_error_unscaled: 2.0000 (2.2426)  loss_ce_0_unscaled: 0.6787 (0.6970)  loss_bbox_0_unscaled: 0.2589 (0.2561)  loss_giou_0_unscaled: 0.5812 (0.5849)  cardinality_error_0_unscaled: 2.0000 (2.2328)  loss_ce_1_unscaled: 0.7196 (0.7270)  loss_bbox_1_unscaled: 0.2377 (0.2503)  loss_giou_1_unscaled: 0.5239 (0.5646)  cardinality_error_1_unscaled: 2.0000 (2.2426)  loss_ce_2_unscaled: 0.6786 (0.7011)  loss_bbox_2_unscaled: 0.2449 (0.2588)  loss_giou_2_unscaled: 0.5162 (0.5716)  cardinality_error_2_unscaled: 2.0000 (2.2426)  loss_ce_3_unscaled: 0.6802 (0.7066)  loss_bbox_3_unscaled: 0.2476 (0.2611)  loss_giou_3_unscaled: 0.5299 (0.5752)  cardinality_error_3_unscaled: 2.0000 (2.2426)  loss_ce_4_unscaled: 0.6612 (0.6992)  loss_bbox_4_unscaled: 0.2511 (0.2683)  loss_giou_4_unscaled: 0.5522 (0.5909)  cardinality_error_4_unscaled: 2.0000 (2.2426)  time: 0.3181  data: 0.0293  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 60/248]  eta: 0:01:03  lr: 0.000100  class_error: 100.00  loss: 18.7328 (19.2479)  loss_ce: 0.6951 (0.6982)  loss_bbox: 1.4131 (1.3874)  loss_giou: 1.2325 (1.2293)  loss_ce_0: 0.6915 (0.6981)  loss_bbox_0: 1.2349 (1.2844)  loss_giou_0: 1.2202 (1.1857)  loss_ce_1: 0.7039 (0.7223)  loss_bbox_1: 1.2424 (1.2741)  loss_giou_1: 1.1755 (1.1600)  loss_ce_2: 0.6887 (0.7005)  loss_bbox_2: 1.2615 (1.3256)  loss_giou_2: 1.1259 (1.1772)  loss_ce_3: 0.7160 (0.7101)  loss_bbox_3: 1.1808 (1.3101)  loss_giou_3: 1.1473 (1.1636)  loss_ce_4: 0.7056 (0.7008)  loss_bbox_4: 1.1832 (1.3338)  loss_giou_4: 1.1563 (1.1868)  loss_ce_unscaled: 0.6951 (0.6982)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2826 (0.2775)  loss_giou_unscaled: 0.6163 (0.6146)  cardinality_error_unscaled: 2.2500 (2.2684)  loss_ce_0_unscaled: 0.6915 (0.6981)  loss_bbox_0_unscaled: 0.2470 (0.2569)  loss_giou_0_unscaled: 0.6101 (0.5929)  cardinality_error_0_unscaled: 2.2500 (2.2602)  loss_ce_1_unscaled: 0.7039 (0.7223)  loss_bbox_1_unscaled: 0.2485 (0.2548)  loss_giou_1_unscaled: 0.5878 (0.5800)  cardinality_error_1_unscaled: 2.2500 (2.2684)  loss_ce_2_unscaled: 0.6887 (0.7005)  loss_bbox_2_unscaled: 0.2523 (0.2651)  loss_giou_2_unscaled: 0.5630 (0.5886)  cardinality_error_2_unscaled: 2.2500 (2.2684)  loss_ce_3_unscaled: 0.7160 (0.7101)  loss_bbox_3_unscaled: 0.2362 (0.2620)  loss_giou_3_unscaled: 0.5737 (0.5818)  cardinality_error_3_unscaled: 2.2500 (2.2684)  loss_ce_4_unscaled: 0.7056 (0.7008)  loss_bbox_4_unscaled: 0.2366 (0.2668)  loss_giou_4_unscaled: 0.5782 (0.5934)  cardinality_error_4_unscaled: 2.2500 (2.2684)  time: 0.3021  data: 0.0292  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 70/248]  eta: 0:00:59  lr: 0.000100  class_error: 100.00  loss: 19.1171 (19.1830)  loss_ce: 0.6919 (0.6952)  loss_bbox: 1.2496 (1.3645)  loss_giou: 1.2067 (1.2140)  loss_ce_0: 0.7008 (0.6988)  loss_bbox_0: 1.2982 (1.2869)  loss_giou_0: 1.2202 (1.1945)  loss_ce_1: 0.7025 (0.7195)  loss_bbox_1: 1.2892 (1.2745)  loss_giou_1: 1.2298 (1.1595)  loss_ce_2: 0.6932 (0.6987)  loss_bbox_2: 1.3181 (1.3235)  loss_giou_2: 1.2785 (1.1823)  loss_ce_3: 0.7152 (0.7077)  loss_bbox_3: 1.2594 (1.3026)  loss_giou_3: 1.1314 (1.1578)  loss_ce_4: 0.7056 (0.6984)  loss_bbox_4: 1.1832 (1.3224)  loss_giou_4: 1.1834 (1.1823)  loss_ce_unscaled: 0.6919 (0.6952)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2499 (0.2729)  loss_giou_unscaled: 0.6034 (0.6070)  cardinality_error_unscaled: 2.3750 (2.2764)  loss_ce_0_unscaled: 0.7008 (0.6988)  loss_bbox_0_unscaled: 0.2596 (0.2574)  loss_giou_0_unscaled: 0.6101 (0.5972)  cardinality_error_0_unscaled: 2.3750 (2.2676)  loss_ce_1_unscaled: 0.7025 (0.7195)  loss_bbox_1_unscaled: 0.2578 (0.2549)  loss_giou_1_unscaled: 0.6149 (0.5797)  cardinality_error_1_unscaled: 2.3750 (2.2746)  loss_ce_2_unscaled: 0.6932 (0.6987)  loss_bbox_2_unscaled: 0.2636 (0.2647)  loss_giou_2_unscaled: 0.6392 (0.5912)  cardinality_error_2_unscaled: 2.3750 (2.2764)  loss_ce_3_unscaled: 0.7152 (0.7077)  loss_bbox_3_unscaled: 0.2519 (0.2605)  loss_giou_3_unscaled: 0.5657 (0.5789)  cardinality_error_3_unscaled: 2.3750 (2.2764)  loss_ce_4_unscaled: 0.7056 (0.6984)  loss_bbox_4_unscaled: 0.2366 (0.2645)  loss_giou_4_unscaled: 0.5917 (0.5911)  cardinality_error_4_unscaled: 2.3750 (2.2764)  time: 0.2988  data: 0.0285  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 80/248]  eta: 0:00:55  lr: 0.000100  class_error: 100.00  loss: 19.0811 (19.1258)  loss_ce: 0.6765 (0.6931)  loss_bbox: 1.2852 (1.3597)  loss_giou: 1.1219 (1.2070)  loss_ce_0: 0.6938 (0.6989)  loss_bbox_0: 1.3006 (1.2874)  loss_giou_0: 1.2088 (1.1950)  loss_ce_1: 0.6918 (0.7195)  loss_bbox_1: 1.2808 (1.2722)  loss_giou_1: 1.1265 (1.1567)  loss_ce_2: 0.6811 (0.6969)  loss_bbox_2: 1.2529 (1.3158)  loss_giou_2: 1.1157 (1.1771)  loss_ce_3: 0.6816 (0.7042)  loss_bbox_3: 1.2264 (1.2967)  loss_giou_3: 1.1116 (1.1520)  loss_ce_4: 0.6801 (0.6966)  loss_bbox_4: 1.3462 (1.3216)  loss_giou_4: 1.1147 (1.1755)  loss_ce_unscaled: 0.6765 (0.6931)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2570 (0.2719)  loss_giou_unscaled: 0.5610 (0.6035)  cardinality_error_unscaled: 2.2500 (2.2685)  loss_ce_0_unscaled: 0.6938 (0.6989)  loss_bbox_0_unscaled: 0.2601 (0.2575)  loss_giou_0_unscaled: 0.6044 (0.5975)  cardinality_error_0_unscaled: 2.2500 (2.2469)  loss_ce_1_unscaled: 0.6918 (0.7195)  loss_bbox_1_unscaled: 0.2562 (0.2544)  loss_giou_1_unscaled: 0.5633 (0.5783)  cardinality_error_1_unscaled: 2.2500 (2.2593)  loss_ce_2_unscaled: 0.6811 (0.6969)  loss_bbox_2_unscaled: 0.2506 (0.2632)  loss_giou_2_unscaled: 0.5578 (0.5885)  cardinality_error_2_unscaled: 2.2500 (2.2670)  loss_ce_3_unscaled: 0.6816 (0.7042)  loss_bbox_3_unscaled: 0.2453 (0.2593)  loss_giou_3_unscaled: 0.5558 (0.5760)  cardinality_error_3_unscaled: 2.2500 (2.2685)  loss_ce_4_unscaled: 0.6801 (0.6966)  loss_bbox_4_unscaled: 0.2692 (0.2643)  loss_giou_4_unscaled: 0.5574 (0.5877)  cardinality_error_4_unscaled: 2.2500 (2.2685)  time: 0.3108  data: 0.0418  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 90/248]  eta: 0:00:51  lr: 0.000100  class_error: 100.00  loss: 19.2965 (19.1390)  loss_ce: 0.6812 (0.6945)  loss_bbox: 1.3738 (1.3727)  loss_giou: 1.1939 (1.2075)  loss_ce_0: 0.6965 (0.7009)  loss_bbox_0: 1.2827 (1.2847)  loss_giou_0: 1.2058 (1.1909)  loss_ce_1: 0.7099 (0.7187)  loss_bbox_1: 1.2849 (1.2813)  loss_giou_1: 1.1738 (1.1633)  loss_ce_2: 0.6859 (0.6971)  loss_bbox_2: 1.2853 (1.3120)  loss_giou_2: 1.1080 (1.1691)  loss_ce_3: 0.6870 (0.7043)  loss_bbox_3: 1.2649 (1.2977)  loss_giou_3: 1.1279 (1.1520)  loss_ce_4: 0.6965 (0.6977)  loss_bbox_4: 1.3198 (1.3225)  loss_giou_4: 1.1570 (1.1722)  loss_ce_unscaled: 0.6812 (0.6945)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2748 (0.2745)  loss_giou_unscaled: 0.5969 (0.6038)  cardinality_error_unscaled: 2.2500 (2.2761)  loss_ce_0_unscaled: 0.6965 (0.7009)  loss_bbox_0_unscaled: 0.2565 (0.2569)  loss_giou_0_unscaled: 0.6029 (0.5955)  cardinality_error_0_unscaled: 2.1250 (2.2555)  loss_ce_1_unscaled: 0.7099 (0.7187)  loss_bbox_1_unscaled: 0.2570 (0.2563)  loss_giou_1_unscaled: 0.5869 (0.5817)  cardinality_error_1_unscaled: 2.2500 (2.2679)  loss_ce_2_unscaled: 0.6859 (0.6971)  loss_bbox_2_unscaled: 0.2571 (0.2624)  loss_giou_2_unscaled: 0.5540 (0.5845)  cardinality_error_2_unscaled: 2.2500 (2.2747)  loss_ce_3_unscaled: 0.6870 (0.7043)  loss_bbox_3_unscaled: 0.2530 (0.2595)  loss_giou_3_unscaled: 0.5639 (0.5760)  cardinality_error_3_unscaled: 2.2500 (2.2761)  loss_ce_4_unscaled: 0.6965 (0.6977)  loss_bbox_4_unscaled: 0.2640 (0.2645)  loss_giou_4_unscaled: 0.5785 (0.5861)  cardinality_error_4_unscaled: 2.2500 (2.2761)  time: 0.3189  data: 0.0423  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [100/248]  eta: 0:00:48  lr: 0.000100  class_error: 100.00  loss: 19.0553 (19.0890)  loss_ce: 0.6979 (0.6930)  loss_bbox: 1.2625 (1.3595)  loss_giou: 1.1258 (1.1978)  loss_ce_0: 0.6952 (0.6986)  loss_bbox_0: 1.2448 (1.2867)  loss_giou_0: 1.1542 (1.1935)  loss_ce_1: 0.6981 (0.7157)  loss_bbox_1: 1.3597 (1.2911)  loss_giou_1: 1.2478 (1.1665)  loss_ce_2: 0.6796 (0.6942)  loss_bbox_2: 1.2960 (1.3170)  loss_giou_2: 1.1189 (1.1767)  loss_ce_3: 0.6876 (0.7015)  loss_bbox_3: 1.2144 (1.2838)  loss_giou_3: 1.1265 (1.1421)  loss_ce_4: 0.6881 (0.6958)  loss_bbox_4: 1.2171 (1.3113)  loss_giou_4: 1.1735 (1.1646)  loss_ce_unscaled: 0.6979 (0.6930)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2525 (0.2719)  loss_giou_unscaled: 0.5629 (0.5989)  cardinality_error_unscaled: 2.2500 (2.2748)  loss_ce_0_unscaled: 0.6952 (0.6986)  loss_bbox_0_unscaled: 0.2490 (0.2573)  loss_giou_0_unscaled: 0.5771 (0.5967)  cardinality_error_0_unscaled: 2.2500 (2.2562)  loss_ce_1_unscaled: 0.6981 (0.7157)  loss_bbox_1_unscaled: 0.2719 (0.2582)  loss_giou_1_unscaled: 0.6239 (0.5832)  cardinality_error_1_unscaled: 2.2500 (2.2673)  loss_ce_2_unscaled: 0.6796 (0.6942)  loss_bbox_2_unscaled: 0.2592 (0.2634)  loss_giou_2_unscaled: 0.5595 (0.5883)  cardinality_error_2_unscaled: 2.2500 (2.2735)  loss_ce_3_unscaled: 0.6876 (0.7015)  loss_bbox_3_unscaled: 0.2429 (0.2568)  loss_giou_3_unscaled: 0.5632 (0.5710)  cardinality_error_3_unscaled: 2.2500 (2.2748)  loss_ce_4_unscaled: 0.6881 (0.6958)  loss_bbox_4_unscaled: 0.2434 (0.2623)  loss_giou_4_unscaled: 0.5867 (0.5823)  cardinality_error_4_unscaled: 2.2500 (2.2748)  time: 0.3125  data: 0.0289  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [110/248]  eta: 0:00:45  lr: 0.000100  class_error: 100.00  loss: 17.9184 (19.0076)  loss_ce: 0.6827 (0.6927)  loss_bbox: 1.2390 (1.3427)  loss_giou: 1.1244 (1.1960)  loss_ce_0: 0.6949 (0.7010)  loss_bbox_0: 1.2058 (1.2776)  loss_giou_0: 1.2261 (1.1982)  loss_ce_1: 0.7076 (0.7177)  loss_bbox_1: 1.2420 (1.2756)  loss_giou_1: 1.1355 (1.1661)  loss_ce_2: 0.6836 (0.6962)  loss_bbox_2: 1.2311 (1.3006)  loss_giou_2: 1.1647 (1.1744)  loss_ce_3: 0.6876 (0.7013)  loss_bbox_3: 1.1823 (1.2710)  loss_giou_3: 1.0836 (1.1422)  loss_ce_4: 0.6845 (0.6969)  loss_bbox_4: 1.1441 (1.2967)  loss_giou_4: 1.1094 (1.1607)  loss_ce_unscaled: 0.6827 (0.6927)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2478 (0.2685)  loss_giou_unscaled: 0.5622 (0.5980)  cardinality_error_unscaled: 2.2500 (2.2872)  loss_ce_0_unscaled: 0.6949 (0.7010)  loss_bbox_0_unscaled: 0.2412 (0.2555)  loss_giou_0_unscaled: 0.6131 (0.5991)  cardinality_error_0_unscaled: 2.2500 (2.2680)  loss_ce_1_unscaled: 0.7076 (0.7177)  loss_bbox_1_unscaled: 0.2484 (0.2551)  loss_giou_1_unscaled: 0.5677 (0.5830)  cardinality_error_1_unscaled: 2.2500 (2.2804)  loss_ce_2_unscaled: 0.6836 (0.6962)  loss_bbox_2_unscaled: 0.2462 (0.2601)  loss_giou_2_unscaled: 0.5824 (0.5872)  cardinality_error_2_unscaled: 2.2500 (2.2838)  loss_ce_3_unscaled: 0.6876 (0.7013)  loss_bbox_3_unscaled: 0.2365 (0.2542)  loss_giou_3_unscaled: 0.5418 (0.5711)  cardinality_error_3_unscaled: 2.2500 (2.2872)  loss_ce_4_unscaled: 0.6845 (0.6969)  loss_bbox_4_unscaled: 0.2288 (0.2593)  loss_giou_4_unscaled: 0.5547 (0.5804)  cardinality_error_4_unscaled: 2.2500 (2.2872)  time: 0.3296  data: 0.0299  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [120/248]  eta: 0:00:42  lr: 0.000100  class_error: 100.00  loss: 17.9195 (18.9201)  loss_ce: 0.6733 (0.6908)  loss_bbox: 1.2390 (1.3387)  loss_giou: 1.1722 (1.1959)  loss_ce_0: 0.7006 (0.7003)  loss_bbox_0: 1.1241 (1.2665)  loss_giou_0: 1.1721 (1.1927)  loss_ce_1: 0.7221 (0.7170)  loss_bbox_1: 1.1349 (1.2665)  loss_giou_1: 1.1391 (1.1622)  loss_ce_2: 0.6898 (0.6949)  loss_bbox_2: 1.1366 (1.2883)  loss_giou_2: 1.1016 (1.1662)  loss_ce_3: 0.6966 (0.7000)  loss_bbox_3: 1.1205 (1.2609)  loss_giou_3: 1.1319 (1.1382)  loss_ce_4: 0.6845 (0.6958)  loss_bbox_4: 1.0409 (1.2878)  loss_giou_4: 1.1608 (1.1574)  loss_ce_unscaled: 0.6733 (0.6908)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2478 (0.2677)  loss_giou_unscaled: 0.5861 (0.5980)  cardinality_error_unscaled: 2.2500 (2.2810)  loss_ce_0_unscaled: 0.7006 (0.7003)  loss_bbox_0_unscaled: 0.2248 (0.2533)  loss_giou_0_unscaled: 0.5861 (0.5964)  cardinality_error_0_unscaled: 2.2500 (2.2624)  loss_ce_1_unscaled: 0.7221 (0.7170)  loss_bbox_1_unscaled: 0.2270 (0.2533)  loss_giou_1_unscaled: 0.5696 (0.5811)  cardinality_error_1_unscaled: 2.2500 (2.2748)  loss_ce_2_unscaled: 0.6898 (0.6949)  loss_bbox_2_unscaled: 0.2273 (0.2577)  loss_giou_2_unscaled: 0.5508 (0.5831)  cardinality_error_2_unscaled: 2.2500 (2.2769)  loss_ce_3_unscaled: 0.6966 (0.7000)  loss_bbox_3_unscaled: 0.2241 (0.2522)  loss_giou_3_unscaled: 0.5660 (0.5691)  cardinality_error_3_unscaled: 2.2500 (2.2810)  loss_ce_4_unscaled: 0.6845 (0.6958)  loss_bbox_4_unscaled: 0.2082 (0.2576)  loss_giou_4_unscaled: 0.5804 (0.5787)  cardinality_error_4_unscaled: 2.2500 (2.2810)  time: 0.3382  data: 0.0438  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [130/248]  eta: 0:00:38  lr: 0.000100  class_error: 100.00  loss: 17.0819 (18.7684)  loss_ce: 0.6713 (0.6898)  loss_bbox: 1.1435 (1.3185)  loss_giou: 1.1722 (1.1898)  loss_ce_0: 0.6863 (0.6994)  loss_bbox_0: 1.0490 (1.2481)  loss_giou_0: 1.1108 (1.1835)  loss_ce_1: 0.6936 (0.7146)  loss_bbox_1: 1.1368 (1.2545)  loss_giou_1: 1.1236 (1.1602)  loss_ce_2: 0.6752 (0.6937)  loss_bbox_2: 1.0560 (1.2706)  loss_giou_2: 1.0803 (1.1606)  loss_ce_3: 0.6784 (0.6980)  loss_bbox_3: 1.0651 (1.2429)  loss_giou_3: 1.0460 (1.1307)  loss_ce_4: 0.6776 (0.6944)  loss_bbox_4: 1.0409 (1.2682)  loss_giou_4: 1.1027 (1.1510)  loss_ce_unscaled: 0.6713 (0.6898)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2287 (0.2637)  loss_giou_unscaled: 0.5861 (0.5949)  cardinality_error_unscaled: 2.2500 (2.2777)  loss_ce_0_unscaled: 0.6863 (0.6994)  loss_bbox_0_unscaled: 0.2098 (0.2496)  loss_giou_0_unscaled: 0.5554 (0.5917)  cardinality_error_0_unscaled: 2.2500 (2.2595)  loss_ce_1_unscaled: 0.6936 (0.7146)  loss_bbox_1_unscaled: 0.2274 (0.2509)  loss_giou_1_unscaled: 0.5618 (0.5801)  cardinality_error_1_unscaled: 2.2500 (2.2719)  loss_ce_2_unscaled: 0.6752 (0.6937)  loss_bbox_2_unscaled: 0.2112 (0.2541)  loss_giou_2_unscaled: 0.5401 (0.5803)  cardinality_error_2_unscaled: 2.2500 (2.2739)  loss_ce_3_unscaled: 0.6784 (0.6980)  loss_bbox_3_unscaled: 0.2130 (0.2486)  loss_giou_3_unscaled: 0.5230 (0.5654)  cardinality_error_3_unscaled: 2.2500 (2.2777)  loss_ce_4_unscaled: 0.6776 (0.6944)  loss_bbox_4_unscaled: 0.2082 (0.2536)  loss_giou_4_unscaled: 0.5513 (0.5755)  cardinality_error_4_unscaled: 2.2500 (2.2777)  time: 0.3288  data: 0.0429  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [140/248]  eta: 0:00:35  lr: 0.000100  class_error: 100.00  loss: 17.2652 (18.7846)  loss_ce: 0.6743 (0.6890)  loss_bbox: 1.1741 (1.3219)  loss_giou: 1.1814 (1.1961)  loss_ce_0: 0.6744 (0.6971)  loss_bbox_0: 1.1010 (1.2496)  loss_giou_0: 1.1790 (1.1875)  loss_ce_1: 0.6854 (0.7128)  loss_bbox_1: 1.1196 (1.2514)  loss_giou_1: 1.1236 (1.1623)  loss_ce_2: 0.6611 (0.6920)  loss_bbox_2: 1.1187 (1.2712)  loss_giou_2: 1.1652 (1.1663)  loss_ce_3: 0.6673 (0.6953)  loss_bbox_3: 1.0949 (1.2437)  loss_giou_3: 1.0901 (1.1359)  loss_ce_4: 0.6690 (0.6922)  loss_bbox_4: 1.1233 (1.2676)  loss_giou_4: 1.1046 (1.1527)  loss_ce_unscaled: 0.6743 (0.6890)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2348 (0.2644)  loss_giou_unscaled: 0.5907 (0.5981)  cardinality_error_unscaled: 2.2500 (2.2686)  loss_ce_0_unscaled: 0.6744 (0.6971)  loss_bbox_0_unscaled: 0.2202 (0.2499)  loss_giou_0_unscaled: 0.5895 (0.5938)  cardinality_error_0_unscaled: 2.1250 (2.2509)  loss_ce_1_unscaled: 0.6854 (0.7128)  loss_bbox_1_unscaled: 0.2239 (0.2503)  loss_giou_1_unscaled: 0.5618 (0.5811)  cardinality_error_1_unscaled: 2.2500 (2.2633)  loss_ce_2_unscaled: 0.6611 (0.6920)  loss_bbox_2_unscaled: 0.2237 (0.2542)  loss_giou_2_unscaled: 0.5826 (0.5831)  cardinality_error_2_unscaled: 2.2500 (2.2651)  loss_ce_3_unscaled: 0.6673 (0.6953)  loss_bbox_3_unscaled: 0.2190 (0.2487)  loss_giou_3_unscaled: 0.5450 (0.5680)  cardinality_error_3_unscaled: 2.2500 (2.2686)  loss_ce_4_unscaled: 0.6690 (0.6922)  loss_bbox_4_unscaled: 0.2247 (0.2535)  loss_giou_4_unscaled: 0.5523 (0.5763)  cardinality_error_4_unscaled: 2.2500 (2.2686)  time: 0.3206  data: 0.0321  max mem: 13753
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [150/248]  eta: 0:00:32  lr: 0.000100  class_error: 100.00  loss: 18.8273 (18.8064)  loss_ce: 0.6955 (0.6902)  loss_bbox: 1.3312 (1.3216)  loss_giou: 1.1578 (1.1892)  loss_ce_0: 0.6845 (0.6974)  loss_bbox_0: 1.2255 (1.2520)  loss_giou_0: 1.1564 (1.1841)  loss_ce_1: 0.6953 (0.7118)  loss_bbox_1: 1.1860 (1.2563)  loss_giou_1: 1.1751 (1.1613)  loss_ce_2: 0.6816 (0.6921)  loss_bbox_2: 1.2381 (1.2749)  loss_giou_2: 1.2101 (1.1662)  loss_ce_3: 0.6814 (0.6957)  loss_bbox_3: 1.2838 (1.2505)  loss_giou_3: 1.1707 (1.1377)  loss_ce_4: 0.6857 (0.6931)  loss_bbox_4: 1.2697 (1.2762)  loss_giou_4: 1.1679 (1.1559)  loss_ce_unscaled: 0.6955 (0.6902)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2662 (0.2643)  loss_giou_unscaled: 0.5789 (0.5946)  cardinality_error_unscaled: 2.2500 (2.2765)  loss_ce_0_unscaled: 0.6845 (0.6974)  loss_bbox_0_unscaled: 0.2451 (0.2504)  loss_giou_0_unscaled: 0.5782 (0.5920)  cardinality_error_0_unscaled: 2.2500 (2.2599)  loss_ce_1_unscaled: 0.6953 (0.7118)  loss_bbox_1_unscaled: 0.2372 (0.2513)  loss_giou_1_unscaled: 0.5876 (0.5807)  cardinality_error_1_unscaled: 2.2500 (2.2715)  loss_ce_2_unscaled: 0.6816 (0.6921)  loss_bbox_2_unscaled: 0.2476 (0.2550)  loss_giou_2_unscaled: 0.6051 (0.5831)  cardinality_error_2_unscaled: 2.2500 (2.2732)  loss_ce_3_unscaled: 0.6814 (0.6957)  loss_bbox_3_unscaled: 0.2568 (0.2501)  loss_giou_3_unscaled: 0.5853 (0.5689)  cardinality_error_3_unscaled: 2.2500 (2.2765)  loss_ce_4_unscaled: 0.6857 (0.6931)  loss_bbox_4_unscaled: 0.2539 (0.2552)  loss_giou_4_unscaled: 0.5839 (0.5779)  cardinality_error_4_unscaled: 2.2500 (2.2765)  time: 0.3327  data: 0.0338  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [160/248]  eta: 0:00:29  lr: 0.000100  class_error: 100.00  loss: 18.5856 (18.7971)  loss_ce: 0.6886 (0.6876)  loss_bbox: 1.2541 (1.3184)  loss_giou: 1.0937 (1.1833)  loss_ce_0: 0.6696 (0.6942)  loss_bbox_0: 1.2942 (1.2529)  loss_giou_0: 1.1244 (1.1812)  loss_ce_1: 0.6573 (0.7079)  loss_bbox_1: 1.2525 (1.2556)  loss_giou_1: 1.1290 (1.1594)  loss_ce_2: 0.6577 (0.6892)  loss_bbox_2: 1.3686 (1.2820)  loss_giou_2: 1.2101 (1.1731)  loss_ce_3: 0.6881 (0.6941)  loss_bbox_3: 1.2509 (1.2555)  loss_giou_3: 1.1529 (1.1418)  loss_ce_4: 0.6732 (0.6907)  loss_bbox_4: 1.2697 (1.2754)  loss_giou_4: 1.1475 (1.1548)  loss_ce_unscaled: 0.6886 (0.6876)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2508 (0.2637)  loss_giou_unscaled: 0.5468 (0.5916)  cardinality_error_unscaled: 2.2500 (2.2632)  loss_ce_0_unscaled: 0.6696 (0.6942)  loss_bbox_0_unscaled: 0.2588 (0.2506)  loss_giou_0_unscaled: 0.5622 (0.5906)  cardinality_error_0_unscaled: 2.2500 (2.2477)  loss_ce_1_unscaled: 0.6573 (0.7079)  loss_bbox_1_unscaled: 0.2505 (0.2511)  loss_giou_1_unscaled: 0.5645 (0.5797)  cardinality_error_1_unscaled: 2.2500 (2.2585)  loss_ce_2_unscaled: 0.6577 (0.6892)  loss_bbox_2_unscaled: 0.2737 (0.2564)  loss_giou_2_unscaled: 0.6051 (0.5866)  cardinality_error_2_unscaled: 2.2500 (2.2601)  loss_ce_3_unscaled: 0.6881 (0.6941)  loss_bbox_3_unscaled: 0.2502 (0.2511)  loss_giou_3_unscaled: 0.5765 (0.5709)  cardinality_error_3_unscaled: 2.2500 (2.2632)  loss_ce_4_unscaled: 0.6732 (0.6907)  loss_bbox_4_unscaled: 0.2539 (0.2551)  loss_giou_4_unscaled: 0.5737 (0.5774)  cardinality_error_4_unscaled: 2.2500 (2.2632)  time: 0.3587  data: 0.0308  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [170/248]  eta: 0:00:25  lr: 0.000100  class_error: 100.00  loss: 18.5074 (18.7657)  loss_ce: 0.6418 (0.6852)  loss_bbox: 1.2541 (1.3149)  loss_giou: 1.1130 (1.1786)  loss_ce_0: 0.6422 (0.6917)  loss_bbox_0: 1.2919 (1.2563)  loss_giou_0: 1.1401 (1.1845)  loss_ce_1: 0.6496 (0.7056)  loss_bbox_1: 1.2185 (1.2539)  loss_giou_1: 1.1251 (1.1576)  loss_ce_2: 0.6524 (0.6873)  loss_bbox_2: 1.2607 (1.2783)  loss_giou_2: 1.1818 (1.1700)  loss_ce_3: 0.6660 (0.6924)  loss_bbox_3: 1.2194 (1.2528)  loss_giou_3: 1.0961 (1.1390)  loss_ce_4: 0.6498 (0.6887)  loss_bbox_4: 1.2348 (1.2750)  loss_giou_4: 1.1013 (1.1539)  loss_ce_unscaled: 0.6418 (0.6852)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2508 (0.2630)  loss_giou_unscaled: 0.5565 (0.5893)  cardinality_error_unscaled: 2.0000 (2.2544)  loss_ce_0_unscaled: 0.6422 (0.6917)  loss_bbox_0_unscaled: 0.2584 (0.2513)  loss_giou_0_unscaled: 0.5700 (0.5922)  cardinality_error_0_unscaled: 2.0000 (2.2398)  loss_ce_1_unscaled: 0.6496 (0.7056)  loss_bbox_1_unscaled: 0.2437 (0.2508)  loss_giou_1_unscaled: 0.5626 (0.5788)  cardinality_error_1_unscaled: 2.0000 (2.2500)  loss_ce_2_unscaled: 0.6524 (0.6873)  loss_bbox_2_unscaled: 0.2521 (0.2557)  loss_giou_2_unscaled: 0.5909 (0.5850)  cardinality_error_2_unscaled: 2.0000 (2.2515)  loss_ce_3_unscaled: 0.6660 (0.6924)  loss_bbox_3_unscaled: 0.2439 (0.2506)  loss_giou_3_unscaled: 0.5480 (0.5695)  cardinality_error_3_unscaled: 2.0000 (2.2544)  loss_ce_4_unscaled: 0.6498 (0.6887)  loss_bbox_4_unscaled: 0.2470 (0.2550)  loss_giou_4_unscaled: 0.5506 (0.5770)  cardinality_error_4_unscaled: 2.0000 (2.2544)  time: 0.3379  data: 0.0290  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [180/248]  eta: 0:00:22  lr: 0.000100  class_error: 100.00  loss: 17.6342 (18.7417)  loss_ce: 0.6502 (0.6841)  loss_bbox: 1.1864 (1.3045)  loss_giou: 1.1130 (1.1735)  loss_ce_0: 0.6632 (0.6913)  loss_bbox_0: 1.2739 (1.2546)  loss_giou_0: 1.1806 (1.1858)  loss_ce_1: 0.6792 (0.7051)  loss_bbox_1: 1.1326 (1.2466)  loss_giou_1: 1.1060 (1.1559)  loss_ce_2: 0.6637 (0.6874)  loss_bbox_2: 1.2133 (1.2779)  loss_giou_2: 1.1693 (1.1734)  loss_ce_3: 0.6701 (0.6919)  loss_bbox_3: 1.1725 (1.2500)  loss_giou_3: 1.0894 (1.1415)  loss_ce_4: 0.6712 (0.6890)  loss_bbox_4: 1.2077 (1.2739)  loss_giou_4: 1.1416 (1.1554)  loss_ce_unscaled: 0.6502 (0.6841)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2373 (0.2609)  loss_giou_unscaled: 0.5565 (0.5867)  cardinality_error_unscaled: 2.1250 (2.2541)  loss_ce_0_unscaled: 0.6632 (0.6913)  loss_bbox_0_unscaled: 0.2548 (0.2509)  loss_giou_0_unscaled: 0.5903 (0.5929)  cardinality_error_0_unscaled: 2.1250 (2.2396)  loss_ce_1_unscaled: 0.6792 (0.7051)  loss_bbox_1_unscaled: 0.2265 (0.2493)  loss_giou_1_unscaled: 0.5530 (0.5779)  cardinality_error_1_unscaled: 2.1250 (2.2500)  loss_ce_2_unscaled: 0.6637 (0.6874)  loss_bbox_2_unscaled: 0.2427 (0.2556)  loss_giou_2_unscaled: 0.5847 (0.5867)  cardinality_error_2_unscaled: 2.1250 (2.2514)  loss_ce_3_unscaled: 0.6701 (0.6919)  loss_bbox_3_unscaled: 0.2345 (0.2500)  loss_giou_3_unscaled: 0.5447 (0.5707)  cardinality_error_3_unscaled: 2.1250 (2.2541)  loss_ce_4_unscaled: 0.6712 (0.6890)  loss_bbox_4_unscaled: 0.2415 (0.2548)  loss_giou_4_unscaled: 0.5708 (0.5777)  cardinality_error_4_unscaled: 2.1250 (2.2541)  time: 0.3257  data: 0.0296  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [190/248]  eta: 0:00:19  lr: 0.000100  class_error: 100.00  loss: 18.0646 (18.7309)  loss_ce: 0.6599 (0.6830)  loss_bbox: 1.1314 (1.3046)  loss_giou: 1.1015 (1.1726)  loss_ce_0: 0.6814 (0.6908)  loss_bbox_0: 1.2423 (1.2536)  loss_giou_0: 1.1822 (1.1865)  loss_ce_1: 0.6813 (0.7036)  loss_bbox_1: 1.0955 (1.2443)  loss_giou_1: 1.0678 (1.1549)  loss_ce_2: 0.6719 (0.6865)  loss_bbox_2: 1.1948 (1.2761)  loss_giou_2: 1.1607 (1.1706)  loss_ce_3: 0.6810 (0.6916)  loss_bbox_3: 1.1909 (1.2506)  loss_giou_3: 1.1504 (1.1413)  loss_ce_4: 0.6758 (0.6887)  loss_bbox_4: 1.2444 (1.2753)  loss_giou_4: 1.1360 (1.1562)  loss_ce_unscaled: 0.6599 (0.6830)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2263 (0.2609)  loss_giou_unscaled: 0.5507 (0.5863)  cardinality_error_unscaled: 2.2500 (2.2565)  loss_ce_0_unscaled: 0.6814 (0.6908)  loss_bbox_0_unscaled: 0.2485 (0.2507)  loss_giou_0_unscaled: 0.5911 (0.5932)  cardinality_error_0_unscaled: 2.2500 (2.2428)  loss_ce_1_unscaled: 0.6813 (0.7036)  loss_bbox_1_unscaled: 0.2191 (0.2489)  loss_giou_1_unscaled: 0.5339 (0.5775)  cardinality_error_1_unscaled: 2.2500 (2.2526)  loss_ce_2_unscaled: 0.6719 (0.6865)  loss_bbox_2_unscaled: 0.2390 (0.2552)  loss_giou_2_unscaled: 0.5804 (0.5853)  cardinality_error_2_unscaled: 2.2500 (2.2539)  loss_ce_3_unscaled: 0.6810 (0.6916)  loss_bbox_3_unscaled: 0.2382 (0.2501)  loss_giou_3_unscaled: 0.5752 (0.5707)  cardinality_error_3_unscaled: 2.2500 (2.2565)  loss_ce_4_unscaled: 0.6758 (0.6887)  loss_bbox_4_unscaled: 0.2489 (0.2551)  loss_giou_4_unscaled: 0.5680 (0.5781)  cardinality_error_4_unscaled: 2.2500 (2.2565)  time: 0.3591  data: 0.0311  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [200/248]  eta: 0:00:16  lr: 0.000100  class_error: 100.00  loss: 17.9062 (18.6805)  loss_ce: 0.6602 (0.6826)  loss_bbox: 1.1446 (1.2961)  loss_giou: 1.1266 (1.1686)  loss_ce_0: 0.6848 (0.6909)  loss_bbox_0: 1.1329 (1.2491)  loss_giou_0: 1.2385 (1.1863)  loss_ce_1: 0.6759 (0.7025)  loss_bbox_1: 1.0855 (1.2379)  loss_giou_1: 1.0651 (1.1518)  loss_ce_2: 0.6719 (0.6861)  loss_bbox_2: 1.1360 (1.2712)  loss_giou_2: 1.1379 (1.1680)  loss_ce_3: 0.6811 (0.6916)  loss_bbox_3: 1.1605 (1.2463)  loss_giou_3: 1.1551 (1.1401)  loss_ce_4: 0.6733 (0.6885)  loss_bbox_4: 1.1552 (1.2687)  loss_giou_4: 1.1109 (1.1542)  loss_ce_unscaled: 0.6602 (0.6826)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2289 (0.2592)  loss_giou_unscaled: 0.5633 (0.5843)  cardinality_error_unscaled: 2.2500 (2.2606)  loss_ce_0_unscaled: 0.6848 (0.6909)  loss_bbox_0_unscaled: 0.2266 (0.2498)  loss_giou_0_unscaled: 0.6192 (0.5931)  cardinality_error_0_unscaled: 2.2500 (2.2469)  loss_ce_1_unscaled: 0.6759 (0.7025)  loss_bbox_1_unscaled: 0.2171 (0.2476)  loss_giou_1_unscaled: 0.5326 (0.5759)  cardinality_error_1_unscaled: 2.2500 (2.2568)  loss_ce_2_unscaled: 0.6719 (0.6861)  loss_bbox_2_unscaled: 0.2272 (0.2542)  loss_giou_2_unscaled: 0.5690 (0.5840)  cardinality_error_2_unscaled: 2.2500 (2.2581)  loss_ce_3_unscaled: 0.6811 (0.6916)  loss_bbox_3_unscaled: 0.2321 (0.2493)  loss_giou_3_unscaled: 0.5775 (0.5700)  cardinality_error_3_unscaled: 2.2500 (2.2606)  loss_ce_4_unscaled: 0.6733 (0.6885)  loss_bbox_4_unscaled: 0.2310 (0.2537)  loss_giou_4_unscaled: 0.5555 (0.5771)  cardinality_error_4_unscaled: 2.2500 (2.2606)  time: 0.3816  data: 0.0304  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [210/248]  eta: 0:00:12  lr: 0.000100  class_error: 100.00  loss: 17.6978 (18.6316)  loss_ce: 0.6641 (0.6813)  loss_bbox: 1.0669 (1.2863)  loss_giou: 1.0667 (1.1627)  loss_ce_0: 0.6835 (0.6902)  loss_bbox_0: 1.1107 (1.2425)  loss_giou_0: 1.1689 (1.1825)  loss_ce_1: 0.6813 (0.7020)  loss_bbox_1: 1.0996 (1.2324)  loss_giou_1: 1.1444 (1.1519)  loss_ce_2: 0.6744 (0.6851)  loss_bbox_2: 1.1022 (1.2644)  loss_giou_2: 1.0718 (1.1651)  loss_ce_3: 0.6722 (0.6901)  loss_bbox_3: 1.1606 (1.2456)  loss_giou_3: 1.1551 (1.1416)  loss_ce_4: 0.6738 (0.6876)  loss_bbox_4: 1.1620 (1.2663)  loss_giou_4: 1.0971 (1.1541)  loss_ce_unscaled: 0.6641 (0.6813)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2134 (0.2573)  loss_giou_unscaled: 0.5334 (0.5813)  cardinality_error_unscaled: 2.2500 (2.2583)  loss_ce_0_unscaled: 0.6835 (0.6902)  loss_bbox_0_unscaled: 0.2221 (0.2485)  loss_giou_0_unscaled: 0.5845 (0.5913)  cardinality_error_0_unscaled: 2.2500 (2.2453)  loss_ce_1_unscaled: 0.6813 (0.7020)  loss_bbox_1_unscaled: 0.2199 (0.2465)  loss_giou_1_unscaled: 0.5722 (0.5760)  cardinality_error_1_unscaled: 2.2500 (2.2547)  loss_ce_2_unscaled: 0.6744 (0.6851)  loss_bbox_2_unscaled: 0.2204 (0.2529)  loss_giou_2_unscaled: 0.5359 (0.5825)  cardinality_error_2_unscaled: 2.2500 (2.2559)  loss_ce_3_unscaled: 0.6722 (0.6901)  loss_bbox_3_unscaled: 0.2321 (0.2491)  loss_giou_3_unscaled: 0.5775 (0.5708)  cardinality_error_3_unscaled: 2.2500 (2.2583)  loss_ce_4_unscaled: 0.6738 (0.6876)  loss_bbox_4_unscaled: 0.2324 (0.2533)  loss_giou_4_unscaled: 0.5485 (0.5771)  cardinality_error_4_unscaled: 2.2500 (2.2583)  time: 0.3748  data: 0.0292  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [220/248]  eta: 0:00:09  lr: 0.000100  class_error: 100.00  loss: 17.6978 (18.5741)  loss_ce: 0.6518 (0.6799)  loss_bbox: 1.0669 (1.2807)  loss_giou: 1.1151 (1.1589)  loss_ce_0: 0.6743 (0.6895)  loss_bbox_0: 1.0571 (1.2333)  loss_giou_0: 1.0674 (1.1762)  loss_ce_1: 0.6787 (0.7010)  loss_bbox_1: 1.1595 (1.2286)  loss_giou_1: 1.1170 (1.1519)  loss_ce_2: 0.6647 (0.6843)  loss_bbox_2: 1.0678 (1.2565)  loss_giou_2: 1.0922 (1.1610)  loss_ce_3: 0.6730 (0.6893)  loss_bbox_3: 1.1600 (1.2410)  loss_giou_3: 1.1551 (1.1407)  loss_ce_4: 0.6738 (0.6863)  loss_bbox_4: 1.1126 (1.2618)  loss_giou_4: 1.0999 (1.1531)  loss_ce_unscaled: 0.6518 (0.6799)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2134 (0.2561)  loss_giou_unscaled: 0.5576 (0.5794)  cardinality_error_unscaled: 2.2500 (2.2574)  loss_ce_0_unscaled: 0.6743 (0.6895)  loss_bbox_0_unscaled: 0.2114 (0.2467)  loss_giou_0_unscaled: 0.5337 (0.5881)  cardinality_error_0_unscaled: 2.2500 (2.2449)  loss_ce_1_unscaled: 0.6787 (0.7010)  loss_bbox_1_unscaled: 0.2319 (0.2457)  loss_giou_1_unscaled: 0.5585 (0.5759)  cardinality_error_1_unscaled: 2.2500 (2.2540)  loss_ce_2_unscaled: 0.6647 (0.6843)  loss_bbox_2_unscaled: 0.2136 (0.2513)  loss_giou_2_unscaled: 0.5461 (0.5805)  cardinality_error_2_unscaled: 2.2500 (2.2551)  loss_ce_3_unscaled: 0.6730 (0.6893)  loss_bbox_3_unscaled: 0.2320 (0.2482)  loss_giou_3_unscaled: 0.5776 (0.5703)  cardinality_error_3_unscaled: 2.2500 (2.2574)  loss_ce_4_unscaled: 0.6738 (0.6863)  loss_bbox_4_unscaled: 0.2225 (0.2524)  loss_giou_4_unscaled: 0.5499 (0.5766)  cardinality_error_4_unscaled: 2.2500 (2.2574)  time: 0.3403  data: 0.0293  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [230/248]  eta: 0:00:06  lr: 0.000100  class_error: 100.00  loss: 16.9594 (18.4998)  loss_ce: 0.6432 (0.6785)  loss_bbox: 1.1758 (1.2766)  loss_giou: 1.0820 (1.1588)  loss_ce_0: 0.6669 (0.6884)  loss_bbox_0: 1.0115 (1.2260)  loss_giou_0: 1.0655 (1.1732)  loss_ce_1: 0.6637 (0.6990)  loss_bbox_1: 1.0746 (1.2212)  loss_giou_1: 1.0882 (1.1470)  loss_ce_2: 0.6625 (0.6823)  loss_bbox_2: 1.0258 (1.2470)  loss_giou_2: 1.0611 (1.1545)  loss_ce_3: 0.6730 (0.6880)  loss_bbox_3: 1.1019 (1.2347)  loss_giou_3: 1.0485 (1.1381)  loss_ce_4: 0.6560 (0.6847)  loss_bbox_4: 1.1114 (1.2534)  loss_giou_4: 1.0873 (1.1485)  loss_ce_unscaled: 0.6432 (0.6785)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2352 (0.2553)  loss_giou_unscaled: 0.5410 (0.5794)  cardinality_error_unscaled: 2.1250 (2.2554)  loss_ce_0_unscaled: 0.6669 (0.6884)  loss_bbox_0_unscaled: 0.2023 (0.2452)  loss_giou_0_unscaled: 0.5327 (0.5866)  cardinality_error_0_unscaled: 2.1250 (2.2435)  loss_ce_1_unscaled: 0.6637 (0.6990)  loss_bbox_1_unscaled: 0.2149 (0.2442)  loss_giou_1_unscaled: 0.5441 (0.5735)  cardinality_error_1_unscaled: 2.1250 (2.2522)  loss_ce_2_unscaled: 0.6625 (0.6823)  loss_bbox_2_unscaled: 0.2052 (0.2494)  loss_giou_2_unscaled: 0.5305 (0.5772)  cardinality_error_2_unscaled: 2.1250 (2.2532)  loss_ce_3_unscaled: 0.6730 (0.6880)  loss_bbox_3_unscaled: 0.2204 (0.2469)  loss_giou_3_unscaled: 0.5243 (0.5691)  cardinality_error_3_unscaled: 2.1250 (2.2549)  loss_ce_4_unscaled: 0.6560 (0.6847)  loss_bbox_4_unscaled: 0.2223 (0.2507)  loss_giou_4_unscaled: 0.5436 (0.5743)  cardinality_error_4_unscaled: 2.1250 (2.2554)  time: 0.3355  data: 0.0300  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [240/248]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 16.0308 (18.3989)  loss_ce: 0.6432 (0.6770)  loss_bbox: 1.0270 (1.2646)  loss_giou: 0.9958 (1.1511)  loss_ce_0: 0.6806 (0.6884)  loss_bbox_0: 0.9993 (1.2163)  loss_giou_0: 1.0633 (1.1669)  loss_ce_1: 0.6855 (0.6998)  loss_bbox_1: 0.9948 (1.2112)  loss_giou_1: 0.9724 (1.1402)  loss_ce_2: 0.6541 (0.6817)  loss_bbox_2: 1.0132 (1.2392)  loss_giou_2: 1.0265 (1.1504)  loss_ce_3: 0.6720 (0.6877)  loss_bbox_3: 1.0627 (1.2256)  loss_giou_3: 1.0315 (1.1324)  loss_ce_4: 0.6538 (0.6833)  loss_bbox_4: 0.9615 (1.2419)  loss_giou_4: 0.9558 (1.1411)  loss_ce_unscaled: 0.6432 (0.6770)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2054 (0.2529)  loss_giou_unscaled: 0.4979 (0.5755)  cardinality_error_unscaled: 2.2500 (2.2552)  loss_ce_0_unscaled: 0.6806 (0.6884)  loss_bbox_0_unscaled: 0.1999 (0.2433)  loss_giou_0_unscaled: 0.5317 (0.5835)  cardinality_error_0_unscaled: 2.2500 (2.2438)  loss_ce_1_unscaled: 0.6855 (0.6998)  loss_bbox_1_unscaled: 0.1990 (0.2422)  loss_giou_1_unscaled: 0.4862 (0.5701)  cardinality_error_1_unscaled: 2.2500 (2.2521)  loss_ce_2_unscaled: 0.6541 (0.6817)  loss_bbox_2_unscaled: 0.2026 (0.2478)  loss_giou_2_unscaled: 0.5132 (0.5752)  cardinality_error_2_unscaled: 2.2500 (2.2531)  loss_ce_3_unscaled: 0.6720 (0.6877)  loss_bbox_3_unscaled: 0.2125 (0.2451)  loss_giou_3_unscaled: 0.5157 (0.5662)  cardinality_error_3_unscaled: 2.2500 (2.2547)  loss_ce_4_unscaled: 0.6538 (0.6833)  loss_bbox_4_unscaled: 0.1923 (0.2484)  loss_giou_4_unscaled: 0.4779 (0.5705)  cardinality_error_4_unscaled: 2.2500 (2.2552)  time: 0.3417  data: 0.0295  max mem: 17024
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [247/248]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 16.1348 (18.3635)  loss_ce: 0.6336 (0.6757)  loss_bbox: 1.0069 (1.2580)  loss_giou: 0.9494 (1.1496)  loss_ce_0: 0.6806 (0.6875)  loss_bbox_0: 1.0568 (1.2168)  loss_giou_0: 1.0853 (1.1725)  loss_ce_1: 0.7012 (0.6995)  loss_bbox_1: 0.9948 (1.2071)  loss_giou_1: 0.9755 (1.1394)  loss_ce_2: 0.6541 (0.6809)  loss_bbox_2: 1.0132 (1.2334)  loss_giou_2: 1.0311 (1.1484)  loss_ce_3: 0.6805 (0.6871)  loss_bbox_3: 1.0343 (1.2198)  loss_giou_3: 1.0013 (1.1311)  loss_ce_4: 0.6517 (0.6822)  loss_bbox_4: 0.9615 (1.2360)  loss_giou_4: 0.9463 (1.1386)  loss_ce_unscaled: 0.6336 (0.6757)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2014 (0.2516)  loss_giou_unscaled: 0.4747 (0.5748)  cardinality_error_unscaled: 2.2500 (2.2535)  loss_ce_0_unscaled: 0.6806 (0.6875)  loss_bbox_0_unscaled: 0.2114 (0.2434)  loss_giou_0_unscaled: 0.5426 (0.5862)  cardinality_error_0_unscaled: 2.2500 (2.2429)  loss_ce_1_unscaled: 0.7012 (0.6995)  loss_bbox_1_unscaled: 0.1990 (0.2414)  loss_giou_1_unscaled: 0.4877 (0.5697)  cardinality_error_1_unscaled: 2.2500 (2.2510)  loss_ce_2_unscaled: 0.6541 (0.6809)  loss_bbox_2_unscaled: 0.2026 (0.2467)  loss_giou_2_unscaled: 0.5156 (0.5742)  cardinality_error_2_unscaled: 2.2500 (2.2515)  loss_ce_3_unscaled: 0.6805 (0.6871)  loss_bbox_3_unscaled: 0.2069 (0.2440)  loss_giou_3_unscaled: 0.5007 (0.5656)  cardinality_error_3_unscaled: 2.2500 (2.2535)  loss_ce_4_unscaled: 0.6517 (0.6822)  loss_bbox_4_unscaled: 0.1923 (0.2472)  loss_giou_4_unscaled: 0.4731 (0.5693)  cardinality_error_4_unscaled: 2.2500 (2.2535)  time: 0.3381  data: 0.0288  max mem: 17024
Epoch: [1] Total time: 0:01:23 (0.3372 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 16.1348 (18.3635)  loss_ce: 0.6336 (0.6757)  loss_bbox: 1.0069 (1.2580)  loss_giou: 0.9494 (1.1496)  loss_ce_0: 0.6806 (0.6875)  loss_bbox_0: 1.0568 (1.2168)  loss_giou_0: 1.0853 (1.1725)  loss_ce_1: 0.7012 (0.6995)  loss_bbox_1: 0.9948 (1.2071)  loss_giou_1: 0.9755 (1.1394)  loss_ce_2: 0.6541 (0.6809)  loss_bbox_2: 1.0132 (1.2334)  loss_giou_2: 1.0311 (1.1484)  loss_ce_3: 0.6805 (0.6871)  loss_bbox_3: 1.0343 (1.2198)  loss_giou_3: 1.0013 (1.1311)  loss_ce_4: 0.6517 (0.6822)  loss_bbox_4: 0.9615 (1.2360)  loss_giou_4: 0.9463 (1.1386)  loss_ce_unscaled: 0.6336 (0.6757)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2014 (0.2516)  loss_giou_unscaled: 0.4747 (0.5748)  cardinality_error_unscaled: 2.2500 (2.2535)  loss_ce_0_unscaled: 0.6806 (0.6875)  loss_bbox_0_unscaled: 0.2114 (0.2434)  loss_giou_0_unscaled: 0.5426 (0.5862)  cardinality_error_0_unscaled: 2.2500 (2.2429)  loss_ce_1_unscaled: 0.7012 (0.6995)  loss_bbox_1_unscaled: 0.1990 (0.2414)  loss_giou_1_unscaled: 0.4877 (0.5697)  cardinality_error_1_unscaled: 2.2500 (2.2510)  loss_ce_2_unscaled: 0.6541 (0.6809)  loss_bbox_2_unscaled: 0.2026 (0.2467)  loss_giou_2_unscaled: 0.5156 (0.5742)  cardinality_error_2_unscaled: 2.2500 (2.2515)  loss_ce_3_unscaled: 0.6805 (0.6871)  loss_bbox_3_unscaled: 0.2069 (0.2440)  loss_giou_3_unscaled: 0.5007 (0.5656)  cardinality_error_3_unscaled: 2.2500 (2.2535)  loss_ce_4_unscaled: 0.6517 (0.6822)  loss_bbox_4_unscaled: 0.1923 (0.2472)  loss_giou_4_unscaled: 0.4731 (0.5693)  cardinality_error_4_unscaled: 2.2500 (2.2535)

End of training epoch
Total execution time = 83.658 sec
Max memory used by tensors = 17851041792 bytes
Max memory cached = 22659727360 bytes
Total memory reserved = 22659727360 bytes
Total memory allocated = 780627968 bytes
Test:  [ 0/27]  eta: 0:00:42  class_error: 100.00  loss: 38.0036 (38.0036)  loss_ce: 0.6050 (0.6050)  loss_bbox: 2.9509 (2.9509)  loss_giou: 2.1694 (2.1694)  loss_ce_0: 0.6393 (0.6393)  loss_bbox_0: 3.7672 (3.7672)  loss_giou_0: 2.5302 (2.5302)  loss_ce_1: 0.6466 (0.6466)  loss_bbox_1: 3.4679 (3.4679)  loss_giou_1: 2.2775 (2.2775)  loss_ce_2: 0.6210 (0.6210)  loss_bbox_2: 3.7706 (3.7706)  loss_giou_2: 2.2388 (2.2388)  loss_ce_3: 0.6179 (0.6179)  loss_bbox_3: 3.6968 (3.6968)  loss_giou_3: 2.3288 (2.3288)  loss_ce_4: 0.6156 (0.6156)  loss_bbox_4: 2.9749 (2.9749)  loss_giou_4: 2.0851 (2.0851)  loss_ce_unscaled: 0.6050 (0.6050)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5902 (0.5902)  loss_giou_unscaled: 1.0847 (1.0847)  cardinality_error_unscaled: 2.0000 (2.0000)  loss_ce_0_unscaled: 0.6393 (0.6393)  loss_bbox_0_unscaled: 0.7534 (0.7534)  loss_giou_0_unscaled: 1.2651 (1.2651)  cardinality_error_0_unscaled: 2.0000 (2.0000)  loss_ce_1_unscaled: 0.6466 (0.6466)  loss_bbox_1_unscaled: 0.6936 (0.6936)  loss_giou_1_unscaled: 1.1388 (1.1388)  cardinality_error_1_unscaled: 2.0000 (2.0000)  loss_ce_2_unscaled: 0.6210 (0.6210)  loss_bbox_2_unscaled: 0.7541 (0.7541)  loss_giou_2_unscaled: 1.1194 (1.1194)  cardinality_error_2_unscaled: 2.0000 (2.0000)  loss_ce_3_unscaled: 0.6179 (0.6179)  loss_bbox_3_unscaled: 0.7394 (0.7394)  loss_giou_3_unscaled: 1.1644 (1.1644)  cardinality_error_3_unscaled: 2.0000 (2.0000)  loss_ce_4_unscaled: 0.6156 (0.6156)  loss_bbox_4_unscaled: 0.5950 (0.5950)  loss_giou_4_unscaled: 1.0425 (1.0425)  cardinality_error_4_unscaled: 2.0000 (2.0000)  time: 1.5651  data: 1.4220  max mem: 17024
Test:  [10/27]  eta: 0:00:07  class_error: 100.00  loss: 36.7025 (38.6327)  loss_ce: 0.6393 (0.6413)  loss_bbox: 2.7827 (2.7348)  loss_giou: 2.3092 (2.3766)  loss_ce_0: 0.6734 (0.6793)  loss_bbox_0: 3.5076 (3.5710)  loss_giou_0: 2.5302 (2.6797)  loss_ce_1: 0.6778 (0.6814)  loss_bbox_1: 3.2117 (3.4001)  loss_giou_1: 2.4345 (2.5447)  loss_ce_2: 0.6524 (0.6548)  loss_bbox_2: 3.4610 (3.5200)  loss_giou_2: 2.3214 (2.4564)  loss_ce_3: 0.6469 (0.6467)  loss_bbox_3: 3.2388 (3.3849)  loss_giou_3: 2.3695 (2.5224)  loss_ce_4: 0.6466 (0.6476)  loss_bbox_4: 2.9558 (3.0497)  loss_giou_4: 2.3443 (2.4411)  loss_ce_unscaled: 0.6393 (0.6413)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5565 (0.5470)  loss_giou_unscaled: 1.1546 (1.1883)  cardinality_error_unscaled: 2.2500 (2.2727)  loss_ce_0_unscaled: 0.6734 (0.6793)  loss_bbox_0_unscaled: 0.7015 (0.7142)  loss_giou_0_unscaled: 1.2651 (1.3399)  cardinality_error_0_unscaled: 2.2500 (2.2727)  loss_ce_1_unscaled: 0.6778 (0.6814)  loss_bbox_1_unscaled: 0.6423 (0.6800)  loss_giou_1_unscaled: 1.2173 (1.2724)  cardinality_error_1_unscaled: 2.2500 (2.2727)  loss_ce_2_unscaled: 0.6524 (0.6548)  loss_bbox_2_unscaled: 0.6922 (0.7040)  loss_giou_2_unscaled: 1.1607 (1.2282)  cardinality_error_2_unscaled: 2.2500 (2.2727)  loss_ce_3_unscaled: 0.6469 (0.6467)  loss_bbox_3_unscaled: 0.6478 (0.6770)  loss_giou_3_unscaled: 1.1848 (1.2612)  cardinality_error_3_unscaled: 2.2500 (2.2727)  loss_ce_4_unscaled: 0.6466 (0.6476)  loss_bbox_4_unscaled: 0.5912 (0.6099)  loss_giou_4_unscaled: 1.1722 (1.2206)  cardinality_error_4_unscaled: 2.2500 (2.2727)  time: 0.4445  data: 0.3131  max mem: 17024
Test:  [20/27]  eta: 0:00:02  class_error: 100.00  loss: 35.8184 (37.2036)  loss_ce: 0.6542 (0.6517)  loss_bbox: 2.4650 (2.5225)  loss_giou: 2.1425 (2.2706)  loss_ce_0: 0.6988 (0.6958)  loss_bbox_0: 3.3175 (3.4116)  loss_giou_0: 2.4776 (2.6104)  loss_ce_1: 0.6816 (0.6851)  loss_bbox_1: 3.1611 (3.2730)  loss_giou_1: 2.3047 (2.4407)  loss_ce_2: 0.6699 (0.6663)  loss_bbox_2: 3.2416 (3.4064)  loss_giou_2: 2.3068 (2.3584)  loss_ce_3: 0.6543 (0.6543)  loss_bbox_3: 3.1200 (3.2158)  loss_giou_3: 2.3076 (2.4089)  loss_ce_4: 0.6459 (0.6515)  loss_bbox_4: 2.7847 (2.9155)  loss_giou_4: 2.2663 (2.3650)  loss_ce_unscaled: 0.6542 (0.6517)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.4930 (0.5045)  loss_giou_unscaled: 1.0712 (1.1353)  cardinality_error_unscaled: 2.2500 (2.2917)  loss_ce_0_unscaled: 0.6988 (0.6958)  loss_bbox_0_unscaled: 0.6635 (0.6823)  loss_giou_0_unscaled: 1.2388 (1.3052)  cardinality_error_0_unscaled: 2.2500 (2.2917)  loss_ce_1_unscaled: 0.6816 (0.6851)  loss_bbox_1_unscaled: 0.6322 (0.6546)  loss_giou_1_unscaled: 1.1523 (1.2204)  cardinality_error_1_unscaled: 2.2500 (2.2917)  loss_ce_2_unscaled: 0.6699 (0.6663)  loss_bbox_2_unscaled: 0.6483 (0.6813)  loss_giou_2_unscaled: 1.1534 (1.1792)  cardinality_error_2_unscaled: 2.2500 (2.2917)  loss_ce_3_unscaled: 0.6543 (0.6543)  loss_bbox_3_unscaled: 0.6240 (0.6432)  loss_giou_3_unscaled: 1.1538 (1.2044)  cardinality_error_3_unscaled: 2.2500 (2.2917)  loss_ce_4_unscaled: 0.6459 (0.6515)  loss_bbox_4_unscaled: 0.5569 (0.5831)  loss_giou_4_unscaled: 1.1331 (1.1825)  cardinality_error_4_unscaled: 2.2500 (2.2917)  time: 0.2867  data: 0.1511  max mem: 17024
Test:  [26/27]  eta: 0:00:00  class_error: 100.00  loss: 36.4007 (37.3777)  loss_ce: 0.6597 (0.6625)  loss_bbox: 2.3884 (2.5262)  loss_giou: 2.0707 (2.2321)  loss_ce_0: 0.7163 (0.7116)  loss_bbox_0: 3.4610 (3.4780)  loss_giou_0: 2.4645 (2.6084)  loss_ce_1: 0.6909 (0.6947)  loss_bbox_1: 3.2166 (3.3290)  loss_giou_1: 2.3047 (2.4240)  loss_ce_2: 0.6770 (0.6782)  loss_bbox_2: 3.4610 (3.4653)  loss_giou_2: 2.2535 (2.3456)  loss_ce_3: 0.6579 (0.6641)  loss_bbox_3: 3.1806 (3.2554)  loss_giou_3: 2.2502 (2.3883)  loss_ce_4: 0.6495 (0.6593)  loss_bbox_4: 2.7927 (2.9218)  loss_giou_4: 2.2027 (2.3332)  loss_ce_unscaled: 0.6597 (0.6625)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.4777 (0.5052)  loss_giou_unscaled: 1.0354 (1.1160)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.7163 (0.7116)  loss_bbox_0_unscaled: 0.6922 (0.6956)  loss_giou_0_unscaled: 1.2323 (1.3042)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.6909 (0.6947)  loss_bbox_1_unscaled: 0.6433 (0.6658)  loss_giou_1_unscaled: 1.1523 (1.2120)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6770 (0.6782)  loss_bbox_2_unscaled: 0.6922 (0.6931)  loss_giou_2_unscaled: 1.1268 (1.1728)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6579 (0.6641)  loss_bbox_3_unscaled: 0.6361 (0.6511)  loss_giou_3_unscaled: 1.1251 (1.1942)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6495 (0.6593)  loss_bbox_4_unscaled: 0.5585 (0.5844)  loss_giou_4_unscaled: 1.1013 (1.1666)  cardinality_error_4_unscaled: 2.2500 (2.3380)  time: 0.2890  data: 0.1564  max mem: 17024
Test: Total time: 0:00:09 (0.3493 s / it)
Averaged stats: class_error: 100.00  loss: 36.4007 (37.3777)  loss_ce: 0.6597 (0.6625)  loss_bbox: 2.3884 (2.5262)  loss_giou: 2.0707 (2.2321)  loss_ce_0: 0.7163 (0.7116)  loss_bbox_0: 3.4610 (3.4780)  loss_giou_0: 2.4645 (2.6084)  loss_ce_1: 0.6909 (0.6947)  loss_bbox_1: 3.2166 (3.3290)  loss_giou_1: 2.3047 (2.4240)  loss_ce_2: 0.6770 (0.6782)  loss_bbox_2: 3.4610 (3.4653)  loss_giou_2: 2.2535 (2.3456)  loss_ce_3: 0.6579 (0.6641)  loss_bbox_3: 3.1806 (3.2554)  loss_giou_3: 2.2502 (2.3883)  loss_ce_4: 0.6495 (0.6593)  loss_bbox_4: 2.7927 (2.9218)  loss_giou_4: 2.2027 (2.3332)  loss_ce_unscaled: 0.6597 (0.6625)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.4777 (0.5052)  loss_giou_unscaled: 1.0354 (1.1160)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.7163 (0.7116)  loss_bbox_0_unscaled: 0.6922 (0.6956)  loss_giou_0_unscaled: 1.2323 (1.3042)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.6909 (0.6947)  loss_bbox_1_unscaled: 0.6433 (0.6658)  loss_giou_1_unscaled: 1.1523 (1.2120)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6770 (0.6782)  loss_bbox_2_unscaled: 0.6922 (0.6931)  loss_giou_2_unscaled: 1.1268 (1.1728)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6579 (0.6641)  loss_bbox_3_unscaled: 0.6361 (0.6511)  loss_giou_3_unscaled: 1.1251 (1.1942)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6495 (0.6593)  loss_bbox_4_unscaled: 0.5585 (0.5844)  loss_giou_4_unscaled: 1.1013 (1.1666)  cardinality_error_4_unscaled: 2.2500 (2.3380)
Accumulating evaluation results...
DONE (t=0.04s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.115
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.147
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.147
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.085
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.162
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [  0/248]  eta: 0:05:41  lr: 0.000100  class_error: 100.00  loss: 19.8706 (19.8706)  loss_ce: 0.7374 (0.7374)  loss_bbox: 1.2289 (1.2289)  loss_giou: 1.2155 (1.2155)  loss_ce_0: 0.7677 (0.7677)  loss_bbox_0: 1.4714 (1.4714)  loss_giou_0: 1.4348 (1.4348)  loss_ce_1: 0.7620 (0.7620)  loss_bbox_1: 1.2255 (1.2255)  loss_giou_1: 1.2697 (1.2697)  loss_ce_2: 0.7734 (0.7734)  loss_bbox_2: 1.2998 (1.2998)  loss_giou_2: 1.2736 (1.2736)  loss_ce_3: 0.7652 (0.7652)  loss_bbox_3: 1.2322 (1.2322)  loss_giou_3: 1.1786 (1.1786)  loss_ce_4: 0.7502 (0.7502)  loss_bbox_4: 1.2340 (1.2340)  loss_giou_4: 1.2508 (1.2508)  loss_ce_unscaled: 0.7374 (0.7374)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2458 (0.2458)  loss_giou_unscaled: 0.6077 (0.6077)  cardinality_error_unscaled: 2.7500 (2.7500)  loss_ce_0_unscaled: 0.7677 (0.7677)  loss_bbox_0_unscaled: 0.2943 (0.2943)  loss_giou_0_unscaled: 0.7174 (0.7174)  cardinality_error_0_unscaled: 2.7500 (2.7500)  loss_ce_1_unscaled: 0.7620 (0.7620)  loss_bbox_1_unscaled: 0.2451 (0.2451)  loss_giou_1_unscaled: 0.6349 (0.6349)  cardinality_error_1_unscaled: 2.7500 (2.7500)  loss_ce_2_unscaled: 0.7734 (0.7734)  loss_bbox_2_unscaled: 0.2600 (0.2600)  loss_giou_2_unscaled: 0.6368 (0.6368)  cardinality_error_2_unscaled: 2.7500 (2.7500)  loss_ce_3_unscaled: 0.7652 (0.7652)  loss_bbox_3_unscaled: 0.2464 (0.2464)  loss_giou_3_unscaled: 0.5893 (0.5893)  cardinality_error_3_unscaled: 2.7500 (2.7500)  loss_ce_4_unscaled: 0.7502 (0.7502)  loss_bbox_4_unscaled: 0.2468 (0.2468)  loss_giou_4_unscaled: 0.6254 (0.6254)  cardinality_error_4_unscaled: 2.7500 (2.7500)  time: 1.3770  data: 0.9812  max mem: 9000
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 10/248]  eta: 0:01:45  lr: 0.000100  class_error: 100.00  loss: 17.5807 (17.3417)  loss_ce: 0.6456 (0.6554)  loss_bbox: 1.1522 (1.1480)  loss_giou: 1.1153 (1.0405)  loss_ce_0: 0.6432 (0.6470)  loss_bbox_0: 1.2528 (1.3190)  loss_giou_0: 1.1568 (1.1939)  loss_ce_1: 0.6535 (0.6586)  loss_bbox_1: 1.1147 (1.1184)  loss_giou_1: 1.1057 (1.0661)  loss_ce_2: 0.6345 (0.6484)  loss_bbox_2: 1.0852 (1.1755)  loss_giou_2: 1.0448 (1.0906)  loss_ce_3: 0.6415 (0.6493)  loss_bbox_3: 1.1063 (1.1184)  loss_giou_3: 1.0781 (1.0496)  loss_ce_4: 0.6472 (0.6428)  loss_bbox_4: 1.0754 (1.1008)  loss_giou_4: 1.0396 (1.0192)  loss_ce_unscaled: 0.6456 (0.6554)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2304 (0.2296)  loss_giou_unscaled: 0.5576 (0.5203)  cardinality_error_unscaled: 2.1250 (2.1591)  loss_ce_0_unscaled: 0.6432 (0.6470)  loss_bbox_0_unscaled: 0.2506 (0.2638)  loss_giou_0_unscaled: 0.5784 (0.5969)  cardinality_error_0_unscaled: 2.1250 (2.1591)  loss_ce_1_unscaled: 0.6535 (0.6586)  loss_bbox_1_unscaled: 0.2229 (0.2237)  loss_giou_1_unscaled: 0.5528 (0.5330)  cardinality_error_1_unscaled: 2.1250 (2.1591)  loss_ce_2_unscaled: 0.6345 (0.6484)  loss_bbox_2_unscaled: 0.2170 (0.2351)  loss_giou_2_unscaled: 0.5224 (0.5453)  cardinality_error_2_unscaled: 2.1250 (2.1591)  loss_ce_3_unscaled: 0.6415 (0.6493)  loss_bbox_3_unscaled: 0.2213 (0.2237)  loss_giou_3_unscaled: 0.5391 (0.5248)  cardinality_error_3_unscaled: 2.1250 (2.1591)  loss_ce_4_unscaled: 0.6472 (0.6428)  loss_bbox_4_unscaled: 0.2151 (0.2202)  loss_giou_4_unscaled: 0.5198 (0.5096)  cardinality_error_4_unscaled: 2.1250 (2.1591)  time: 0.4451  data: 0.1158  max mem: 11774
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 20/248]  eta: 0:01:33  lr: 0.000100  class_error: 100.00  loss: 17.9303 (18.3114)  loss_ce: 0.6696 (0.6808)  loss_bbox: 1.1791 (1.2928)  loss_giou: 1.1229 (1.1539)  loss_ce_0: 0.6580 (0.6665)  loss_bbox_0: 1.2528 (1.3261)  loss_giou_0: 1.2277 (1.2368)  loss_ce_1: 0.6605 (0.6680)  loss_bbox_1: 1.1147 (1.1805)  loss_giou_1: 1.1057 (1.1148)  loss_ce_2: 0.6578 (0.6593)  loss_bbox_2: 1.1229 (1.2280)  loss_giou_2: 1.0784 (1.1261)  loss_ce_3: 0.6565 (0.6639)  loss_bbox_3: 1.1063 (1.2130)  loss_giou_3: 1.0793 (1.1072)  loss_ce_4: 0.6618 (0.6664)  loss_bbox_4: 1.1144 (1.2237)  loss_giou_4: 1.0987 (1.1036)  loss_ce_unscaled: 0.6696 (0.6808)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2358 (0.2586)  loss_giou_unscaled: 0.5615 (0.5770)  cardinality_error_unscaled: 2.1250 (2.1726)  loss_ce_0_unscaled: 0.6580 (0.6665)  loss_bbox_0_unscaled: 0.2506 (0.2652)  loss_giou_0_unscaled: 0.6139 (0.6184)  cardinality_error_0_unscaled: 2.1250 (2.1726)  loss_ce_1_unscaled: 0.6605 (0.6680)  loss_bbox_1_unscaled: 0.2229 (0.2361)  loss_giou_1_unscaled: 0.5528 (0.5574)  cardinality_error_1_unscaled: 2.1250 (2.1726)  loss_ce_2_unscaled: 0.6578 (0.6593)  loss_bbox_2_unscaled: 0.2246 (0.2456)  loss_giou_2_unscaled: 0.5392 (0.5630)  cardinality_error_2_unscaled: 2.1250 (2.1726)  loss_ce_3_unscaled: 0.6565 (0.6639)  loss_bbox_3_unscaled: 0.2213 (0.2426)  loss_giou_3_unscaled: 0.5397 (0.5536)  cardinality_error_3_unscaled: 2.1250 (2.1726)  loss_ce_4_unscaled: 0.6618 (0.6664)  loss_bbox_4_unscaled: 0.2229 (0.2447)  loss_giou_4_unscaled: 0.5493 (0.5518)  cardinality_error_4_unscaled: 2.1250 (2.1726)  time: 0.3604  data: 0.0295  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 30/248]  eta: 0:01:24  lr: 0.000100  class_error: 100.00  loss: 17.4813 (17.7423)  loss_ce: 0.6905 (0.6771)  loss_bbox: 1.1193 (1.2041)  loss_giou: 1.0847 (1.0924)  loss_ce_0: 0.6763 (0.6687)  loss_bbox_0: 1.1255 (1.2446)  loss_giou_0: 1.1731 (1.1841)  loss_ce_1: 0.6790 (0.6699)  loss_bbox_1: 1.1798 (1.1532)  loss_giou_1: 1.0988 (1.1044)  loss_ce_2: 0.6847 (0.6664)  loss_bbox_2: 1.1347 (1.2087)  loss_giou_2: 1.1376 (1.1232)  loss_ce_3: 0.6788 (0.6665)  loss_bbox_3: 1.0967 (1.1531)  loss_giou_3: 1.0425 (1.0731)  loss_ce_4: 0.6815 (0.6626)  loss_bbox_4: 1.0388 (1.1417)  loss_giou_4: 1.0406 (1.0485)  loss_ce_unscaled: 0.6905 (0.6771)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2239 (0.2408)  loss_giou_unscaled: 0.5423 (0.5462)  cardinality_error_unscaled: 2.2500 (2.2016)  loss_ce_0_unscaled: 0.6763 (0.6687)  loss_bbox_0_unscaled: 0.2251 (0.2489)  loss_giou_0_unscaled: 0.5865 (0.5920)  cardinality_error_0_unscaled: 2.2500 (2.2016)  loss_ce_1_unscaled: 0.6790 (0.6699)  loss_bbox_1_unscaled: 0.2360 (0.2306)  loss_giou_1_unscaled: 0.5494 (0.5522)  cardinality_error_1_unscaled: 2.2500 (2.2016)  loss_ce_2_unscaled: 0.6847 (0.6664)  loss_bbox_2_unscaled: 0.2269 (0.2417)  loss_giou_2_unscaled: 0.5688 (0.5616)  cardinality_error_2_unscaled: 2.2500 (2.2016)  loss_ce_3_unscaled: 0.6788 (0.6665)  loss_bbox_3_unscaled: 0.2193 (0.2306)  loss_giou_3_unscaled: 0.5212 (0.5365)  cardinality_error_3_unscaled: 2.2500 (2.2016)  loss_ce_4_unscaled: 0.6815 (0.6626)  loss_bbox_4_unscaled: 0.2078 (0.2283)  loss_giou_4_unscaled: 0.5203 (0.5243)  cardinality_error_4_unscaled: 2.2500 (2.2016)  time: 0.3587  data: 0.0310  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 40/248]  eta: 0:01:20  lr: 0.000100  class_error: 100.00  loss: 16.1459 (17.4682)  loss_ce: 0.6533 (0.6697)  loss_bbox: 1.0352 (1.1720)  loss_giou: 0.9789 (1.0780)  loss_ce_0: 0.6423 (0.6601)  loss_bbox_0: 1.0799 (1.2336)  loss_giou_0: 1.1099 (1.1806)  loss_ce_1: 0.6483 (0.6638)  loss_bbox_1: 1.0112 (1.1276)  loss_giou_1: 1.0455 (1.0880)  loss_ce_2: 0.6679 (0.6616)  loss_bbox_2: 1.0238 (1.1700)  loss_giou_2: 1.1376 (1.1103)  loss_ce_3: 0.6477 (0.6622)  loss_bbox_3: 1.0105 (1.1225)  loss_giou_3: 0.9850 (1.0574)  loss_ce_4: 0.6492 (0.6585)  loss_bbox_4: 0.9635 (1.1138)  loss_giou_4: 0.9263 (1.0386)  loss_ce_unscaled: 0.6533 (0.6697)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2070 (0.2344)  loss_giou_unscaled: 0.4894 (0.5390)  cardinality_error_unscaled: 2.1250 (2.1768)  loss_ce_0_unscaled: 0.6423 (0.6601)  loss_bbox_0_unscaled: 0.2160 (0.2467)  loss_giou_0_unscaled: 0.5550 (0.5903)  cardinality_error_0_unscaled: 2.1250 (2.1768)  loss_ce_1_unscaled: 0.6483 (0.6638)  loss_bbox_1_unscaled: 0.2022 (0.2255)  loss_giou_1_unscaled: 0.5227 (0.5440)  cardinality_error_1_unscaled: 2.1250 (2.1768)  loss_ce_2_unscaled: 0.6679 (0.6616)  loss_bbox_2_unscaled: 0.2048 (0.2340)  loss_giou_2_unscaled: 0.5688 (0.5552)  cardinality_error_2_unscaled: 2.1250 (2.1768)  loss_ce_3_unscaled: 0.6477 (0.6622)  loss_bbox_3_unscaled: 0.2021 (0.2245)  loss_giou_3_unscaled: 0.4925 (0.5287)  cardinality_error_3_unscaled: 2.1250 (2.1768)  loss_ce_4_unscaled: 0.6492 (0.6585)  loss_bbox_4_unscaled: 0.1927 (0.2228)  loss_giou_4_unscaled: 0.4631 (0.5193)  cardinality_error_4_unscaled: 2.1250 (2.1768)  time: 0.3678  data: 0.0302  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 50/248]  eta: 0:01:15  lr: 0.000100  class_error: 100.00  loss: 16.6085 (17.4656)  loss_ce: 0.6533 (0.6675)  loss_bbox: 1.0620 (1.1592)  loss_giou: 1.0553 (1.0944)  loss_ce_0: 0.6393 (0.6592)  loss_bbox_0: 1.0799 (1.2109)  loss_giou_0: 1.1099 (1.1873)  loss_ce_1: 0.6483 (0.6669)  loss_bbox_1: 0.9599 (1.1199)  loss_giou_1: 1.0704 (1.0979)  loss_ce_2: 0.6581 (0.6631)  loss_bbox_2: 1.0238 (1.1536)  loss_giou_2: 1.1478 (1.1264)  loss_ce_3: 0.6477 (0.6597)  loss_bbox_3: 1.0105 (1.1071)  loss_giou_3: 1.0341 (1.0746)  loss_ce_4: 0.6470 (0.6577)  loss_bbox_4: 0.9737 (1.0994)  loss_giou_4: 1.0369 (1.0607)  loss_ce_unscaled: 0.6533 (0.6675)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2124 (0.2318)  loss_giou_unscaled: 0.5277 (0.5472)  cardinality_error_unscaled: 2.1250 (2.1912)  loss_ce_0_unscaled: 0.6393 (0.6592)  loss_bbox_0_unscaled: 0.2160 (0.2422)  loss_giou_0_unscaled: 0.5550 (0.5937)  cardinality_error_0_unscaled: 2.1250 (2.1912)  loss_ce_1_unscaled: 0.6483 (0.6669)  loss_bbox_1_unscaled: 0.1920 (0.2240)  loss_giou_1_unscaled: 0.5352 (0.5490)  cardinality_error_1_unscaled: 2.1250 (2.1912)  loss_ce_2_unscaled: 0.6581 (0.6631)  loss_bbox_2_unscaled: 0.2048 (0.2307)  loss_giou_2_unscaled: 0.5739 (0.5632)  cardinality_error_2_unscaled: 2.1250 (2.1912)  loss_ce_3_unscaled: 0.6477 (0.6597)  loss_bbox_3_unscaled: 0.2021 (0.2214)  loss_giou_3_unscaled: 0.5171 (0.5373)  cardinality_error_3_unscaled: 2.1250 (2.1912)  loss_ce_4_unscaled: 0.6470 (0.6577)  loss_bbox_4_unscaled: 0.1947 (0.2199)  loss_giou_4_unscaled: 0.5184 (0.5304)  cardinality_error_4_unscaled: 2.1250 (2.1912)  time: 0.3661  data: 0.0284  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 60/248]  eta: 0:01:10  lr: 0.000100  class_error: 100.00  loss: 17.0888 (17.4684)  loss_ce: 0.6515 (0.6617)  loss_bbox: 1.0948 (1.1582)  loss_giou: 1.1212 (1.1018)  loss_ce_0: 0.6674 (0.6581)  loss_bbox_0: 1.1162 (1.1920)  loss_giou_0: 1.0813 (1.1747)  loss_ce_1: 0.6745 (0.6669)  loss_bbox_1: 1.0984 (1.1147)  loss_giou_1: 1.1245 (1.1025)  loss_ce_2: 0.6818 (0.6655)  loss_bbox_2: 1.1129 (1.1584)  loss_giou_2: 1.1617 (1.1393)  loss_ce_3: 0.6579 (0.6608)  loss_bbox_3: 1.0521 (1.1049)  loss_giou_3: 1.0473 (1.0803)  loss_ce_4: 0.6629 (0.6575)  loss_bbox_4: 1.0434 (1.0982)  loss_giou_4: 1.1246 (1.0727)  loss_ce_unscaled: 0.6515 (0.6617)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2190 (0.2316)  loss_giou_unscaled: 0.5606 (0.5509)  cardinality_error_unscaled: 2.2500 (2.1988)  loss_ce_0_unscaled: 0.6674 (0.6581)  loss_bbox_0_unscaled: 0.2232 (0.2384)  loss_giou_0_unscaled: 0.5406 (0.5874)  cardinality_error_0_unscaled: 2.2500 (2.1988)  loss_ce_1_unscaled: 0.6745 (0.6669)  loss_bbox_1_unscaled: 0.2197 (0.2229)  loss_giou_1_unscaled: 0.5623 (0.5513)  cardinality_error_1_unscaled: 2.2500 (2.1988)  loss_ce_2_unscaled: 0.6818 (0.6655)  loss_bbox_2_unscaled: 0.2226 (0.2317)  loss_giou_2_unscaled: 0.5809 (0.5696)  cardinality_error_2_unscaled: 2.2500 (2.1988)  loss_ce_3_unscaled: 0.6579 (0.6608)  loss_bbox_3_unscaled: 0.2104 (0.2210)  loss_giou_3_unscaled: 0.5236 (0.5402)  cardinality_error_3_unscaled: 2.2500 (2.1988)  loss_ce_4_unscaled: 0.6629 (0.6575)  loss_bbox_4_unscaled: 0.2087 (0.2196)  loss_giou_4_unscaled: 0.5623 (0.5363)  cardinality_error_4_unscaled: 2.2500 (2.1988)  time: 0.3388  data: 0.0295  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 70/248]  eta: 0:01:06  lr: 0.000100  class_error: 100.00  loss: 17.0263 (17.4002)  loss_ce: 0.6548 (0.6642)  loss_bbox: 1.0855 (1.1411)  loss_giou: 1.1038 (1.0999)  loss_ce_0: 0.6658 (0.6605)  loss_bbox_0: 1.0432 (1.1663)  loss_giou_0: 1.1533 (1.1671)  loss_ce_1: 0.6893 (0.6693)  loss_bbox_1: 1.0334 (1.1021)  loss_giou_1: 1.1245 (1.1048)  loss_ce_2: 0.6899 (0.6697)  loss_bbox_2: 1.1129 (1.1448)  loss_giou_2: 1.1079 (1.1377)  loss_ce_3: 0.6752 (0.6649)  loss_bbox_3: 1.0390 (1.0950)  loss_giou_3: 1.0587 (1.0857)  loss_ce_4: 0.6680 (0.6623)  loss_bbox_4: 1.0637 (1.0861)  loss_giou_4: 1.1246 (1.0788)  loss_ce_unscaled: 0.6548 (0.6642)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2171 (0.2282)  loss_giou_unscaled: 0.5519 (0.5500)  cardinality_error_unscaled: 2.2500 (2.2201)  loss_ce_0_unscaled: 0.6658 (0.6605)  loss_bbox_0_unscaled: 0.2086 (0.2333)  loss_giou_0_unscaled: 0.5766 (0.5835)  cardinality_error_0_unscaled: 2.2500 (2.2201)  loss_ce_1_unscaled: 0.6893 (0.6693)  loss_bbox_1_unscaled: 0.2067 (0.2204)  loss_giou_1_unscaled: 0.5623 (0.5524)  cardinality_error_1_unscaled: 2.2500 (2.2201)  loss_ce_2_unscaled: 0.6899 (0.6697)  loss_bbox_2_unscaled: 0.2226 (0.2290)  loss_giou_2_unscaled: 0.5539 (0.5689)  cardinality_error_2_unscaled: 2.2500 (2.2201)  loss_ce_3_unscaled: 0.6752 (0.6649)  loss_bbox_3_unscaled: 0.2078 (0.2190)  loss_giou_3_unscaled: 0.5293 (0.5429)  cardinality_error_3_unscaled: 2.2500 (2.2201)  loss_ce_4_unscaled: 0.6680 (0.6623)  loss_bbox_4_unscaled: 0.2127 (0.2172)  loss_giou_4_unscaled: 0.5623 (0.5394)  cardinality_error_4_unscaled: 2.2500 (2.2201)  time: 0.3471  data: 0.0306  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 80/248]  eta: 0:01:01  lr: 0.000100  class_error: 100.00  loss: 16.2573 (17.2461)  loss_ce: 0.6430 (0.6598)  loss_bbox: 0.9616 (1.1216)  loss_giou: 1.0562 (1.0915)  loss_ce_0: 0.6658 (0.6588)  loss_bbox_0: 1.0143 (1.1530)  loss_giou_0: 1.1029 (1.1567)  loss_ce_1: 0.6589 (0.6654)  loss_bbox_1: 0.9869 (1.0896)  loss_giou_1: 1.0538 (1.0977)  loss_ce_2: 0.6595 (0.6655)  loss_bbox_2: 1.0010 (1.1293)  loss_giou_2: 1.0897 (1.1270)  loss_ce_3: 0.6533 (0.6610)  loss_bbox_3: 1.0065 (1.0865)  loss_giou_3: 1.0587 (1.0817)  loss_ce_4: 0.6416 (0.6585)  loss_bbox_4: 0.9876 (1.0714)  loss_giou_4: 1.0210 (1.0711)  loss_ce_unscaled: 0.6430 (0.6598)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1923 (0.2243)  loss_giou_unscaled: 0.5281 (0.5457)  cardinality_error_unscaled: 2.2500 (2.2176)  loss_ce_0_unscaled: 0.6658 (0.6588)  loss_bbox_0_unscaled: 0.2029 (0.2306)  loss_giou_0_unscaled: 0.5515 (0.5784)  cardinality_error_0_unscaled: 2.2500 (2.2160)  loss_ce_1_unscaled: 0.6589 (0.6654)  loss_bbox_1_unscaled: 0.1974 (0.2179)  loss_giou_1_unscaled: 0.5269 (0.5488)  cardinality_error_1_unscaled: 2.2500 (2.2176)  loss_ce_2_unscaled: 0.6595 (0.6655)  loss_bbox_2_unscaled: 0.2002 (0.2259)  loss_giou_2_unscaled: 0.5448 (0.5635)  cardinality_error_2_unscaled: 2.2500 (2.2176)  loss_ce_3_unscaled: 0.6533 (0.6610)  loss_bbox_3_unscaled: 0.2013 (0.2173)  loss_giou_3_unscaled: 0.5293 (0.5409)  cardinality_error_3_unscaled: 2.2500 (2.2176)  loss_ce_4_unscaled: 0.6416 (0.6585)  loss_bbox_4_unscaled: 0.1975 (0.2143)  loss_giou_4_unscaled: 0.5105 (0.5356)  cardinality_error_4_unscaled: 2.2500 (2.2176)  time: 0.3459  data: 0.0300  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 90/248]  eta: 0:00:56  lr: 0.000100  class_error: 100.00  loss: 16.2785 (17.2082)  loss_ce: 0.6386 (0.6580)  loss_bbox: 1.0107 (1.1342)  loss_giou: 1.0885 (1.0975)  loss_ce_0: 0.6430 (0.6571)  loss_bbox_0: 1.0143 (1.1428)  loss_giou_0: 1.0243 (1.1408)  loss_ce_1: 0.6453 (0.6636)  loss_bbox_1: 0.9897 (1.0865)  loss_giou_1: 0.9572 (1.0849)  loss_ce_2: 0.6411 (0.6631)  loss_bbox_2: 1.0577 (1.1274)  loss_giou_2: 1.0344 (1.1154)  loss_ce_3: 0.6439 (0.6596)  loss_bbox_3: 1.0463 (1.0929)  loss_giou_3: 1.0319 (1.0835)  loss_ce_4: 0.6339 (0.6569)  loss_bbox_4: 1.0418 (1.0765)  loss_giou_4: 0.9832 (1.0675)  loss_ce_unscaled: 0.6386 (0.6580)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2021 (0.2268)  loss_giou_unscaled: 0.5443 (0.5487)  cardinality_error_unscaled: 2.2500 (2.2225)  loss_ce_0_unscaled: 0.6430 (0.6571)  loss_bbox_0_unscaled: 0.2029 (0.2286)  loss_giou_0_unscaled: 0.5121 (0.5704)  cardinality_error_0_unscaled: 2.2500 (2.2212)  loss_ce_1_unscaled: 0.6453 (0.6636)  loss_bbox_1_unscaled: 0.1979 (0.2173)  loss_giou_1_unscaled: 0.4786 (0.5425)  cardinality_error_1_unscaled: 2.2500 (2.2225)  loss_ce_2_unscaled: 0.6411 (0.6631)  loss_bbox_2_unscaled: 0.2115 (0.2255)  loss_giou_2_unscaled: 0.5172 (0.5577)  cardinality_error_2_unscaled: 2.2500 (2.2225)  loss_ce_3_unscaled: 0.6439 (0.6596)  loss_bbox_3_unscaled: 0.2093 (0.2186)  loss_giou_3_unscaled: 0.5160 (0.5417)  cardinality_error_3_unscaled: 2.2500 (2.2225)  loss_ce_4_unscaled: 0.6339 (0.6569)  loss_bbox_4_unscaled: 0.2084 (0.2153)  loss_giou_4_unscaled: 0.4916 (0.5338)  cardinality_error_4_unscaled: 2.2500 (2.2225)  time: 0.3186  data: 0.0296  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [100/248]  eta: 0:00:52  lr: 0.000100  class_error: 100.00  loss: 16.8988 (17.2516)  loss_ce: 0.6450 (0.6579)  loss_bbox: 1.1590 (1.1255)  loss_giou: 1.1021 (1.0957)  loss_ce_0: 0.6538 (0.6593)  loss_bbox_0: 1.0844 (1.1437)  loss_giou_0: 1.0496 (1.1455)  loss_ce_1: 0.6527 (0.6662)  loss_bbox_1: 1.1544 (1.1053)  loss_giou_1: 1.0754 (1.1048)  loss_ce_2: 0.6551 (0.6628)  loss_bbox_2: 1.0660 (1.1251)  loss_giou_2: 1.0620 (1.1188)  loss_ce_3: 0.6502 (0.6604)  loss_bbox_3: 1.0773 (1.0918)  loss_giou_3: 1.0737 (1.0862)  loss_ce_4: 0.6448 (0.6584)  loss_bbox_4: 1.0708 (1.0733)  loss_giou_4: 1.0293 (1.0709)  loss_ce_unscaled: 0.6450 (0.6579)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2318 (0.2251)  loss_giou_unscaled: 0.5511 (0.5479)  cardinality_error_unscaled: 2.2500 (2.2240)  loss_ce_0_unscaled: 0.6538 (0.6593)  loss_bbox_0_unscaled: 0.2169 (0.2287)  loss_giou_0_unscaled: 0.5248 (0.5727)  cardinality_error_0_unscaled: 2.2500 (2.2228)  loss_ce_1_unscaled: 0.6527 (0.6662)  loss_bbox_1_unscaled: 0.2309 (0.2211)  loss_giou_1_unscaled: 0.5377 (0.5524)  cardinality_error_1_unscaled: 2.2500 (2.2240)  loss_ce_2_unscaled: 0.6551 (0.6628)  loss_bbox_2_unscaled: 0.2132 (0.2250)  loss_giou_2_unscaled: 0.5310 (0.5594)  cardinality_error_2_unscaled: 2.2500 (2.2240)  loss_ce_3_unscaled: 0.6502 (0.6604)  loss_bbox_3_unscaled: 0.2155 (0.2184)  loss_giou_3_unscaled: 0.5369 (0.5431)  cardinality_error_3_unscaled: 2.2500 (2.2240)  loss_ce_4_unscaled: 0.6448 (0.6584)  loss_bbox_4_unscaled: 0.2142 (0.2147)  loss_giou_4_unscaled: 0.5147 (0.5355)  cardinality_error_4_unscaled: 2.2500 (2.2240)  time: 0.3244  data: 0.0293  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [110/248]  eta: 0:00:49  lr: 0.000100  class_error: 100.00  loss: 17.2544 (17.2003)  loss_ce: 0.6462 (0.6579)  loss_bbox: 0.9967 (1.1112)  loss_giou: 1.0526 (1.0916)  loss_ce_0: 0.6705 (0.6607)  loss_bbox_0: 1.1222 (1.1307)  loss_giou_0: 1.1374 (1.1419)  loss_ce_1: 0.6889 (0.6674)  loss_bbox_1: 1.1544 (1.0986)  loss_giou_1: 1.1414 (1.1051)  loss_ce_2: 0.6682 (0.6642)  loss_bbox_2: 1.0365 (1.1178)  loss_giou_2: 1.0727 (1.1193)  loss_ce_3: 0.6609 (0.6609)  loss_bbox_3: 1.0730 (1.0890)  loss_giou_3: 1.0707 (1.0909)  loss_ce_4: 0.6633 (0.6589)  loss_bbox_4: 1.0067 (1.0646)  loss_giou_4: 1.0712 (1.0697)  loss_ce_unscaled: 0.6462 (0.6579)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1993 (0.2222)  loss_giou_unscaled: 0.5263 (0.5458)  cardinality_error_unscaled: 2.2500 (2.2297)  loss_ce_0_unscaled: 0.6705 (0.6607)  loss_bbox_0_unscaled: 0.2244 (0.2261)  loss_giou_0_unscaled: 0.5687 (0.5709)  cardinality_error_0_unscaled: 2.2500 (2.2286)  loss_ce_1_unscaled: 0.6889 (0.6674)  loss_bbox_1_unscaled: 0.2309 (0.2197)  loss_giou_1_unscaled: 0.5707 (0.5525)  cardinality_error_1_unscaled: 2.2500 (2.2264)  loss_ce_2_unscaled: 0.6682 (0.6642)  loss_bbox_2_unscaled: 0.2073 (0.2236)  loss_giou_2_unscaled: 0.5364 (0.5597)  cardinality_error_2_unscaled: 2.2500 (2.2297)  loss_ce_3_unscaled: 0.6609 (0.6609)  loss_bbox_3_unscaled: 0.2146 (0.2178)  loss_giou_3_unscaled: 0.5353 (0.5455)  cardinality_error_3_unscaled: 2.2500 (2.2297)  loss_ce_4_unscaled: 0.6633 (0.6589)  loss_bbox_4_unscaled: 0.2013 (0.2129)  loss_giou_4_unscaled: 0.5356 (0.5348)  cardinality_error_4_unscaled: 2.2500 (2.2297)  time: 0.3452  data: 0.0291  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [120/248]  eta: 0:00:45  lr: 0.000100  class_error: 100.00  loss: 16.4405 (17.1728)  loss_ce: 0.6341 (0.6552)  loss_bbox: 1.0104 (1.1194)  loss_giou: 1.0273 (1.0873)  loss_ce_0: 0.6505 (0.6592)  loss_bbox_0: 1.0735 (1.1318)  loss_giou_0: 1.0397 (1.1304)  loss_ce_1: 0.6464 (0.6653)  loss_bbox_1: 1.0459 (1.1041)  loss_giou_1: 1.0585 (1.0976)  loss_ce_2: 0.6519 (0.6617)  loss_bbox_2: 1.0236 (1.1202)  loss_giou_2: 1.0277 (1.1093)  loss_ce_3: 0.6476 (0.6592)  loss_bbox_3: 1.0942 (1.0960)  loss_giou_3: 1.0323 (1.0835)  loss_ce_4: 0.6496 (0.6575)  loss_bbox_4: 1.0318 (1.0714)  loss_giou_4: 1.0305 (1.0637)  loss_ce_unscaled: 0.6341 (0.6552)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2021 (0.2239)  loss_giou_unscaled: 0.5136 (0.5436)  cardinality_error_unscaled: 2.1250 (2.2231)  loss_ce_0_unscaled: 0.6505 (0.6592)  loss_bbox_0_unscaled: 0.2147 (0.2264)  loss_giou_0_unscaled: 0.5198 (0.5652)  cardinality_error_0_unscaled: 2.1250 (2.2221)  loss_ce_1_unscaled: 0.6464 (0.6653)  loss_bbox_1_unscaled: 0.2092 (0.2208)  loss_giou_1_unscaled: 0.5293 (0.5488)  cardinality_error_1_unscaled: 2.1250 (2.2200)  loss_ce_2_unscaled: 0.6519 (0.6617)  loss_bbox_2_unscaled: 0.2047 (0.2240)  loss_giou_2_unscaled: 0.5139 (0.5546)  cardinality_error_2_unscaled: 2.1250 (2.2231)  loss_ce_3_unscaled: 0.6476 (0.6592)  loss_bbox_3_unscaled: 0.2188 (0.2192)  loss_giou_3_unscaled: 0.5162 (0.5417)  cardinality_error_3_unscaled: 2.1250 (2.2231)  loss_ce_4_unscaled: 0.6496 (0.6575)  loss_bbox_4_unscaled: 0.2064 (0.2143)  loss_giou_4_unscaled: 0.5152 (0.5319)  cardinality_error_4_unscaled: 2.1250 (2.2231)  time: 0.3467  data: 0.0300  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [130/248]  eta: 0:00:41  lr: 0.000100  class_error: 100.00  loss: 16.7769 (17.1688)  loss_ce: 0.6511 (0.6573)  loss_bbox: 1.0509 (1.1145)  loss_giou: 1.0272 (1.0848)  loss_ce_0: 0.6694 (0.6615)  loss_bbox_0: 1.1041 (1.1334)  loss_giou_0: 1.0812 (1.1358)  loss_ce_1: 0.6724 (0.6676)  loss_bbox_1: 1.0459 (1.1004)  loss_giou_1: 1.0568 (1.0977)  loss_ce_2: 0.6593 (0.6642)  loss_bbox_2: 1.0236 (1.1152)  loss_giou_2: 1.0150 (1.1074)  loss_ce_3: 0.6616 (0.6611)  loss_bbox_3: 1.1084 (1.0932)  loss_giou_3: 1.0323 (1.0832)  loss_ce_4: 0.6549 (0.6596)  loss_bbox_4: 1.0676 (1.0693)  loss_giou_4: 1.0327 (1.0629)  loss_ce_unscaled: 0.6511 (0.6573)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2102 (0.2229)  loss_giou_unscaled: 0.5136 (0.5424)  cardinality_error_unscaled: 2.2500 (2.2366)  loss_ce_0_unscaled: 0.6694 (0.6615)  loss_bbox_0_unscaled: 0.2208 (0.2267)  loss_giou_0_unscaled: 0.5406 (0.5679)  cardinality_error_0_unscaled: 2.2500 (2.2357)  loss_ce_1_unscaled: 0.6724 (0.6676)  loss_bbox_1_unscaled: 0.2092 (0.2201)  loss_giou_1_unscaled: 0.5284 (0.5488)  cardinality_error_1_unscaled: 2.2500 (2.2338)  loss_ce_2_unscaled: 0.6593 (0.6642)  loss_bbox_2_unscaled: 0.2047 (0.2230)  loss_giou_2_unscaled: 0.5075 (0.5537)  cardinality_error_2_unscaled: 2.2500 (2.2357)  loss_ce_3_unscaled: 0.6616 (0.6611)  loss_bbox_3_unscaled: 0.2217 (0.2186)  loss_giou_3_unscaled: 0.5162 (0.5416)  cardinality_error_3_unscaled: 2.2500 (2.2366)  loss_ce_4_unscaled: 0.6549 (0.6596)  loss_bbox_4_unscaled: 0.2135 (0.2139)  loss_giou_4_unscaled: 0.5163 (0.5314)  cardinality_error_4_unscaled: 2.2500 (2.2366)  time: 0.3473  data: 0.0298  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [140/248]  eta: 0:00:38  lr: 0.000100  class_error: 100.00  loss: 17.0165 (17.1667)  loss_ce: 0.6618 (0.6559)  loss_bbox: 0.9705 (1.1053)  loss_giou: 1.0463 (1.0894)  loss_ce_0: 0.6694 (0.6603)  loss_bbox_0: 1.0376 (1.1280)  loss_giou_0: 1.1557 (1.1376)  loss_ce_1: 0.6739 (0.6654)  loss_bbox_1: 1.0057 (1.0954)  loss_giou_1: 1.1085 (1.1001)  loss_ce_2: 0.6697 (0.6626)  loss_bbox_2: 1.0843 (1.1134)  loss_giou_2: 1.1230 (1.1125)  loss_ce_3: 0.6625 (0.6599)  loss_bbox_3: 1.0930 (1.0900)  loss_giou_3: 1.0939 (1.0889)  loss_ce_4: 0.6650 (0.6589)  loss_bbox_4: 1.0553 (1.0706)  loss_giou_4: 1.0647 (1.0725)  loss_ce_unscaled: 0.6618 (0.6559)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1941 (0.2211)  loss_giou_unscaled: 0.5231 (0.5447)  cardinality_error_unscaled: 2.2500 (2.2385)  loss_ce_0_unscaled: 0.6694 (0.6603)  loss_bbox_0_unscaled: 0.2075 (0.2256)  loss_giou_0_unscaled: 0.5778 (0.5688)  cardinality_error_0_unscaled: 2.2500 (2.2376)  loss_ce_1_unscaled: 0.6739 (0.6654)  loss_bbox_1_unscaled: 0.2011 (0.2191)  loss_giou_1_unscaled: 0.5543 (0.5500)  cardinality_error_1_unscaled: 2.2500 (2.2358)  loss_ce_2_unscaled: 0.6697 (0.6626)  loss_bbox_2_unscaled: 0.2169 (0.2227)  loss_giou_2_unscaled: 0.5615 (0.5563)  cardinality_error_2_unscaled: 2.2500 (2.2376)  loss_ce_3_unscaled: 0.6625 (0.6599)  loss_bbox_3_unscaled: 0.2186 (0.2180)  loss_giou_3_unscaled: 0.5469 (0.5444)  cardinality_error_3_unscaled: 2.2500 (2.2385)  loss_ce_4_unscaled: 0.6650 (0.6589)  loss_bbox_4_unscaled: 0.2111 (0.2141)  loss_giou_4_unscaled: 0.5323 (0.5363)  cardinality_error_4_unscaled: 2.2500 (2.2385)  time: 0.3372  data: 0.0287  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [150/248]  eta: 0:00:34  lr: 0.000100  class_error: 100.00  loss: 17.5891 (17.1891)  loss_ce: 0.6426 (0.6562)  loss_bbox: 0.9802 (1.1084)  loss_giou: 1.1590 (1.0912)  loss_ce_0: 0.6510 (0.6613)  loss_bbox_0: 1.0675 (1.1307)  loss_giou_0: 1.1557 (1.1380)  loss_ce_1: 0.6393 (0.6653)  loss_bbox_1: 1.0612 (1.1002)  loss_giou_1: 1.1468 (1.1033)  loss_ce_2: 0.6375 (0.6632)  loss_bbox_2: 1.1108 (1.1139)  loss_giou_2: 1.1230 (1.1123)  loss_ce_3: 0.6507 (0.6608)  loss_bbox_3: 1.0782 (1.0911)  loss_giou_3: 1.0970 (1.0898)  loss_ce_4: 0.6539 (0.6591)  loss_bbox_4: 1.0186 (1.0703)  loss_giou_4: 1.1131 (1.0742)  loss_ce_unscaled: 0.6426 (0.6562)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1960 (0.2217)  loss_giou_unscaled: 0.5795 (0.5456)  cardinality_error_unscaled: 2.2500 (2.2417)  loss_ce_0_unscaled: 0.6510 (0.6613)  loss_bbox_0_unscaled: 0.2135 (0.2261)  loss_giou_0_unscaled: 0.5778 (0.5690)  cardinality_error_0_unscaled: 2.2500 (2.2409)  loss_ce_1_unscaled: 0.6393 (0.6653)  loss_bbox_1_unscaled: 0.2122 (0.2200)  loss_giou_1_unscaled: 0.5734 (0.5516)  cardinality_error_1_unscaled: 2.2500 (2.2392)  loss_ce_2_unscaled: 0.6375 (0.6632)  loss_bbox_2_unscaled: 0.2222 (0.2228)  loss_giou_2_unscaled: 0.5615 (0.5562)  cardinality_error_2_unscaled: 2.2500 (2.2409)  loss_ce_3_unscaled: 0.6507 (0.6608)  loss_bbox_3_unscaled: 0.2156 (0.2182)  loss_giou_3_unscaled: 0.5485 (0.5449)  cardinality_error_3_unscaled: 2.2500 (2.2417)  loss_ce_4_unscaled: 0.6539 (0.6591)  loss_bbox_4_unscaled: 0.2037 (0.2141)  loss_giou_4_unscaled: 0.5565 (0.5371)  cardinality_error_4_unscaled: 2.2500 (2.2417)  time: 0.3615  data: 0.0629  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [160/248]  eta: 0:00:31  lr: 0.000100  class_error: 100.00  loss: 17.3932 (17.2177)  loss_ce: 0.6668 (0.6576)  loss_bbox: 1.1301 (1.1111)  loss_giou: 1.0574 (1.0909)  loss_ce_0: 0.6694 (0.6622)  loss_bbox_0: 1.1330 (1.1332)  loss_giou_0: 1.0653 (1.1354)  loss_ce_1: 0.6841 (0.6664)  loss_bbox_1: 1.1029 (1.1062)  loss_giou_1: 1.1074 (1.1024)  loss_ce_2: 0.6677 (0.6648)  loss_bbox_2: 1.1262 (1.1194)  loss_giou_2: 1.0717 (1.1113)  loss_ce_3: 0.6871 (0.6622)  loss_bbox_3: 1.1098 (1.0953)  loss_giou_3: 1.0718 (1.0879)  loss_ce_4: 0.6642 (0.6596)  loss_bbox_4: 1.0856 (1.0763)  loss_giou_4: 1.0179 (1.0757)  loss_ce_unscaled: 0.6668 (0.6576)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2260 (0.2222)  loss_giou_unscaled: 0.5287 (0.5455)  cardinality_error_unscaled: 2.2500 (2.2438)  loss_ce_0_unscaled: 0.6694 (0.6622)  loss_bbox_0_unscaled: 0.2266 (0.2266)  loss_giou_0_unscaled: 0.5327 (0.5677)  cardinality_error_0_unscaled: 2.2500 (2.2430)  loss_ce_1_unscaled: 0.6841 (0.6664)  loss_bbox_1_unscaled: 0.2206 (0.2212)  loss_giou_1_unscaled: 0.5537 (0.5512)  cardinality_error_1_unscaled: 2.2500 (2.2415)  loss_ce_2_unscaled: 0.6677 (0.6648)  loss_bbox_2_unscaled: 0.2252 (0.2239)  loss_giou_2_unscaled: 0.5358 (0.5557)  cardinality_error_2_unscaled: 2.2500 (2.2430)  loss_ce_3_unscaled: 0.6871 (0.6622)  loss_bbox_3_unscaled: 0.2220 (0.2191)  loss_giou_3_unscaled: 0.5359 (0.5439)  cardinality_error_3_unscaled: 2.2500 (2.2438)  loss_ce_4_unscaled: 0.6642 (0.6596)  loss_bbox_4_unscaled: 0.2171 (0.2153)  loss_giou_4_unscaled: 0.5090 (0.5378)  cardinality_error_4_unscaled: 2.2500 (2.2438)  time: 0.3752  data: 0.0636  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [170/248]  eta: 0:00:27  lr: 0.000100  class_error: 100.00  loss: 16.9723 (17.1749)  loss_ce: 0.6531 (0.6577)  loss_bbox: 1.0241 (1.1053)  loss_giou: 1.0839 (1.0914)  loss_ce_0: 0.6575 (0.6625)  loss_bbox_0: 1.0064 (1.1240)  loss_giou_0: 1.0533 (1.1295)  loss_ce_1: 0.6625 (0.6672)  loss_bbox_1: 0.9953 (1.0981)  loss_giou_1: 1.0378 (1.0987)  loss_ce_2: 0.6539 (0.6653)  loss_bbox_2: 1.0541 (1.1152)  loss_giou_2: 1.0825 (1.1108)  loss_ce_3: 0.6602 (0.6627)  loss_bbox_3: 1.0720 (1.0907)  loss_giou_3: 1.0718 (1.0854)  loss_ce_4: 0.6642 (0.6609)  loss_bbox_4: 1.1337 (1.0743)  loss_giou_4: 1.0087 (1.0752)  loss_ce_unscaled: 0.6531 (0.6577)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2048 (0.2211)  loss_giou_unscaled: 0.5420 (0.5457)  cardinality_error_unscaled: 2.2500 (2.2507)  loss_ce_0_unscaled: 0.6575 (0.6625)  loss_bbox_0_unscaled: 0.2013 (0.2248)  loss_giou_0_unscaled: 0.5267 (0.5648)  cardinality_error_0_unscaled: 2.2500 (2.2500)  loss_ce_1_unscaled: 0.6625 (0.6672)  loss_bbox_1_unscaled: 0.1991 (0.2196)  loss_giou_1_unscaled: 0.5189 (0.5493)  cardinality_error_1_unscaled: 2.2500 (2.2485)  loss_ce_2_unscaled: 0.6539 (0.6653)  loss_bbox_2_unscaled: 0.2108 (0.2230)  loss_giou_2_unscaled: 0.5413 (0.5554)  cardinality_error_2_unscaled: 2.2500 (2.2500)  loss_ce_3_unscaled: 0.6602 (0.6627)  loss_bbox_3_unscaled: 0.2144 (0.2181)  loss_giou_3_unscaled: 0.5359 (0.5427)  cardinality_error_3_unscaled: 2.2500 (2.2507)  loss_ce_4_unscaled: 0.6642 (0.6609)  loss_bbox_4_unscaled: 0.2267 (0.2149)  loss_giou_4_unscaled: 0.5044 (0.5376)  cardinality_error_4_unscaled: 2.2500 (2.2507)  time: 0.3398  data: 0.0294  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [180/248]  eta: 0:00:24  lr: 0.000100  class_error: 100.00  loss: 16.4681 (17.1509)  loss_ce: 0.6654 (0.6592)  loss_bbox: 1.0328 (1.1056)  loss_giou: 1.0252 (1.0879)  loss_ce_0: 0.6728 (0.6637)  loss_bbox_0: 1.0099 (1.1227)  loss_giou_0: 1.0115 (1.1229)  loss_ce_1: 0.6936 (0.6692)  loss_bbox_1: 1.0022 (1.0963)  loss_giou_1: 0.9854 (1.0940)  loss_ce_2: 0.6924 (0.6668)  loss_bbox_2: 1.0623 (1.1158)  loss_giou_2: 1.0545 (1.1072)  loss_ce_3: 0.6728 (0.6636)  loss_bbox_3: 1.0514 (1.0884)  loss_giou_3: 1.0045 (1.0799)  loss_ce_4: 0.6705 (0.6622)  loss_bbox_4: 1.0120 (1.0743)  loss_giou_4: 0.9759 (1.0712)  loss_ce_unscaled: 0.6654 (0.6592)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2066 (0.2211)  loss_giou_unscaled: 0.5126 (0.5439)  cardinality_error_unscaled: 2.3750 (2.2562)  loss_ce_0_unscaled: 0.6728 (0.6637)  loss_bbox_0_unscaled: 0.2020 (0.2245)  loss_giou_0_unscaled: 0.5057 (0.5614)  cardinality_error_0_unscaled: 2.3750 (2.2555)  loss_ce_1_unscaled: 0.6936 (0.6692)  loss_bbox_1_unscaled: 0.2004 (0.2193)  loss_giou_1_unscaled: 0.4927 (0.5470)  cardinality_error_1_unscaled: 2.3750 (2.2541)  loss_ce_2_unscaled: 0.6924 (0.6668)  loss_bbox_2_unscaled: 0.2125 (0.2232)  loss_giou_2_unscaled: 0.5273 (0.5536)  cardinality_error_2_unscaled: 2.3750 (2.2555)  loss_ce_3_unscaled: 0.6728 (0.6636)  loss_bbox_3_unscaled: 0.2103 (0.2177)  loss_giou_3_unscaled: 0.5023 (0.5400)  cardinality_error_3_unscaled: 2.3750 (2.2562)  loss_ce_4_unscaled: 0.6705 (0.6622)  loss_bbox_4_unscaled: 0.2024 (0.2149)  loss_giou_4_unscaled: 0.4880 (0.5356)  cardinality_error_4_unscaled: 2.3750 (2.2562)  time: 0.3410  data: 0.0297  max mem: 13354
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [190/248]  eta: 0:00:20  lr: 0.000100  class_error: 100.00  loss: 16.4681 (17.0983)  loss_ce: 0.6583 (0.6583)  loss_bbox: 1.0428 (1.1020)  loss_giou: 1.0252 (1.0858)  loss_ce_0: 0.6737 (0.6644)  loss_bbox_0: 1.0967 (1.1192)  loss_giou_0: 1.0115 (1.1200)  loss_ce_1: 0.6904 (0.6698)  loss_bbox_1: 1.0452 (1.0903)  loss_giou_1: 0.9598 (1.0875)  loss_ce_2: 0.6898 (0.6672)  loss_bbox_2: 1.0034 (1.1073)  loss_giou_2: 0.9923 (1.1001)  loss_ce_3: 0.6728 (0.6637)  loss_bbox_3: 0.9874 (1.0831)  loss_giou_3: 0.9879 (1.0754)  loss_ce_4: 0.6622 (0.6623)  loss_bbox_4: 1.0047 (1.0721)  loss_giou_4: 1.0380 (1.0699)  loss_ce_unscaled: 0.6583 (0.6583)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2086 (0.2204)  loss_giou_unscaled: 0.5126 (0.5429)  cardinality_error_unscaled: 2.2500 (2.2585)  loss_ce_0_unscaled: 0.6737 (0.6644)  loss_bbox_0_unscaled: 0.2193 (0.2238)  loss_giou_0_unscaled: 0.5057 (0.5600)  cardinality_error_0_unscaled: 2.2500 (2.2579)  loss_ce_1_unscaled: 0.6904 (0.6698)  loss_bbox_1_unscaled: 0.2090 (0.2181)  loss_giou_1_unscaled: 0.4799 (0.5437)  cardinality_error_1_unscaled: 2.2500 (2.2565)  loss_ce_2_unscaled: 0.6898 (0.6672)  loss_bbox_2_unscaled: 0.2007 (0.2215)  loss_giou_2_unscaled: 0.4962 (0.5500)  cardinality_error_2_unscaled: 2.2500 (2.2579)  loss_ce_3_unscaled: 0.6728 (0.6637)  loss_bbox_3_unscaled: 0.1975 (0.2166)  loss_giou_3_unscaled: 0.4940 (0.5377)  cardinality_error_3_unscaled: 2.2500 (2.2585)  loss_ce_4_unscaled: 0.6622 (0.6623)  loss_bbox_4_unscaled: 0.2009 (0.2144)  loss_giou_4_unscaled: 0.5190 (0.5350)  cardinality_error_4_unscaled: 2.2500 (2.2585)  time: 0.3737  data: 0.0309  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [200/248]  eta: 0:00:17  lr: 0.000100  class_error: 100.00  loss: 15.8816 (17.0571)  loss_ce: 0.6489 (0.6584)  loss_bbox: 0.9276 (1.0920)  loss_giou: 1.0355 (1.0826)  loss_ce_0: 0.6737 (0.6657)  loss_bbox_0: 1.0134 (1.1120)  loss_giou_0: 1.0458 (1.1208)  loss_ce_1: 0.6811 (0.6707)  loss_bbox_1: 1.0185 (1.0873)  loss_giou_1: 1.0251 (1.0920)  loss_ce_2: 0.6695 (0.6676)  loss_bbox_2: 0.9619 (1.0998)  loss_giou_2: 0.9988 (1.0996)  loss_ce_3: 0.6658 (0.6647)  loss_bbox_3: 0.9201 (1.0748)  loss_giou_3: 1.0118 (1.0765)  loss_ce_4: 0.6600 (0.6625)  loss_bbox_4: 0.9124 (1.0628)  loss_giou_4: 1.0307 (1.0673)  loss_ce_unscaled: 0.6489 (0.6584)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1855 (0.2184)  loss_giou_unscaled: 0.5177 (0.5413)  cardinality_error_unscaled: 2.2500 (2.2637)  loss_ce_0_unscaled: 0.6737 (0.6657)  loss_bbox_0_unscaled: 0.2027 (0.2224)  loss_giou_0_unscaled: 0.5229 (0.5604)  cardinality_error_0_unscaled: 2.2500 (2.2631)  loss_ce_1_unscaled: 0.6811 (0.6707)  loss_bbox_1_unscaled: 0.2037 (0.2175)  loss_giou_1_unscaled: 0.5125 (0.5460)  cardinality_error_1_unscaled: 2.2500 (2.2618)  loss_ce_2_unscaled: 0.6695 (0.6676)  loss_bbox_2_unscaled: 0.1924 (0.2200)  loss_giou_2_unscaled: 0.4994 (0.5498)  cardinality_error_2_unscaled: 2.2500 (2.2631)  loss_ce_3_unscaled: 0.6658 (0.6647)  loss_bbox_3_unscaled: 0.1840 (0.2150)  loss_giou_3_unscaled: 0.5059 (0.5383)  cardinality_error_3_unscaled: 2.2500 (2.2637)  loss_ce_4_unscaled: 0.6600 (0.6625)  loss_bbox_4_unscaled: 0.1825 (0.2126)  loss_giou_4_unscaled: 0.5154 (0.5337)  cardinality_error_4_unscaled: 2.2500 (2.2637)  time: 0.3689  data: 0.0305  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [210/248]  eta: 0:00:13  lr: 0.000100  class_error: 100.00  loss: 16.0977 (17.0167)  loss_ce: 0.6502 (0.6587)  loss_bbox: 0.9260 (1.0871)  loss_giou: 1.0549 (1.0794)  loss_ce_0: 0.6630 (0.6657)  loss_bbox_0: 1.0037 (1.1071)  loss_giou_0: 1.0458 (1.1185)  loss_ce_1: 0.6734 (0.6705)  loss_bbox_1: 1.0114 (1.0824)  loss_giou_1: 1.0888 (1.0887)  loss_ce_2: 0.6632 (0.6675)  loss_bbox_2: 0.9619 (1.0962)  loss_giou_2: 1.0506 (1.0965)  loss_ce_3: 0.6609 (0.6644)  loss_bbox_3: 0.9408 (1.0707)  loss_giou_3: 1.0547 (1.0746)  loss_ce_4: 0.6533 (0.6629)  loss_bbox_4: 0.9464 (1.0593)  loss_giou_4: 1.0063 (1.0666)  loss_ce_unscaled: 0.6502 (0.6587)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1852 (0.2174)  loss_giou_unscaled: 0.5274 (0.5397)  cardinality_error_unscaled: 2.2500 (2.2654)  loss_ce_0_unscaled: 0.6630 (0.6657)  loss_bbox_0_unscaled: 0.2007 (0.2214)  loss_giou_0_unscaled: 0.5229 (0.5593)  cardinality_error_0_unscaled: 2.2500 (2.2654)  loss_ce_1_unscaled: 0.6734 (0.6705)  loss_bbox_1_unscaled: 0.2023 (0.2165)  loss_giou_1_unscaled: 0.5444 (0.5443)  cardinality_error_1_unscaled: 2.2500 (2.2642)  loss_ce_2_unscaled: 0.6632 (0.6675)  loss_bbox_2_unscaled: 0.1924 (0.2192)  loss_giou_2_unscaled: 0.5253 (0.5482)  cardinality_error_2_unscaled: 2.2500 (2.2654)  loss_ce_3_unscaled: 0.6609 (0.6644)  loss_bbox_3_unscaled: 0.1882 (0.2141)  loss_giou_3_unscaled: 0.5273 (0.5373)  cardinality_error_3_unscaled: 2.2500 (2.2648)  loss_ce_4_unscaled: 0.6533 (0.6629)  loss_bbox_4_unscaled: 0.1893 (0.2119)  loss_giou_4_unscaled: 0.5031 (0.5333)  cardinality_error_4_unscaled: 2.2500 (2.2660)  time: 0.3445  data: 0.0295  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [220/248]  eta: 0:00:09  lr: 0.000100  class_error: 100.00  loss: 16.7669 (17.0257)  loss_ce: 0.6379 (0.6587)  loss_bbox: 1.0284 (1.0860)  loss_giou: 1.0584 (1.0781)  loss_ce_0: 0.6511 (0.6644)  loss_bbox_0: 1.1059 (1.1119)  loss_giou_0: 1.0956 (1.1206)  loss_ce_1: 0.6626 (0.6704)  loss_bbox_1: 1.0153 (1.0856)  loss_giou_1: 1.0652 (1.0913)  loss_ce_2: 0.6430 (0.6674)  loss_bbox_2: 1.0437 (1.0962)  loss_giou_2: 1.0652 (1.0978)  loss_ce_3: 0.6491 (0.6648)  loss_bbox_3: 1.0231 (1.0696)  loss_giou_3: 1.0412 (1.0734)  loss_ce_4: 0.6605 (0.6633)  loss_bbox_4: 1.0224 (1.0605)  loss_giou_4: 1.0079 (1.0657)  loss_ce_unscaled: 0.6379 (0.6587)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2057 (0.2172)  loss_giou_unscaled: 0.5292 (0.5390)  cardinality_error_unscaled: 2.1250 (2.2607)  loss_ce_0_unscaled: 0.6511 (0.6644)  loss_bbox_0_unscaled: 0.2212 (0.2224)  loss_giou_0_unscaled: 0.5478 (0.5603)  cardinality_error_0_unscaled: 2.1250 (2.2607)  loss_ce_1_unscaled: 0.6626 (0.6704)  loss_bbox_1_unscaled: 0.2031 (0.2171)  loss_giou_1_unscaled: 0.5326 (0.5456)  cardinality_error_1_unscaled: 2.1250 (2.2596)  loss_ce_2_unscaled: 0.6430 (0.6674)  loss_bbox_2_unscaled: 0.2087 (0.2192)  loss_giou_2_unscaled: 0.5326 (0.5489)  cardinality_error_2_unscaled: 2.1250 (2.2607)  loss_ce_3_unscaled: 0.6491 (0.6648)  loss_bbox_3_unscaled: 0.2046 (0.2139)  loss_giou_3_unscaled: 0.5206 (0.5367)  cardinality_error_3_unscaled: 2.1250 (2.2602)  loss_ce_4_unscaled: 0.6605 (0.6633)  loss_bbox_4_unscaled: 0.2045 (0.2121)  loss_giou_4_unscaled: 0.5039 (0.5328)  cardinality_error_4_unscaled: 2.1250 (2.2613)  time: 0.3564  data: 0.0301  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [230/248]  eta: 0:00:06  lr: 0.000100  class_error: 100.00  loss: 16.9623 (17.0306)  loss_ce: 0.6379 (0.6581)  loss_bbox: 1.0113 (1.0839)  loss_giou: 1.0788 (1.0799)  loss_ce_0: 0.6302 (0.6639)  loss_bbox_0: 1.1228 (1.1110)  loss_giou_0: 1.1221 (1.1227)  loss_ce_1: 0.6626 (0.6705)  loss_bbox_1: 1.0153 (1.0851)  loss_giou_1: 1.0828 (1.0931)  loss_ce_2: 0.6409 (0.6672)  loss_bbox_2: 1.0489 (1.0954)  loss_giou_2: 1.1057 (1.0979)  loss_ce_3: 0.6491 (0.6646)  loss_bbox_3: 1.0231 (1.0700)  loss_giou_3: 1.0809 (1.0772)  loss_ce_4: 0.6622 (0.6626)  loss_bbox_4: 1.0224 (1.0600)  loss_giou_4: 1.0311 (1.0675)  loss_ce_unscaled: 0.6379 (0.6581)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2023 (0.2168)  loss_giou_unscaled: 0.5394 (0.5400)  cardinality_error_unscaled: 2.1250 (2.2619)  loss_ce_0_unscaled: 0.6302 (0.6639)  loss_bbox_0_unscaled: 0.2246 (0.2222)  loss_giou_0_unscaled: 0.5610 (0.5613)  cardinality_error_0_unscaled: 2.1250 (2.2619)  loss_ce_1_unscaled: 0.6626 (0.6705)  loss_bbox_1_unscaled: 0.2031 (0.2170)  loss_giou_1_unscaled: 0.5414 (0.5466)  cardinality_error_1_unscaled: 2.1250 (2.2608)  loss_ce_2_unscaled: 0.6409 (0.6672)  loss_bbox_2_unscaled: 0.2098 (0.2191)  loss_giou_2_unscaled: 0.5528 (0.5490)  cardinality_error_2_unscaled: 2.1250 (2.2619)  loss_ce_3_unscaled: 0.6491 (0.6646)  loss_bbox_3_unscaled: 0.2046 (0.2140)  loss_giou_3_unscaled: 0.5405 (0.5386)  cardinality_error_3_unscaled: 2.1250 (2.2614)  loss_ce_4_unscaled: 0.6622 (0.6626)  loss_bbox_4_unscaled: 0.2045 (0.2120)  loss_giou_4_unscaled: 0.5156 (0.5337)  cardinality_error_4_unscaled: 2.1250 (2.2624)  time: 0.3804  data: 0.0292  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [240/248]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 15.4718 (16.9783)  loss_ce: 0.6121 (0.6564)  loss_bbox: 0.9431 (1.0781)  loss_giou: 0.9688 (1.0759)  loss_ce_0: 0.6413 (0.6632)  loss_bbox_0: 0.9558 (1.1055)  loss_giou_0: 1.0135 (1.1178)  loss_ce_1: 0.6370 (0.6692)  loss_bbox_1: 0.9238 (1.0809)  loss_giou_1: 1.0497 (1.0909)  loss_ce_2: 0.6287 (0.6663)  loss_bbox_2: 0.9810 (1.0919)  loss_giou_2: 1.0541 (1.0950)  loss_ce_3: 0.6269 (0.6633)  loss_bbox_3: 0.9285 (1.0656)  loss_giou_3: 1.0739 (1.0750)  loss_ce_4: 0.6328 (0.6613)  loss_bbox_4: 0.9410 (1.0567)  loss_giou_4: 1.0286 (1.0654)  loss_ce_unscaled: 0.6121 (0.6564)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1886 (0.2156)  loss_giou_unscaled: 0.4844 (0.5379)  cardinality_error_unscaled: 2.1250 (2.2583)  loss_ce_0_unscaled: 0.6413 (0.6632)  loss_bbox_0_unscaled: 0.1912 (0.2211)  loss_giou_0_unscaled: 0.5068 (0.5589)  cardinality_error_0_unscaled: 2.1250 (2.2583)  loss_ce_1_unscaled: 0.6370 (0.6692)  loss_bbox_1_unscaled: 0.1848 (0.2162)  loss_giou_1_unscaled: 0.5249 (0.5455)  cardinality_error_1_unscaled: 2.1250 (2.2573)  loss_ce_2_unscaled: 0.6287 (0.6663)  loss_bbox_2_unscaled: 0.1962 (0.2184)  loss_giou_2_unscaled: 0.5270 (0.5475)  cardinality_error_2_unscaled: 2.1250 (2.2583)  loss_ce_3_unscaled: 0.6269 (0.6633)  loss_bbox_3_unscaled: 0.1857 (0.2131)  loss_giou_3_unscaled: 0.5369 (0.5375)  cardinality_error_3_unscaled: 2.1250 (2.2578)  loss_ce_4_unscaled: 0.6328 (0.6613)  loss_bbox_4_unscaled: 0.1882 (0.2113)  loss_giou_4_unscaled: 0.5143 (0.5327)  cardinality_error_4_unscaled: 2.1250 (2.2588)  time: 0.3980  data: 0.0518  max mem: 14982
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [247/248]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 15.5728 (16.9563)  loss_ce: 0.6254 (0.6565)  loss_bbox: 0.9088 (1.0738)  loss_giou: 1.0081 (1.0749)  loss_ce_0: 0.6535 (0.6640)  loss_bbox_0: 0.9919 (1.1015)  loss_giou_0: 1.0391 (1.1158)  loss_ce_1: 0.6516 (0.6696)  loss_bbox_1: 0.9668 (1.0776)  loss_giou_1: 1.0724 (1.0907)  loss_ce_2: 0.6487 (0.6669)  loss_bbox_2: 0.9794 (1.0888)  loss_giou_2: 1.0662 (1.0958)  loss_ce_3: 0.6399 (0.6636)  loss_bbox_3: 0.9510 (1.0629)  loss_giou_3: 1.0434 (1.0759)  loss_ce_4: 0.6353 (0.6613)  loss_bbox_4: 0.8935 (1.0518)  loss_giou_4: 1.0365 (1.0647)  loss_ce_unscaled: 0.6254 (0.6565)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1818 (0.2148)  loss_giou_unscaled: 0.5040 (0.5375)  cardinality_error_unscaled: 2.2500 (2.2616)  loss_ce_0_unscaled: 0.6535 (0.6640)  loss_bbox_0_unscaled: 0.1984 (0.2203)  loss_giou_0_unscaled: 0.5195 (0.5579)  cardinality_error_0_unscaled: 2.2500 (2.2616)  loss_ce_1_unscaled: 0.6516 (0.6696)  loss_bbox_1_unscaled: 0.1934 (0.2155)  loss_giou_1_unscaled: 0.5362 (0.5454)  cardinality_error_1_unscaled: 2.2500 (2.2606)  loss_ce_2_unscaled: 0.6487 (0.6669)  loss_bbox_2_unscaled: 0.1959 (0.2178)  loss_giou_2_unscaled: 0.5331 (0.5479)  cardinality_error_2_unscaled: 2.2500 (2.2616)  loss_ce_3_unscaled: 0.6399 (0.6636)  loss_bbox_3_unscaled: 0.1902 (0.2126)  loss_giou_3_unscaled: 0.5217 (0.5380)  cardinality_error_3_unscaled: 2.2500 (2.2611)  loss_ce_4_unscaled: 0.6353 (0.6613)  loss_bbox_4_unscaled: 0.1787 (0.2104)  loss_giou_4_unscaled: 0.5182 (0.5323)  cardinality_error_4_unscaled: 2.2500 (2.2621)  time: 0.3851  data: 0.0519  max mem: 14982
Epoch: [2] Total time: 0:01:29 (0.3602 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 15.5728 (16.9563)  loss_ce: 0.6254 (0.6565)  loss_bbox: 0.9088 (1.0738)  loss_giou: 1.0081 (1.0749)  loss_ce_0: 0.6535 (0.6640)  loss_bbox_0: 0.9919 (1.1015)  loss_giou_0: 1.0391 (1.1158)  loss_ce_1: 0.6516 (0.6696)  loss_bbox_1: 0.9668 (1.0776)  loss_giou_1: 1.0724 (1.0907)  loss_ce_2: 0.6487 (0.6669)  loss_bbox_2: 0.9794 (1.0888)  loss_giou_2: 1.0662 (1.0958)  loss_ce_3: 0.6399 (0.6636)  loss_bbox_3: 0.9510 (1.0629)  loss_giou_3: 1.0434 (1.0759)  loss_ce_4: 0.6353 (0.6613)  loss_bbox_4: 0.8935 (1.0518)  loss_giou_4: 1.0365 (1.0647)  loss_ce_unscaled: 0.6254 (0.6565)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1818 (0.2148)  loss_giou_unscaled: 0.5040 (0.5375)  cardinality_error_unscaled: 2.2500 (2.2616)  loss_ce_0_unscaled: 0.6535 (0.6640)  loss_bbox_0_unscaled: 0.1984 (0.2203)  loss_giou_0_unscaled: 0.5195 (0.5579)  cardinality_error_0_unscaled: 2.2500 (2.2616)  loss_ce_1_unscaled: 0.6516 (0.6696)  loss_bbox_1_unscaled: 0.1934 (0.2155)  loss_giou_1_unscaled: 0.5362 (0.5454)  cardinality_error_1_unscaled: 2.2500 (2.2606)  loss_ce_2_unscaled: 0.6487 (0.6669)  loss_bbox_2_unscaled: 0.1959 (0.2178)  loss_giou_2_unscaled: 0.5331 (0.5479)  cardinality_error_2_unscaled: 2.2500 (2.2616)  loss_ce_3_unscaled: 0.6399 (0.6636)  loss_bbox_3_unscaled: 0.1902 (0.2126)  loss_giou_3_unscaled: 0.5217 (0.5380)  cardinality_error_3_unscaled: 2.2500 (2.2611)  loss_ce_4_unscaled: 0.6353 (0.6613)  loss_bbox_4_unscaled: 0.1787 (0.2104)  loss_giou_4_unscaled: 0.5182 (0.5323)  cardinality_error_4_unscaled: 2.2500 (2.2621)

End of training epoch
Total execution time = 89.344 sec
Max memory used by tensors = 15709271040 bytes
Max memory cached = 19377684480 bytes
Total memory reserved = 19377684480 bytes
Total memory allocated = 760503808 bytes
Test:  [ 0/27]  eta: 0:00:32  class_error: 100.00  loss: 34.3489 (34.3489)  loss_ce: 0.5901 (0.5901)  loss_bbox: 3.2038 (3.2038)  loss_giou: 2.0876 (2.0876)  loss_ce_0: 0.6059 (0.6059)  loss_bbox_0: 2.6264 (2.6264)  loss_giou_0: 2.1844 (2.1844)  loss_ce_1: 0.5903 (0.5903)  loss_bbox_1: 2.7090 (2.7090)  loss_giou_1: 2.2093 (2.2093)  loss_ce_2: 0.5929 (0.5929)  loss_bbox_2: 2.8717 (2.8717)  loss_giou_2: 2.0177 (2.0177)  loss_ce_3: 0.5859 (0.5859)  loss_bbox_3: 3.0196 (3.0196)  loss_giou_3: 2.0576 (2.0576)  loss_ce_4: 0.5895 (0.5895)  loss_bbox_4: 3.5088 (3.5088)  loss_giou_4: 2.2984 (2.2984)  loss_ce_unscaled: 0.5901 (0.5901)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.6408 (0.6408)  loss_giou_unscaled: 1.0438 (1.0438)  cardinality_error_unscaled: 2.0000 (2.0000)  loss_ce_0_unscaled: 0.6059 (0.6059)  loss_bbox_0_unscaled: 0.5253 (0.5253)  loss_giou_0_unscaled: 1.0922 (1.0922)  cardinality_error_0_unscaled: 2.0000 (2.0000)  loss_ce_1_unscaled: 0.5903 (0.5903)  loss_bbox_1_unscaled: 0.5418 (0.5418)  loss_giou_1_unscaled: 1.1047 (1.1047)  cardinality_error_1_unscaled: 2.0000 (2.0000)  loss_ce_2_unscaled: 0.5929 (0.5929)  loss_bbox_2_unscaled: 0.5743 (0.5743)  loss_giou_2_unscaled: 1.0089 (1.0089)  cardinality_error_2_unscaled: 2.0000 (2.0000)  loss_ce_3_unscaled: 0.5859 (0.5859)  loss_bbox_3_unscaled: 0.6039 (0.6039)  loss_giou_3_unscaled: 1.0288 (1.0288)  cardinality_error_3_unscaled: 2.0000 (2.0000)  loss_ce_4_unscaled: 0.5895 (0.5895)  loss_bbox_4_unscaled: 0.7018 (0.7018)  loss_giou_4_unscaled: 1.1492 (1.1492)  cardinality_error_4_unscaled: 2.0000 (2.0000)  time: 1.1889  data: 1.0426  max mem: 14982
Test:  [10/27]  eta: 0:00:07  class_error: 100.00  loss: 34.3489 (34.5202)  loss_ce: 0.6285 (0.6345)  loss_bbox: 2.9165 (2.9937)  loss_giou: 2.2518 (2.3316)  loss_ce_0: 0.6475 (0.6516)  loss_bbox_0: 2.7819 (2.7226)  loss_giou_0: 2.2213 (2.4732)  loss_ce_1: 0.6329 (0.6361)  loss_bbox_1: 2.5301 (2.4972)  loss_giou_1: 2.2472 (2.3070)  loss_ce_2: 0.6369 (0.6402)  loss_bbox_2: 2.6981 (2.6746)  loss_giou_2: 2.2051 (2.2234)  loss_ce_3: 0.6295 (0.6331)  loss_bbox_3: 2.6268 (2.7145)  loss_giou_3: 2.1364 (2.2378)  loss_ce_4: 0.6319 (0.6358)  loss_bbox_4: 3.0528 (3.1057)  loss_giou_4: 2.3018 (2.4077)  loss_ce_unscaled: 0.6285 (0.6345)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5833 (0.5987)  loss_giou_unscaled: 1.1259 (1.1658)  cardinality_error_unscaled: 2.2500 (2.2727)  loss_ce_0_unscaled: 0.6475 (0.6516)  loss_bbox_0_unscaled: 0.5564 (0.5445)  loss_giou_0_unscaled: 1.1107 (1.2366)  cardinality_error_0_unscaled: 2.2500 (2.2727)  loss_ce_1_unscaled: 0.6329 (0.6361)  loss_bbox_1_unscaled: 0.5060 (0.4994)  loss_giou_1_unscaled: 1.1236 (1.1535)  cardinality_error_1_unscaled: 2.2500 (2.2727)  loss_ce_2_unscaled: 0.6369 (0.6402)  loss_bbox_2_unscaled: 0.5396 (0.5349)  loss_giou_2_unscaled: 1.1025 (1.1117)  cardinality_error_2_unscaled: 2.2500 (2.2727)  loss_ce_3_unscaled: 0.6295 (0.6331)  loss_bbox_3_unscaled: 0.5254 (0.5429)  loss_giou_3_unscaled: 1.0682 (1.1189)  cardinality_error_3_unscaled: 2.2500 (2.2727)  loss_ce_4_unscaled: 0.6319 (0.6358)  loss_bbox_4_unscaled: 0.6106 (0.6211)  loss_giou_4_unscaled: 1.1509 (1.2039)  cardinality_error_4_unscaled: 2.2500 (2.2727)  time: 0.4231  data: 0.2887  max mem: 14982
Test:  [20/27]  eta: 0:00:02  class_error: 100.00  loss: 32.9707 (33.6427)  loss_ce: 0.6489 (0.6456)  loss_bbox: 2.7286 (2.8136)  loss_giou: 1.9988 (2.2252)  loss_ce_0: 0.6640 (0.6622)  loss_bbox_0: 2.6742 (2.6706)  loss_giou_0: 2.2726 (2.4241)  loss_ce_1: 0.6462 (0.6469)  loss_bbox_1: 2.3971 (2.4222)  loss_giou_1: 2.2739 (2.3037)  loss_ce_2: 0.6530 (0.6519)  loss_bbox_2: 2.6931 (2.6201)  loss_giou_2: 2.2880 (2.2601)  loss_ce_3: 0.6477 (0.6451)  loss_bbox_3: 2.5598 (2.5425)  loss_giou_3: 2.1364 (2.1884)  loss_ce_4: 0.6415 (0.6446)  loss_bbox_4: 2.9636 (2.9714)  loss_giou_4: 2.1473 (2.3045)  loss_ce_unscaled: 0.6489 (0.6456)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5457 (0.5627)  loss_giou_unscaled: 0.9994 (1.1126)  cardinality_error_unscaled: 2.2500 (2.2917)  loss_ce_0_unscaled: 0.6640 (0.6622)  loss_bbox_0_unscaled: 0.5348 (0.5341)  loss_giou_0_unscaled: 1.1363 (1.2120)  cardinality_error_0_unscaled: 2.2500 (2.2917)  loss_ce_1_unscaled: 0.6462 (0.6469)  loss_bbox_1_unscaled: 0.4794 (0.4844)  loss_giou_1_unscaled: 1.1370 (1.1519)  cardinality_error_1_unscaled: 2.2500 (2.2917)  loss_ce_2_unscaled: 0.6530 (0.6519)  loss_bbox_2_unscaled: 0.5386 (0.5240)  loss_giou_2_unscaled: 1.1440 (1.1301)  cardinality_error_2_unscaled: 2.2500 (2.2917)  loss_ce_3_unscaled: 0.6477 (0.6451)  loss_bbox_3_unscaled: 0.5120 (0.5085)  loss_giou_3_unscaled: 1.0682 (1.0942)  cardinality_error_3_unscaled: 2.2500 (2.2917)  loss_ce_4_unscaled: 0.6415 (0.6446)  loss_bbox_4_unscaled: 0.5927 (0.5943)  loss_giou_4_unscaled: 1.0737 (1.1522)  cardinality_error_4_unscaled: 2.2500 (2.2917)  time: 0.2827  data: 0.1442  max mem: 14982
Test:  [26/27]  eta: 0:00:00  class_error: 100.00  loss: 32.6291 (33.5778)  loss_ce: 0.6563 (0.6537)  loss_bbox: 2.7208 (2.8165)  loss_giou: 1.9944 (2.1952)  loss_ce_0: 0.6731 (0.6712)  loss_bbox_0: 2.6901 (2.7071)  loss_giou_0: 2.2726 (2.3993)  loss_ce_1: 0.6571 (0.6546)  loss_bbox_1: 2.4828 (2.4067)  loss_giou_1: 2.2119 (2.2524)  loss_ce_2: 0.6665 (0.6607)  loss_bbox_2: 2.6931 (2.6300)  loss_giou_2: 2.2667 (2.2408)  loss_ce_3: 0.6590 (0.6533)  loss_bbox_3: 2.4432 (2.5301)  loss_giou_3: 2.0924 (2.1454)  loss_ce_4: 0.6519 (0.6520)  loss_bbox_4: 3.0027 (3.0200)  loss_giou_4: 2.1473 (2.2888)  loss_ce_unscaled: 0.6563 (0.6537)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5442 (0.5633)  loss_giou_unscaled: 0.9972 (1.0976)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.6731 (0.6712)  loss_bbox_0_unscaled: 0.5380 (0.5414)  loss_giou_0_unscaled: 1.1363 (1.1996)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.6571 (0.6546)  loss_bbox_1_unscaled: 0.4966 (0.4813)  loss_giou_1_unscaled: 1.1059 (1.1262)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6665 (0.6607)  loss_bbox_2_unscaled: 0.5386 (0.5260)  loss_giou_2_unscaled: 1.1334 (1.1204)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6590 (0.6533)  loss_bbox_3_unscaled: 0.4886 (0.5060)  loss_giou_3_unscaled: 1.0462 (1.0727)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6519 (0.6520)  loss_bbox_4_unscaled: 0.6005 (0.6040)  loss_giou_4_unscaled: 1.0737 (1.1444)  cardinality_error_4_unscaled: 2.2500 (2.3380)  time: 0.2813  data: 0.1459  max mem: 14982
Test: Total time: 0:00:08 (0.3196 s / it)
Averaged stats: class_error: 100.00  loss: 32.6291 (33.5778)  loss_ce: 0.6563 (0.6537)  loss_bbox: 2.7208 (2.8165)  loss_giou: 1.9944 (2.1952)  loss_ce_0: 0.6731 (0.6712)  loss_bbox_0: 2.6901 (2.7071)  loss_giou_0: 2.2726 (2.3993)  loss_ce_1: 0.6571 (0.6546)  loss_bbox_1: 2.4828 (2.4067)  loss_giou_1: 2.2119 (2.2524)  loss_ce_2: 0.6665 (0.6607)  loss_bbox_2: 2.6931 (2.6300)  loss_giou_2: 2.2667 (2.2408)  loss_ce_3: 0.6590 (0.6533)  loss_bbox_3: 2.4432 (2.5301)  loss_giou_3: 2.0924 (2.1454)  loss_ce_4: 0.6519 (0.6520)  loss_bbox_4: 3.0027 (3.0200)  loss_giou_4: 2.1473 (2.2888)  loss_ce_unscaled: 0.6563 (0.6537)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5442 (0.5633)  loss_giou_unscaled: 0.9972 (1.0976)  cardinality_error_unscaled: 2.2500 (2.3380)  loss_ce_0_unscaled: 0.6731 (0.6712)  loss_bbox_0_unscaled: 0.5380 (0.5414)  loss_giou_0_unscaled: 1.1363 (1.1996)  cardinality_error_0_unscaled: 2.2500 (2.3380)  loss_ce_1_unscaled: 0.6571 (0.6546)  loss_bbox_1_unscaled: 0.4966 (0.4813)  loss_giou_1_unscaled: 1.1059 (1.1262)  cardinality_error_1_unscaled: 2.2500 (2.3380)  loss_ce_2_unscaled: 0.6665 (0.6607)  loss_bbox_2_unscaled: 0.5386 (0.5260)  loss_giou_2_unscaled: 1.1334 (1.1204)  cardinality_error_2_unscaled: 2.2500 (2.3380)  loss_ce_3_unscaled: 0.6590 (0.6533)  loss_bbox_3_unscaled: 0.4886 (0.5060)  loss_giou_3_unscaled: 1.0462 (1.0727)  cardinality_error_3_unscaled: 2.2500 (2.3380)  loss_ce_4_unscaled: 0.6519 (0.6520)  loss_bbox_4_unscaled: 0.6005 (0.6040)  loss_giou_4_unscaled: 1.0737 (1.1444)  cardinality_error_4_unscaled: 2.2500 (2.3380)
Accumulating evaluation results...
DONE (t=0.05s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.185
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.208
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.208
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.096
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.237
| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=16, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.04s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Using mixed precision training
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [  0/124]  eta: 0:05:25  lr: 0.000100  class_error: 94.87  loss: 53.2564 (53.2564)  loss_ce: 2.5686 (2.5686)  loss_bbox: 3.5803 (3.5803)  loss_giou: 1.8522 (1.8522)  loss_ce_0: 3.9668 (3.9668)  loss_bbox_0: 4.0001 (4.0001)  loss_giou_0: 1.8507 (1.8507)  loss_ce_1: 3.8951 (3.8951)  loss_bbox_1: 3.8438 (3.8438)  loss_giou_1: 1.8451 (1.8451)  loss_ce_2: 3.6007 (3.6007)  loss_bbox_2: 3.7846 (3.7846)  loss_giou_2: 1.8363 (1.8363)  loss_ce_3: 2.5858 (2.5858)  loss_bbox_3: 3.8775 (3.8775)  loss_giou_3: 1.8392 (1.8392)  loss_ce_4: 2.7633 (2.7633)  loss_bbox_4: 3.7245 (3.7245)  loss_giou_4: 1.8418 (1.8418)  loss_ce_unscaled: 2.5686 (2.5686)  class_error_unscaled: 94.8718 (94.8718)  loss_bbox_unscaled: 0.7161 (0.7161)  loss_giou_unscaled: 0.9261 (0.9261)  cardinality_error_unscaled: 64.5000 (64.5000)  loss_ce_0_unscaled: 3.9668 (3.9668)  loss_bbox_0_unscaled: 0.8000 (0.8000)  loss_giou_0_unscaled: 0.9254 (0.9254)  cardinality_error_0_unscaled: 97.5625 (97.5625)  loss_ce_1_unscaled: 3.8951 (3.8951)  loss_bbox_1_unscaled: 0.7688 (0.7688)  loss_giou_1_unscaled: 0.9225 (0.9225)  cardinality_error_1_unscaled: 97.5625 (97.5625)  loss_ce_2_unscaled: 3.6007 (3.6007)  loss_bbox_2_unscaled: 0.7569 (0.7569)  loss_giou_2_unscaled: 0.9182 (0.9182)  cardinality_error_2_unscaled: 97.5625 (97.5625)  loss_ce_3_unscaled: 2.5858 (2.5858)  loss_bbox_3_unscaled: 0.7755 (0.7755)  loss_giou_3_unscaled: 0.9196 (0.9196)  cardinality_error_3_unscaled: 75.4375 (75.4375)  loss_ce_4_unscaled: 2.7633 (2.7633)  loss_bbox_4_unscaled: 0.7449 (0.7449)  loss_giou_4_unscaled: 0.9209 (0.9209)  cardinality_error_4_unscaled: 92.1875 (92.1875)  time: 2.6268  data: 1.4360  max mem: 19420
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 10/124]  eta: 0:01:22  lr: 0.000100  class_error: 100.00  loss: 53.0168 (51.0517)  loss_ce: 2.6243 (2.4305)  loss_bbox: 3.6013 (3.5944)  loss_giou: 1.9341 (1.9242)  loss_ce_0: 3.9378 (3.5836)  loss_bbox_0: 3.8801 (3.8277)  loss_giou_0: 1.8647 (1.8683)  loss_ce_1: 3.8399 (3.4518)  loss_bbox_1: 3.7964 (3.7368)  loss_giou_1: 1.8926 (1.8909)  loss_ce_2: 3.5813 (3.1751)  loss_bbox_2: 3.7477 (3.6968)  loss_giou_2: 1.8825 (1.8812)  loss_ce_3: 2.5858 (2.3241)  loss_bbox_3: 3.7881 (3.7402)  loss_giou_3: 1.8798 (1.8781)  loss_ce_4: 2.7813 (2.5125)  loss_bbox_4: 3.6982 (3.6390)  loss_giou_4: 1.9009 (1.8964)  loss_ce_unscaled: 2.6243 (2.4305)  class_error_unscaled: 90.9091 (92.7059)  loss_bbox_unscaled: 0.7203 (0.7189)  loss_giou_unscaled: 0.9671 (0.9621)  cardinality_error_unscaled: 74.6250 (63.6875)  loss_ce_0_unscaled: 3.9378 (3.5836)  loss_bbox_0_unscaled: 0.7760 (0.7655)  loss_giou_0_unscaled: 0.9324 (0.9342)  cardinality_error_0_unscaled: 97.6250 (83.4318)  loss_ce_1_unscaled: 3.8399 (3.4518)  loss_bbox_1_unscaled: 0.7593 (0.7474)  loss_giou_1_unscaled: 0.9463 (0.9454)  cardinality_error_1_unscaled: 97.6250 (80.2898)  loss_ce_2_unscaled: 3.5813 (3.1751)  loss_bbox_2_unscaled: 0.7495 (0.7394)  loss_giou_2_unscaled: 0.9413 (0.9406)  cardinality_error_2_unscaled: 97.6250 (80.3807)  loss_ce_3_unscaled: 2.5858 (2.3241)  loss_bbox_3_unscaled: 0.7576 (0.7480)  loss_giou_3_unscaled: 0.9399 (0.9391)  cardinality_error_3_unscaled: 74.3125 (63.2670)  loss_ce_4_unscaled: 2.7813 (2.5125)  loss_bbox_4_unscaled: 0.7396 (0.7278)  loss_giou_4_unscaled: 0.9504 (0.9482)  cardinality_error_4_unscaled: 92.2500 (76.6477)  time: 0.7218  data: 0.2898  max mem: 20595
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 20/124]  eta: 0:01:05  lr: 0.000100  class_error: 100.00  loss: 40.5837 (44.7637)  loss_ce: 0.9561 (1.6777)  loss_bbox: 3.4978 (3.5154)  loss_giou: 1.9686 (1.9783)  loss_ce_0: 1.0386 (2.2697)  loss_bbox_0: 3.6542 (3.6631)  loss_giou_0: 1.9526 (1.9438)  loss_ce_1: 0.9153 (2.1991)  loss_bbox_1: 3.5249 (3.5882)  loss_giou_1: 1.9948 (1.9730)  loss_ce_2: 0.8918 (2.0478)  loss_bbox_2: 3.5730 (3.5887)  loss_giou_2: 1.9546 (1.9496)  loss_ce_3: 0.8729 (1.6005)  loss_bbox_3: 3.6000 (3.6197)  loss_giou_3: 1.9454 (1.9444)  loss_ce_4: 0.8875 (1.7017)  loss_bbox_4: 3.5442 (3.5434)  loss_giou_4: 1.9711 (1.9595)  loss_ce_unscaled: 0.9561 (1.6777)  class_error_unscaled: 100.0000 (96.1793)  loss_bbox_unscaled: 0.6996 (0.7031)  loss_giou_unscaled: 0.9843 (0.9891)  cardinality_error_unscaled: 2.4375 (34.4286)  loss_ce_0_unscaled: 1.0386 (2.2697)  loss_bbox_0_unscaled: 0.7308 (0.7326)  loss_giou_0_unscaled: 0.9763 (0.9719)  cardinality_error_0_unscaled: 2.4375 (44.7708)  loss_ce_1_unscaled: 0.9153 (2.1991)  loss_bbox_1_unscaled: 0.7050 (0.7176)  loss_giou_1_unscaled: 0.9974 (0.9865)  cardinality_error_1_unscaled: 2.4375 (43.1250)  loss_ce_2_unscaled: 0.8918 (2.0478)  loss_bbox_2_unscaled: 0.7146 (0.7177)  loss_giou_2_unscaled: 0.9773 (0.9748)  cardinality_error_2_unscaled: 2.4375 (43.1726)  loss_ce_3_unscaled: 0.8729 (1.6005)  loss_bbox_3_unscaled: 0.7200 (0.7239)  loss_giou_3_unscaled: 0.9727 (0.9722)  cardinality_error_3_unscaled: 2.4375 (34.2083)  loss_ce_4_unscaled: 0.8875 (1.7017)  loss_bbox_4_unscaled: 0.7088 (0.7087)  loss_giou_4_unscaled: 0.9856 (0.9797)  cardinality_error_4_unscaled: 2.4375 (41.2173)  time: 0.5264  data: 0.1250  max mem: 27880
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 30/124]  eta: 0:00:53  lr: 0.000100  class_error: 100.00  loss: 36.7254 (41.6307)  loss_ce: 0.7679 (1.3765)  loss_bbox: 3.2360 (3.3463)  loss_giou: 2.0646 (2.0233)  loss_ce_0: 0.7556 (1.7731)  loss_bbox_0: 3.2526 (3.4505)  loss_giou_0: 2.0665 (1.9971)  loss_ce_1: 0.7572 (1.7257)  loss_bbox_1: 3.2153 (3.3898)  loss_giou_1: 2.0888 (2.0244)  loss_ce_2: 0.7653 (1.6238)  loss_bbox_2: 3.2527 (3.3962)  loss_giou_2: 2.0546 (1.9988)  loss_ce_3: 0.7691 (1.3254)  loss_bbox_3: 3.2582 (3.4177)  loss_giou_3: 2.0518 (1.9963)  loss_ce_4: 0.7709 (1.3943)  loss_bbox_4: 3.2235 (3.3613)  loss_giou_4: 2.0576 (2.0102)  loss_ce_unscaled: 0.7679 (1.3765)  class_error_unscaled: 100.0000 (97.4118)  loss_bbox_unscaled: 0.6472 (0.6693)  loss_giou_unscaled: 1.0323 (1.0117)  cardinality_error_unscaled: 2.2500 (24.0625)  loss_ce_0_unscaled: 0.7556 (1.7731)  loss_bbox_0_unscaled: 0.6505 (0.6901)  loss_giou_0_unscaled: 1.0333 (0.9985)  cardinality_error_0_unscaled: 2.2500 (31.0685)  loss_ce_1_unscaled: 0.7572 (1.7257)  loss_bbox_1_unscaled: 0.6431 (0.6780)  loss_giou_1_unscaled: 1.0444 (1.0122)  cardinality_error_1_unscaled: 2.2500 (29.9536)  loss_ce_2_unscaled: 0.7653 (1.6238)  loss_bbox_2_unscaled: 0.6505 (0.6792)  loss_giou_2_unscaled: 1.0273 (0.9994)  cardinality_error_2_unscaled: 2.2500 (29.9859)  loss_ce_3_unscaled: 0.7691 (1.3254)  loss_bbox_3_unscaled: 0.6516 (0.6835)  loss_giou_3_unscaled: 1.0259 (0.9982)  cardinality_error_3_unscaled: 2.2500 (23.9133)  loss_ce_4_unscaled: 0.7709 (1.3943)  loss_bbox_4_unscaled: 0.6447 (0.6723)  loss_giou_4_unscaled: 1.0288 (1.0051)  cardinality_error_4_unscaled: 2.2500 (28.6613)  time: 0.4869  data: 0.0772  max mem: 27880
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 40/124]  eta: 0:00:48  lr: 0.000100  class_error: 100.00  loss: 33.2825 (39.5486)  loss_ce: 0.7457 (1.2226)  loss_bbox: 2.7834 (3.2079)  loss_giou: 2.0088 (2.0126)  loss_ce_0: 0.7174 (1.5154)  loss_bbox_0: 2.8811 (3.3053)  loss_giou_0: 2.0254 (1.9964)  loss_ce_1: 0.7253 (1.4803)  loss_bbox_1: 2.8307 (3.2474)  loss_giou_1: 2.0393 (2.0185)  loss_ce_2: 0.7341 (1.4048)  loss_bbox_2: 2.7929 (3.2482)  loss_giou_2: 2.0170 (1.9939)  loss_ce_3: 0.7465 (1.1836)  loss_bbox_3: 2.7858 (3.2601)  loss_giou_3: 1.9980 (1.9939)  loss_ce_4: 0.7545 (1.2379)  loss_bbox_4: 2.7878 (3.2151)  loss_giou_4: 2.0100 (2.0048)  loss_ce_unscaled: 0.7457 (1.2226)  class_error_unscaled: 100.0000 (98.0430)  loss_bbox_unscaled: 0.5567 (0.6416)  loss_giou_unscaled: 1.0044 (1.0063)  cardinality_error_unscaled: 2.1875 (18.7241)  loss_ce_0_unscaled: 0.7174 (1.5154)  loss_bbox_0_unscaled: 0.5762 (0.6611)  loss_giou_0_unscaled: 1.0127 (0.9982)  cardinality_error_0_unscaled: 2.1875 (24.0213)  loss_ce_1_unscaled: 0.7253 (1.4803)  loss_bbox_1_unscaled: 0.5661 (0.6495)  loss_giou_1_unscaled: 1.0197 (1.0093)  cardinality_error_1_unscaled: 2.1875 (23.1784)  loss_ce_2_unscaled: 0.7341 (1.4048)  loss_bbox_2_unscaled: 0.5586 (0.6496)  loss_giou_2_unscaled: 1.0085 (0.9970)  cardinality_error_2_unscaled: 2.1875 (23.2027)  loss_ce_3_unscaled: 0.7465 (1.1836)  loss_bbox_3_unscaled: 0.5572 (0.6520)  loss_giou_3_unscaled: 0.9990 (0.9969)  cardinality_error_3_unscaled: 2.1875 (18.6113)  loss_ce_4_unscaled: 0.7545 (1.2379)  loss_bbox_4_unscaled: 0.5576 (0.6430)  loss_giou_4_unscaled: 1.0050 (1.0024)  cardinality_error_4_unscaled: 2.1875 (22.2012)  time: 0.5228  data: 0.1419  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 50/124]  eta: 0:00:42  lr: 0.000100  class_error: 100.00  loss: 32.1699 (38.0403)  loss_ce: 0.7405 (1.1275)  loss_bbox: 2.5570 (3.0616)  loss_giou: 1.9920 (2.0267)  loss_ce_0: 0.7174 (1.3597)  loss_bbox_0: 2.6120 (3.1438)  loss_giou_0: 2.0344 (2.0140)  loss_ce_1: 0.7253 (1.3353)  loss_bbox_1: 2.5793 (3.0979)  loss_giou_1: 2.0249 (2.0322)  loss_ce_2: 0.7369 (1.2762)  loss_bbox_2: 2.5848 (3.0953)  loss_giou_2: 2.0429 (2.0157)  loss_ce_3: 0.7434 (1.0970)  loss_bbox_3: 2.5252 (3.1088)  loss_giou_3: 2.0383 (2.0151)  loss_ce_4: 0.7527 (1.1406)  loss_bbox_4: 2.5446 (3.0705)  loss_giou_4: 2.0245 (2.0223)  loss_ce_unscaled: 0.7405 (1.1275)  class_error_unscaled: 100.0000 (98.4268)  loss_bbox_unscaled: 0.5114 (0.6123)  loss_giou_unscaled: 0.9960 (1.0133)  cardinality_error_unscaled: 2.1875 (15.5012)  loss_ce_0_unscaled: 0.7174 (1.3597)  loss_bbox_0_unscaled: 0.5224 (0.6288)  loss_giou_0_unscaled: 1.0172 (1.0070)  cardinality_error_0_unscaled: 2.1875 (19.7598)  loss_ce_1_unscaled: 0.7253 (1.3353)  loss_bbox_1_unscaled: 0.5159 (0.6196)  loss_giou_1_unscaled: 1.0124 (1.0161)  cardinality_error_1_unscaled: 2.1875 (19.0821)  loss_ce_2_unscaled: 0.7369 (1.2762)  loss_bbox_2_unscaled: 0.5170 (0.6191)  loss_giou_2_unscaled: 1.0214 (1.0079)  cardinality_error_2_unscaled: 2.1875 (19.1017)  loss_ce_3_unscaled: 0.7434 (1.0970)  loss_bbox_3_unscaled: 0.5050 (0.6218)  loss_giou_3_unscaled: 1.0191 (1.0076)  cardinality_error_3_unscaled: 2.1875 (15.4105)  loss_ce_4_unscaled: 0.7527 (1.1406)  loss_bbox_4_unscaled: 0.5089 (0.6141)  loss_giou_4_unscaled: 1.0122 (1.0111)  cardinality_error_4_unscaled: 2.1875 (18.2966)  time: 0.5670  data: 0.1545  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 60/124]  eta: 0:00:36  lr: 0.000100  class_error: 100.00  loss: 31.6159 (36.9656)  loss_ce: 0.7237 (1.0589)  loss_bbox: 2.4000 (2.9612)  loss_giou: 2.0338 (2.0336)  loss_ce_0: 0.7137 (1.2518)  loss_bbox_0: 2.4208 (3.0305)  loss_giou_0: 2.0630 (2.0234)  loss_ce_1: 0.7250 (1.2326)  loss_bbox_1: 2.4157 (2.9938)  loss_giou_1: 2.0666 (2.0395)  loss_ce_2: 0.7277 (1.1847)  loss_bbox_2: 2.3731 (2.9896)  loss_giou_2: 2.0694 (2.0282)  loss_ce_3: 0.7079 (1.0328)  loss_bbox_3: 2.4023 (3.0049)  loss_giou_3: 2.0602 (2.0249)  loss_ce_4: 0.7216 (1.0702)  loss_bbox_4: 2.3870 (2.9703)  loss_giou_4: 2.0540 (2.0347)  loss_ce_unscaled: 0.7237 (1.0589)  class_error_unscaled: 100.0000 (98.6847)  loss_bbox_unscaled: 0.4800 (0.5922)  loss_giou_unscaled: 1.0169 (1.0168)  cardinality_error_unscaled: 2.3125 (13.3330)  loss_ce_0_unscaled: 0.7137 (1.2518)  loss_bbox_0_unscaled: 0.4842 (0.6061)  loss_giou_0_unscaled: 1.0315 (1.0117)  cardinality_error_0_unscaled: 2.3125 (16.8934)  loss_ce_1_unscaled: 0.7250 (1.2326)  loss_bbox_1_unscaled: 0.4831 (0.5988)  loss_giou_1_unscaled: 1.0333 (1.0198)  cardinality_error_1_unscaled: 2.3125 (16.3268)  loss_ce_2_unscaled: 0.7277 (1.1847)  loss_bbox_2_unscaled: 0.4746 (0.5979)  loss_giou_2_unscaled: 1.0347 (1.0141)  cardinality_error_2_unscaled: 2.3125 (16.3432)  loss_ce_3_unscaled: 0.7079 (1.0328)  loss_bbox_3_unscaled: 0.4805 (0.6010)  loss_giou_3_unscaled: 1.0301 (1.0124)  cardinality_error_3_unscaled: 2.3125 (13.2572)  loss_ce_4_unscaled: 0.7216 (1.0702)  loss_bbox_4_unscaled: 0.4774 (0.5941)  loss_giou_4_unscaled: 1.0270 (1.0174)  cardinality_error_4_unscaled: 2.3125 (15.6701)  time: 0.5755  data: 0.1474  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 70/124]  eta: 0:00:30  lr: 0.000100  class_error: 100.00  loss: 31.4164 (36.1560)  loss_ce: 0.6941 (1.0078)  loss_bbox: 2.4364 (2.8874)  loss_giou: 2.0173 (2.0355)  loss_ce_0: 0.6916 (1.1718)  loss_bbox_0: 2.4550 (2.9431)  loss_giou_0: 2.0361 (2.0299)  loss_ce_1: 0.7011 (1.1562)  loss_bbox_1: 2.4368 (2.9167)  loss_giou_1: 2.0230 (2.0431)  loss_ce_2: 0.6995 (1.1150)  loss_bbox_2: 2.4669 (2.9131)  loss_giou_2: 2.0801 (2.0375)  loss_ce_3: 0.6989 (0.9850)  loss_bbox_3: 2.4865 (2.9255)  loss_giou_3: 2.0477 (2.0336)  loss_ce_4: 0.7097 (1.0174)  loss_bbox_4: 2.4208 (2.8961)  loss_giou_4: 2.0595 (2.0413)  loss_ce_unscaled: 0.6941 (1.0078)  class_error_unscaled: 100.0000 (98.8699)  loss_bbox_unscaled: 0.4873 (0.5775)  loss_giou_unscaled: 1.0086 (1.0178)  cardinality_error_unscaled: 2.2500 (11.7623)  loss_ce_0_unscaled: 0.6916 (1.1718)  loss_bbox_0_unscaled: 0.4910 (0.5886)  loss_giou_0_unscaled: 1.0180 (1.0149)  cardinality_error_0_unscaled: 2.2500 (14.8213)  loss_ce_1_unscaled: 0.7011 (1.1562)  loss_bbox_1_unscaled: 0.4874 (0.5833)  loss_giou_1_unscaled: 1.0115 (1.0216)  cardinality_error_1_unscaled: 2.2500 (14.3345)  loss_ce_2_unscaled: 0.6995 (1.1150)  loss_bbox_2_unscaled: 0.4934 (0.5826)  loss_giou_2_unscaled: 1.0400 (1.0187)  cardinality_error_2_unscaled: 2.2500 (14.3486)  loss_ce_3_unscaled: 0.6989 (0.9850)  loss_bbox_3_unscaled: 0.4973 (0.5851)  loss_giou_3_unscaled: 1.0239 (1.0168)  cardinality_error_3_unscaled: 2.2500 (11.6972)  loss_ce_4_unscaled: 0.7097 (1.0174)  loss_bbox_4_unscaled: 0.4842 (0.5792)  loss_giou_4_unscaled: 1.0297 (1.0206)  cardinality_error_4_unscaled: 2.2500 (13.7702)  time: 0.5348  data: 0.1334  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 80/124]  eta: 0:00:24  lr: 0.000100  class_error: 100.00  loss: 29.9953 (35.3444)  loss_ce: 0.6926 (0.9693)  loss_bbox: 2.2454 (2.7979)  loss_giou: 2.0173 (2.0356)  loss_ce_0: 0.6911 (1.1123)  loss_bbox_0: 2.3164 (2.8470)  loss_giou_0: 2.0227 (2.0308)  loss_ce_1: 0.6975 (1.0993)  loss_bbox_1: 2.3216 (2.8257)  loss_giou_1: 2.0230 (2.0448)  loss_ce_2: 0.6995 (1.0642)  loss_bbox_2: 2.3946 (2.8272)  loss_giou_2: 2.0797 (2.0402)  loss_ce_3: 0.7071 (0.9499)  loss_bbox_3: 2.3389 (2.8355)  loss_giou_3: 2.0588 (2.0356)  loss_ce_4: 0.7084 (0.9786)  loss_bbox_4: 2.3193 (2.8087)  loss_giou_4: 2.0542 (2.0418)  loss_ce_unscaled: 0.6926 (0.9693)  class_error_unscaled: 100.0000 (99.0094)  loss_bbox_unscaled: 0.4491 (0.5596)  loss_giou_unscaled: 1.0086 (1.0178)  cardinality_error_unscaled: 2.2500 (10.5887)  loss_ce_0_unscaled: 0.6911 (1.1123)  loss_bbox_0_unscaled: 0.4633 (0.5694)  loss_giou_0_unscaled: 1.0113 (1.0154)  cardinality_error_0_unscaled: 2.2500 (13.2701)  loss_ce_1_unscaled: 0.6975 (1.0993)  loss_bbox_1_unscaled: 0.4643 (0.5651)  loss_giou_1_unscaled: 1.0115 (1.0224)  cardinality_error_1_unscaled: 2.2500 (12.8434)  loss_ce_2_unscaled: 0.6995 (1.0642)  loss_bbox_2_unscaled: 0.4789 (0.5654)  loss_giou_2_unscaled: 1.0399 (1.0201)  cardinality_error_2_unscaled: 2.2500 (12.8557)  loss_ce_3_unscaled: 0.7071 (0.9499)  loss_bbox_3_unscaled: 0.4678 (0.5671)  loss_giou_3_unscaled: 1.0294 (1.0178)  cardinality_error_3_unscaled: 2.2500 (10.5316)  loss_ce_4_unscaled: 0.7084 (0.9786)  loss_bbox_4_unscaled: 0.4639 (0.5617)  loss_giou_4_unscaled: 1.0271 (1.0209)  cardinality_error_4_unscaled: 2.2500 (12.3488)  time: 0.4988  data: 0.1062  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [ 90/124]  eta: 0:00:18  lr: 0.000100  class_error: 100.00  loss: 29.3930 (34.6087)  loss_ce: 0.7032 (0.9404)  loss_bbox: 2.0562 (2.7253)  loss_giou: 1.9795 (2.0271)  loss_ce_0: 0.6929 (1.0674)  loss_bbox_0: 2.0293 (2.7632)  loss_giou_0: 1.9813 (2.0201)  loss_ce_1: 0.7002 (1.0562)  loss_bbox_1: 2.0364 (2.7436)  loss_giou_1: 2.0099 (2.0344)  loss_ce_2: 0.7158 (1.0253)  loss_bbox_2: 2.0488 (2.7507)  loss_giou_2: 1.9995 (2.0320)  loss_ce_3: 0.7071 (0.9236)  loss_bbox_3: 2.0615 (2.7581)  loss_giou_3: 1.9919 (2.0278)  loss_ce_4: 0.7084 (0.9492)  loss_bbox_4: 2.0538 (2.7333)  loss_giou_4: 1.9779 (2.0310)  loss_ce_unscaled: 0.7032 (0.9404)  class_error_unscaled: 100.0000 (99.1183)  loss_bbox_unscaled: 0.4112 (0.5451)  loss_giou_unscaled: 0.9898 (1.0135)  cardinality_error_unscaled: 2.2500 (9.6820)  loss_ce_0_unscaled: 0.6929 (1.0674)  loss_bbox_0_unscaled: 0.4059 (0.5526)  loss_giou_0_unscaled: 0.9907 (1.0100)  cardinality_error_0_unscaled: 2.2500 (12.0687)  loss_ce_1_unscaled: 0.7002 (1.0562)  loss_bbox_1_unscaled: 0.4073 (0.5487)  loss_giou_1_unscaled: 1.0050 (1.0172)  cardinality_error_1_unscaled: 2.2500 (11.6889)  loss_ce_2_unscaled: 0.7158 (1.0253)  loss_bbox_2_unscaled: 0.4098 (0.5501)  loss_giou_2_unscaled: 0.9997 (1.0160)  cardinality_error_2_unscaled: 2.2500 (11.6999)  loss_ce_3_unscaled: 0.7071 (0.9236)  loss_bbox_3_unscaled: 0.4123 (0.5516)  loss_giou_3_unscaled: 0.9960 (1.0139)  cardinality_error_3_unscaled: 2.2500 (9.6312)  loss_ce_4_unscaled: 0.7084 (0.9492)  loss_bbox_4_unscaled: 0.4108 (0.5467)  loss_giou_4_unscaled: 0.9889 (1.0155)  cardinality_error_4_unscaled: 2.2500 (11.2486)  time: 0.5457  data: 0.1605  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [100/124]  eta: 0:00:13  lr: 0.000100  class_error: 100.00  loss: 26.9021 (33.7221)  loss_ce: 0.7032 (0.9169)  loss_bbox: 2.0226 (2.6444)  loss_giou: 1.8436 (1.9988)  loss_ce_0: 0.7046 (1.0312)  loss_bbox_0: 1.8475 (2.6669)  loss_giou_0: 1.7537 (1.9874)  loss_ce_1: 0.7028 (1.0221)  loss_bbox_1: 1.8848 (2.6496)  loss_giou_1: 1.7544 (1.9993)  loss_ce_2: 0.7090 (0.9939)  loss_bbox_2: 1.9501 (2.6633)  loss_giou_2: 1.8068 (2.0040)  loss_ce_3: 0.7053 (0.9024)  loss_bbox_3: 1.9675 (2.6679)  loss_giou_3: 1.7959 (1.9973)  loss_ce_4: 0.7050 (0.9252)  loss_bbox_4: 1.9955 (2.6482)  loss_giou_4: 1.8465 (2.0032)  loss_ce_unscaled: 0.7032 (0.9169)  class_error_unscaled: 100.0000 (99.2056)  loss_bbox_unscaled: 0.4045 (0.5289)  loss_giou_unscaled: 0.9218 (0.9994)  cardinality_error_unscaled: 2.3125 (8.9505)  loss_ce_0_unscaled: 0.7046 (1.0312)  loss_bbox_0_unscaled: 0.3695 (0.5334)  loss_giou_0_unscaled: 0.8769 (0.9937)  cardinality_error_0_unscaled: 2.3125 (11.1009)  loss_ce_1_unscaled: 0.7028 (1.0221)  loss_bbox_1_unscaled: 0.3770 (0.5299)  loss_giou_1_unscaled: 0.8772 (0.9997)  cardinality_error_1_unscaled: 2.3125 (10.7587)  loss_ce_2_unscaled: 0.7090 (0.9939)  loss_bbox_2_unscaled: 0.3900 (0.5327)  loss_giou_2_unscaled: 0.9034 (1.0020)  cardinality_error_2_unscaled: 2.3125 (10.7686)  loss_ce_3_unscaled: 0.7053 (0.9024)  loss_bbox_3_unscaled: 0.3935 (0.5336)  loss_giou_3_unscaled: 0.8980 (0.9986)  cardinality_error_3_unscaled: 2.3125 (8.9047)  loss_ce_4_unscaled: 0.7050 (0.9252)  loss_bbox_4_unscaled: 0.3991 (0.5296)  loss_giou_4_unscaled: 0.9233 (1.0016)  cardinality_error_4_unscaled: 2.3125 (10.3620)  time: 0.5010  data: 0.1267  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [110/124]  eta: 0:00:07  lr: 0.000100  class_error: 100.00  loss: 25.1632 (32.9369)  loss_ce: 0.7059 (0.8982)  loss_bbox: 1.8944 (2.5719)  loss_giou: 1.6958 (1.9693)  loss_ce_0: 0.7046 (1.0018)  loss_bbox_0: 1.8276 (2.5832)  loss_giou_0: 1.6322 (1.9513)  loss_ce_1: 0.7136 (0.9944)  loss_bbox_1: 1.7724 (2.5652)  loss_giou_1: 1.6323 (1.9616)  loss_ce_2: 0.7282 (0.9692)  loss_bbox_2: 1.9011 (2.5864)  loss_giou_2: 1.7186 (1.9750)  loss_ce_3: 0.7216 (0.8867)  loss_bbox_3: 1.8981 (2.5939)  loss_giou_3: 1.6745 (1.9684)  loss_ce_4: 0.7171 (0.9066)  loss_bbox_4: 1.8845 (2.5775)  loss_giou_4: 1.7352 (1.9763)  loss_ce_unscaled: 0.7059 (0.8982)  class_error_unscaled: 100.0000 (99.2772)  loss_bbox_unscaled: 0.3789 (0.5144)  loss_giou_unscaled: 0.8479 (0.9846)  cardinality_error_unscaled: 2.2500 (8.3435)  loss_ce_0_unscaled: 0.7046 (1.0018)  loss_bbox_0_unscaled: 0.3655 (0.5166)  loss_giou_0_unscaled: 0.8161 (0.9756)  cardinality_error_0_unscaled: 2.2500 (10.3001)  loss_ce_1_unscaled: 0.7136 (0.9944)  loss_bbox_1_unscaled: 0.3545 (0.5130)  loss_giou_1_unscaled: 0.8162 (0.9808)  cardinality_error_1_unscaled: 2.2500 (9.9887)  loss_ce_2_unscaled: 0.7282 (0.9692)  loss_bbox_2_unscaled: 0.3802 (0.5173)  loss_giou_2_unscaled: 0.8593 (0.9875)  cardinality_error_2_unscaled: 2.2500 (9.9977)  loss_ce_3_unscaled: 0.7216 (0.8867)  loss_bbox_3_unscaled: 0.3796 (0.5188)  loss_giou_3_unscaled: 0.8372 (0.9842)  cardinality_error_3_unscaled: 2.2500 (8.3018)  loss_ce_4_unscaled: 0.7171 (0.9066)  loss_bbox_4_unscaled: 0.3769 (0.5155)  loss_giou_4_unscaled: 0.8676 (0.9882)  cardinality_error_4_unscaled: 2.2500 (9.6278)  time: 0.4372  data: 0.0672  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:449: FutureWarning: torch.cuda.max_memory_cached has been renamed to torch.cuda.max_memory_reserved
  warnings.warn(
Epoch: [0]  [120/124]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 23.8766 (32.1546)  loss_ce: 0.7193 (0.8837)  loss_bbox: 1.7375 (2.5019)  loss_giou: 1.5762 (1.9356)  loss_ce_0: 0.7129 (0.9781)  loss_bbox_0: 1.7417 (2.5084)  loss_giou_0: 1.5723 (1.9120)  loss_ce_1: 0.7194 (0.9727)  loss_bbox_1: 1.6178 (2.4834)  loss_giou_1: 1.5018 (1.9168)  loss_ce_2: 0.7186 (0.9487)  loss_bbox_2: 1.7225 (2.5106)  loss_giou_2: 1.5772 (1.9338)  loss_ce_3: 0.7239 (0.8734)  loss_bbox_3: 1.7855 (2.5211)  loss_giou_3: 1.5713 (1.9302)  loss_ce_4: 0.7226 (0.8914)  loss_bbox_4: 1.8109 (2.5110)  loss_giou_4: 1.5920 (1.9420)  loss_ce_unscaled: 0.7193 (0.8837)  class_error_unscaled: 100.0000 (99.3369)  loss_bbox_unscaled: 0.3475 (0.5004)  loss_giou_unscaled: 0.7881 (0.9678)  cardinality_error_unscaled: 2.1875 (7.8363)  loss_ce_0_unscaled: 0.7129 (0.9781)  loss_bbox_0_unscaled: 0.3483 (0.5017)  loss_giou_0_unscaled: 0.7862 (0.9560)  cardinality_error_0_unscaled: 2.1875 (9.6312)  loss_ce_1_unscaled: 0.7194 (0.9727)  loss_bbox_1_unscaled: 0.3236 (0.4967)  loss_giou_1_unscaled: 0.7509 (0.9584)  cardinality_error_1_unscaled: 2.1875 (9.3456)  loss_ce_2_unscaled: 0.7186 (0.9487)  loss_bbox_2_unscaled: 0.3445 (0.5021)  loss_giou_2_unscaled: 0.7886 (0.9669)  cardinality_error_2_unscaled: 2.1875 (9.3538)  loss_ce_3_unscaled: 0.7239 (0.8734)  loss_bbox_3_unscaled: 0.3571 (0.5042)  loss_giou_3_unscaled: 0.7856 (0.9651)  cardinality_error_3_unscaled: 2.1875 (7.7980)  loss_ce_4_unscaled: 0.7226 (0.8914)  loss_bbox_4_unscaled: 0.3622 (0.5022)  loss_giou_4_unscaled: 0.7960 (0.9710)  cardinality_error_4_unscaled: 2.1875 (9.0145)  time: 0.4398  data: 0.0657  max mem: 29512
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [0]  [123/124]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 23.5229 (31.9057)  loss_ce: 0.7218 (0.8808)  loss_bbox: 1.6842 (2.4796)  loss_giou: 1.5526 (1.9225)  loss_ce_0: 0.7191 (0.9729)  loss_bbox_0: 1.7283 (2.4863)  loss_giou_0: 1.5381 (1.8993)  loss_ce_1: 0.7358 (0.9680)  loss_bbox_1: 1.5936 (2.4586)  loss_giou_1: 1.4726 (1.9010)  loss_ce_2: 0.7298 (0.9442)  loss_bbox_2: 1.6866 (2.4861)  loss_giou_2: 1.5422 (1.9197)  loss_ce_3: 0.7362 (0.8707)  loss_bbox_3: 1.6793 (2.4968)  loss_giou_3: 1.5122 (1.9159)  loss_ce_4: 0.7382 (0.8885)  loss_bbox_4: 1.7302 (2.4868)  loss_giou_4: 1.5574 (1.9279)  loss_ce_unscaled: 0.7218 (0.8808)  class_error_unscaled: 100.0000 (99.3529)  loss_bbox_unscaled: 0.3368 (0.4959)  loss_giou_unscaled: 0.7763 (0.9613)  cardinality_error_unscaled: 2.1875 (7.7046)  loss_ce_0_unscaled: 0.7191 (0.9729)  loss_bbox_0_unscaled: 0.3457 (0.4973)  loss_giou_0_unscaled: 0.7690 (0.9497)  cardinality_error_0_unscaled: 2.1875 (9.4561)  loss_ce_1_unscaled: 0.7358 (0.9680)  loss_bbox_1_unscaled: 0.3187 (0.4917)  loss_giou_1_unscaled: 0.7363 (0.9505)  cardinality_error_1_unscaled: 2.1875 (9.1769)  loss_ce_2_unscaled: 0.7298 (0.9442)  loss_bbox_2_unscaled: 0.3373 (0.4972)  loss_giou_2_unscaled: 0.7711 (0.9598)  cardinality_error_2_unscaled: 2.1875 (9.1850)  loss_ce_3_unscaled: 0.7362 (0.8707)  loss_bbox_3_unscaled: 0.3359 (0.4994)  loss_giou_3_unscaled: 0.7561 (0.9580)  cardinality_error_3_unscaled: 2.1875 (7.6673)  loss_ce_4_unscaled: 0.7382 (0.8885)  loss_bbox_4_unscaled: 0.3460 (0.4974)  loss_giou_4_unscaled: 0.7787 (0.9639)  cardinality_error_4_unscaled: 2.1875 (8.8543)  time: 0.4275  data: 0.0640  max mem: 29512
Epoch: [0] Total time: 0:01:05 (0.5251 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 23.5229 (31.9057)  loss_ce: 0.7218 (0.8808)  loss_bbox: 1.6842 (2.4796)  loss_giou: 1.5526 (1.9225)  loss_ce_0: 0.7191 (0.9729)  loss_bbox_0: 1.7283 (2.4863)  loss_giou_0: 1.5381 (1.8993)  loss_ce_1: 0.7358 (0.9680)  loss_bbox_1: 1.5936 (2.4586)  loss_giou_1: 1.4726 (1.9010)  loss_ce_2: 0.7298 (0.9442)  loss_bbox_2: 1.6866 (2.4861)  loss_giou_2: 1.5422 (1.9197)  loss_ce_3: 0.7362 (0.8707)  loss_bbox_3: 1.6793 (2.4968)  loss_giou_3: 1.5122 (1.9159)  loss_ce_4: 0.7382 (0.8885)  loss_bbox_4: 1.7302 (2.4868)  loss_giou_4: 1.5574 (1.9279)  loss_ce_unscaled: 0.7218 (0.8808)  class_error_unscaled: 100.0000 (99.3529)  loss_bbox_unscaled: 0.3368 (0.4959)  loss_giou_unscaled: 0.7763 (0.9613)  cardinality_error_unscaled: 2.1875 (7.7046)  loss_ce_0_unscaled: 0.7191 (0.9729)  loss_bbox_0_unscaled: 0.3457 (0.4973)  loss_giou_0_unscaled: 0.7690 (0.9497)  cardinality_error_0_unscaled: 2.1875 (9.4561)  loss_ce_1_unscaled: 0.7358 (0.9680)  loss_bbox_1_unscaled: 0.3187 (0.4917)  loss_giou_1_unscaled: 0.7363 (0.9505)  cardinality_error_1_unscaled: 2.1875 (9.1769)  loss_ce_2_unscaled: 0.7298 (0.9442)  loss_bbox_2_unscaled: 0.3373 (0.4972)  loss_giou_2_unscaled: 0.7711 (0.9598)  cardinality_error_2_unscaled: 2.1875 (9.1850)  loss_ce_3_unscaled: 0.7362 (0.8707)  loss_bbox_3_unscaled: 0.3359 (0.4994)  loss_giou_3_unscaled: 0.7561 (0.9580)  cardinality_error_3_unscaled: 2.1875 (7.6673)  loss_ce_4_unscaled: 0.7382 (0.8885)  loss_bbox_4_unscaled: 0.3460 (0.4974)  loss_giou_4_unscaled: 0.7787 (0.9639)  cardinality_error_4_unscaled: 2.1875 (8.8543)

End of training epoch
Total execution time = 65.159 sec
Max memory used by tensors = 30945416192 bytes
Max memory cached = 40512782336 bytes
Total memory reserved = 38258343936 bytes
Total memory allocated = 853518848 bytes
Test:  [ 0/14]  eta: 0:00:32  class_error: 100.00  loss: 36.7624 (36.7624)  loss_ce: 0.6998 (0.6998)  loss_bbox: 2.7347 (2.7347)  loss_giou: 2.7050 (2.7050)  loss_ce_0: 0.7195 (0.7195)  loss_bbox_0: 2.4889 (2.4889)  loss_giou_0: 2.6235 (2.6235)  loss_ce_1: 0.7142 (0.7142)  loss_bbox_1: 2.6857 (2.6857)  loss_giou_1: 2.7563 (2.7563)  loss_ce_2: 0.6935 (0.6935)  loss_bbox_2: 2.6394 (2.6394)  loss_giou_2: 2.7047 (2.7047)  loss_ce_3: 0.6996 (0.6996)  loss_bbox_3: 2.7137 (2.7137)  loss_giou_3: 2.7078 (2.7078)  loss_ce_4: 0.6925 (0.6925)  loss_bbox_4: 2.9974 (2.9974)  loss_giou_4: 2.7862 (2.7862)  loss_ce_unscaled: 0.6998 (0.6998)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5469 (0.5469)  loss_giou_unscaled: 1.3525 (1.3525)  cardinality_error_unscaled: 2.1875 (2.1875)  loss_ce_0_unscaled: 0.7195 (0.7195)  loss_bbox_0_unscaled: 0.4978 (0.4978)  loss_giou_0_unscaled: 1.3118 (1.3118)  cardinality_error_0_unscaled: 2.1875 (2.1875)  loss_ce_1_unscaled: 0.7142 (0.7142)  loss_bbox_1_unscaled: 0.5371 (0.5371)  loss_giou_1_unscaled: 1.3782 (1.3782)  cardinality_error_1_unscaled: 2.1875 (2.1875)  loss_ce_2_unscaled: 0.6935 (0.6935)  loss_bbox_2_unscaled: 0.5279 (0.5279)  loss_giou_2_unscaled: 1.3524 (1.3524)  cardinality_error_2_unscaled: 2.1875 (2.1875)  loss_ce_3_unscaled: 0.6996 (0.6996)  loss_bbox_3_unscaled: 0.5427 (0.5427)  loss_giou_3_unscaled: 1.3539 (1.3539)  cardinality_error_3_unscaled: 2.1875 (2.1875)  loss_ce_4_unscaled: 0.6925 (0.6925)  loss_bbox_4_unscaled: 0.5995 (0.5995)  loss_giou_4_unscaled: 1.3931 (1.3931)  cardinality_error_4_unscaled: 2.1875 (2.1875)  time: 2.3369  data: 2.0486  max mem: 29512
Test:  [10/14]  eta: 0:00:03  class_error: 100.00  loss: 32.3520 (33.3020)  loss_ce: 0.7099 (0.7179)  loss_bbox: 2.6267 (2.5834)  loss_giou: 2.1178 (2.2465)  loss_ce_0: 0.7158 (0.7232)  loss_bbox_0: 2.3943 (2.4307)  loss_giou_0: 2.0932 (2.2740)  loss_ce_1: 0.7142 (0.7253)  loss_bbox_1: 2.4875 (2.5269)  loss_giou_1: 2.1378 (2.2920)  loss_ce_2: 0.7057 (0.7129)  loss_bbox_2: 2.4633 (2.5049)  loss_giou_2: 2.0610 (2.2597)  loss_ce_3: 0.7025 (0.7125)  loss_bbox_3: 2.5616 (2.5717)  loss_giou_3: 2.0826 (2.2544)  loss_ce_4: 0.6978 (0.7101)  loss_bbox_4: 2.7604 (2.7652)  loss_giou_4: 2.2089 (2.2906)  loss_ce_unscaled: 0.7099 (0.7179)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5253 (0.5167)  loss_giou_unscaled: 1.0589 (1.1233)  cardinality_error_unscaled: 2.2500 (2.2955)  loss_ce_0_unscaled: 0.7158 (0.7232)  loss_bbox_0_unscaled: 0.4789 (0.4861)  loss_giou_0_unscaled: 1.0466 (1.1370)  cardinality_error_0_unscaled: 2.2500 (2.2955)  loss_ce_1_unscaled: 0.7142 (0.7253)  loss_bbox_1_unscaled: 0.4975 (0.5054)  loss_giou_1_unscaled: 1.0689 (1.1460)  cardinality_error_1_unscaled: 2.2500 (2.2955)  loss_ce_2_unscaled: 0.7057 (0.7129)  loss_bbox_2_unscaled: 0.4927 (0.5010)  loss_giou_2_unscaled: 1.0305 (1.1298)  cardinality_error_2_unscaled: 2.2500 (2.2955)  loss_ce_3_unscaled: 0.7025 (0.7125)  loss_bbox_3_unscaled: 0.5123 (0.5143)  loss_giou_3_unscaled: 1.0413 (1.1272)  cardinality_error_3_unscaled: 2.2500 (2.2955)  loss_ce_4_unscaled: 0.6978 (0.7101)  loss_bbox_4_unscaled: 0.5521 (0.5530)  loss_giou_4_unscaled: 1.1044 (1.1453)  cardinality_error_4_unscaled: 2.2500 (2.2955)  time: 0.8643  data: 0.6000  max mem: 29512
Test:  [13/14]  eta: 0:00:00  class_error: 100.00  loss: 32.3520 (33.4675)  loss_ce: 0.7308 (0.7286)  loss_bbox: 2.6391 (2.6472)  loss_giou: 2.1120 (2.2112)  loss_ce_0: 0.7158 (0.7296)  loss_bbox_0: 2.4036 (2.4594)  loss_giou_0: 2.0932 (2.2376)  loss_ce_1: 0.7271 (0.7346)  loss_bbox_1: 2.5811 (2.5818)  loss_giou_1: 2.1297 (2.2532)  loss_ce_2: 0.7228 (0.7220)  loss_bbox_2: 2.5534 (2.5568)  loss_giou_2: 2.0610 (2.2172)  loss_ce_3: 0.7124 (0.7200)  loss_bbox_3: 2.6410 (2.6341)  loss_giou_3: 2.0826 (2.2159)  loss_ce_4: 0.7178 (0.7197)  loss_bbox_4: 2.9105 (2.8338)  loss_giou_4: 2.1642 (2.2649)  loss_ce_unscaled: 0.7308 (0.7286)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5278 (0.5294)  loss_giou_unscaled: 1.0560 (1.1056)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.7158 (0.7296)  loss_bbox_0_unscaled: 0.4807 (0.4919)  loss_giou_0_unscaled: 1.0466 (1.1188)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.7271 (0.7346)  loss_bbox_1_unscaled: 0.5162 (0.5164)  loss_giou_1_unscaled: 1.0648 (1.1266)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.7228 (0.7220)  loss_bbox_2_unscaled: 0.5107 (0.5114)  loss_giou_2_unscaled: 1.0305 (1.1086)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.7124 (0.7200)  loss_bbox_3_unscaled: 0.5282 (0.5268)  loss_giou_3_unscaled: 1.0413 (1.1079)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.7178 (0.7197)  loss_bbox_4_unscaled: 0.5821 (0.5668)  loss_giou_4_unscaled: 1.0821 (1.1325)  cardinality_error_4_unscaled: 2.3750 (2.3616)  time: 0.7585  data: 0.5079  max mem: 29512
Test: Total time: 0:00:10 (0.7638 s / it)
Averaged stats: class_error: 100.00  loss: 32.3520 (33.4675)  loss_ce: 0.7308 (0.7286)  loss_bbox: 2.6391 (2.6472)  loss_giou: 2.1120 (2.2112)  loss_ce_0: 0.7158 (0.7296)  loss_bbox_0: 2.4036 (2.4594)  loss_giou_0: 2.0932 (2.2376)  loss_ce_1: 0.7271 (0.7346)  loss_bbox_1: 2.5811 (2.5818)  loss_giou_1: 2.1297 (2.2532)  loss_ce_2: 0.7228 (0.7220)  loss_bbox_2: 2.5534 (2.5568)  loss_giou_2: 2.0610 (2.2172)  loss_ce_3: 0.7124 (0.7200)  loss_bbox_3: 2.6410 (2.6341)  loss_giou_3: 2.0826 (2.2159)  loss_ce_4: 0.7178 (0.7197)  loss_bbox_4: 2.9105 (2.8338)  loss_giou_4: 2.1642 (2.2649)  loss_ce_unscaled: 0.7308 (0.7286)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5278 (0.5294)  loss_giou_unscaled: 1.0560 (1.1056)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.7158 (0.7296)  loss_bbox_0_unscaled: 0.4807 (0.4919)  loss_giou_0_unscaled: 1.0466 (1.1188)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.7271 (0.7346)  loss_bbox_1_unscaled: 0.5162 (0.5164)  loss_giou_1_unscaled: 1.0648 (1.1266)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.7228 (0.7220)  loss_bbox_2_unscaled: 0.5107 (0.5114)  loss_giou_2_unscaled: 1.0305 (1.1086)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.7124 (0.7200)  loss_bbox_3_unscaled: 0.5282 (0.5268)  loss_giou_3_unscaled: 1.0413 (1.1079)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.7178 (0.7197)  loss_bbox_4_unscaled: 0.5821 (0.5668)  loss_giou_4_unscaled: 1.0821 (1.1325)  cardinality_error_4_unscaled: 2.3750 (2.3616)
Accumulating evaluation results...
DONE (t=0.04s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.092
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.126
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.127
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.087
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.134
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [  0/124]  eta: 0:04:17  lr: 0.000100  class_error: 100.00  loss: 23.1441 (23.1441)  loss_ce: 0.6997 (0.6997)  loss_bbox: 1.6854 (1.6854)  loss_giou: 1.4186 (1.4186)  loss_ce_0: 0.6923 (0.6923)  loss_bbox_0: 1.8795 (1.8795)  loss_giou_0: 1.5725 (1.5725)  loss_ce_1: 0.7386 (0.7386)  loss_bbox_1: 1.7013 (1.7013)  loss_giou_1: 1.4174 (1.4174)  loss_ce_2: 0.7096 (0.7096)  loss_bbox_2: 1.6557 (1.6557)  loss_giou_2: 1.4642 (1.4642)  loss_ce_3: 0.7133 (0.7133)  loss_bbox_3: 1.6230 (1.6230)  loss_giou_3: 1.4155 (1.4155)  loss_ce_4: 0.7037 (0.7037)  loss_bbox_4: 1.6473 (1.6473)  loss_giou_4: 1.4067 (1.4067)  loss_ce_unscaled: 0.6997 (0.6997)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.3371 (0.3371)  loss_giou_unscaled: 0.7093 (0.7093)  cardinality_error_unscaled: 2.0625 (2.0625)  loss_ce_0_unscaled: 0.6923 (0.6923)  loss_bbox_0_unscaled: 0.3759 (0.3759)  loss_giou_0_unscaled: 0.7862 (0.7862)  cardinality_error_0_unscaled: 2.0625 (2.0625)  loss_ce_1_unscaled: 0.7386 (0.7386)  loss_bbox_1_unscaled: 0.3403 (0.3403)  loss_giou_1_unscaled: 0.7087 (0.7087)  cardinality_error_1_unscaled: 2.0625 (2.0625)  loss_ce_2_unscaled: 0.7096 (0.7096)  loss_bbox_2_unscaled: 0.3311 (0.3311)  loss_giou_2_unscaled: 0.7321 (0.7321)  cardinality_error_2_unscaled: 2.0625 (2.0625)  loss_ce_3_unscaled: 0.7133 (0.7133)  loss_bbox_3_unscaled: 0.3246 (0.3246)  loss_giou_3_unscaled: 0.7078 (0.7078)  cardinality_error_3_unscaled: 2.0625 (2.0625)  loss_ce_4_unscaled: 0.7037 (0.7037)  loss_bbox_4_unscaled: 0.3295 (0.3295)  loss_giou_4_unscaled: 0.7034 (0.7034)  cardinality_error_4_unscaled: 2.0625 (2.0625)  time: 2.0760  data: 1.6534  max mem: 16631
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 10/124]  eta: 0:01:21  lr: 0.000100  class_error: 100.00  loss: 19.7007 (19.7645)  loss_ce: 0.7231 (0.7302)  loss_bbox: 1.2511 (1.3180)  loss_giou: 1.1989 (1.2521)  loss_ce_0: 0.7439 (0.7322)  loss_bbox_0: 1.3610 (1.4150)  loss_giou_0: 1.2617 (1.2932)  loss_ce_1: 0.7386 (0.7507)  loss_bbox_1: 1.2585 (1.2910)  loss_giou_1: 1.2291 (1.2078)  loss_ce_2: 0.7448 (0.7412)  loss_bbox_2: 1.2575 (1.2684)  loss_giou_2: 1.1944 (1.2166)  loss_ce_3: 0.7334 (0.7410)  loss_bbox_3: 1.2568 (1.2920)  loss_giou_3: 1.2670 (1.2497)  loss_ce_4: 0.7318 (0.7265)  loss_bbox_4: 1.2658 (1.2877)  loss_giou_4: 1.1784 (1.2511)  loss_ce_unscaled: 0.7231 (0.7302)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2502 (0.2636)  loss_giou_unscaled: 0.5995 (0.6261)  cardinality_error_unscaled: 2.3125 (2.3011)  loss_ce_0_unscaled: 0.7439 (0.7322)  loss_bbox_0_unscaled: 0.2722 (0.2830)  loss_giou_0_unscaled: 0.6309 (0.6466)  cardinality_error_0_unscaled: 2.3125 (2.3011)  loss_ce_1_unscaled: 0.7386 (0.7507)  loss_bbox_1_unscaled: 0.2517 (0.2582)  loss_giou_1_unscaled: 0.6145 (0.6039)  cardinality_error_1_unscaled: 2.3125 (2.2955)  loss_ce_2_unscaled: 0.7448 (0.7412)  loss_bbox_2_unscaled: 0.2515 (0.2537)  loss_giou_2_unscaled: 0.5972 (0.6083)  cardinality_error_2_unscaled: 2.3125 (2.2955)  loss_ce_3_unscaled: 0.7334 (0.7410)  loss_bbox_3_unscaled: 0.2514 (0.2584)  loss_giou_3_unscaled: 0.6335 (0.6248)  cardinality_error_3_unscaled: 2.3125 (2.3011)  loss_ce_4_unscaled: 0.7318 (0.7265)  loss_bbox_4_unscaled: 0.2532 (0.2575)  loss_giou_4_unscaled: 0.5892 (0.6255)  cardinality_error_4_unscaled: 2.3125 (2.3011)  time: 0.7139  data: 0.2437  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 20/124]  eta: 0:01:03  lr: 0.000100  class_error: 100.00  loss: 19.3749 (19.4165)  loss_ce: 0.7399 (0.7321)  loss_bbox: 1.2522 (1.3020)  loss_giou: 1.1413 (1.1846)  loss_ce_0: 0.7383 (0.7303)  loss_bbox_0: 1.3610 (1.4122)  loss_giou_0: 1.1904 (1.2475)  loss_ce_1: 0.7396 (0.7475)  loss_bbox_1: 1.2585 (1.3004)  loss_giou_1: 1.1673 (1.1789)  loss_ce_2: 0.7283 (0.7320)  loss_bbox_2: 1.2236 (1.2871)  loss_giou_2: 1.1455 (1.1732)  loss_ce_3: 0.7334 (0.7374)  loss_bbox_3: 1.2542 (1.2934)  loss_giou_3: 1.1452 (1.1868)  loss_ce_4: 0.7482 (0.7333)  loss_bbox_4: 1.2497 (1.2693)  loss_giou_4: 1.1640 (1.1684)  loss_ce_unscaled: 0.7399 (0.7321)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2504 (0.2604)  loss_giou_unscaled: 0.5706 (0.5923)  cardinality_error_unscaled: 2.2500 (2.2946)  loss_ce_0_unscaled: 0.7383 (0.7303)  loss_bbox_0_unscaled: 0.2722 (0.2824)  loss_giou_0_unscaled: 0.5952 (0.6238)  cardinality_error_0_unscaled: 2.2500 (2.2917)  loss_ce_1_unscaled: 0.7396 (0.7475)  loss_bbox_1_unscaled: 0.2517 (0.2601)  loss_giou_1_unscaled: 0.5837 (0.5895)  cardinality_error_1_unscaled: 2.2500 (2.2887)  loss_ce_2_unscaled: 0.7283 (0.7320)  loss_bbox_2_unscaled: 0.2447 (0.2574)  loss_giou_2_unscaled: 0.5727 (0.5866)  cardinality_error_2_unscaled: 2.2500 (2.2857)  loss_ce_3_unscaled: 0.7334 (0.7374)  loss_bbox_3_unscaled: 0.2508 (0.2587)  loss_giou_3_unscaled: 0.5726 (0.5934)  cardinality_error_3_unscaled: 2.2500 (2.2946)  loss_ce_4_unscaled: 0.7482 (0.7333)  loss_bbox_4_unscaled: 0.2499 (0.2539)  loss_giou_4_unscaled: 0.5820 (0.5842)  cardinality_error_4_unscaled: 2.2500 (2.2917)  time: 0.5345  data: 0.0856  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 30/124]  eta: 0:00:52  lr: 0.000100  class_error: 100.00  loss: 19.0490 (19.3216)  loss_ce: 0.7174 (0.7230)  loss_bbox: 1.2741 (1.2909)  loss_giou: 1.1193 (1.1837)  loss_ce_0: 0.7272 (0.7292)  loss_bbox_0: 1.3625 (1.3905)  loss_giou_0: 1.1904 (1.2578)  loss_ce_1: 0.7396 (0.7457)  loss_bbox_1: 1.2693 (1.2815)  loss_giou_1: 1.1427 (1.1850)  loss_ce_2: 0.7281 (0.7304)  loss_bbox_2: 1.2109 (1.2668)  loss_giou_2: 1.1165 (1.1741)  loss_ce_3: 0.7318 (0.7352)  loss_bbox_3: 1.2285 (1.2789)  loss_giou_3: 1.1228 (1.1916)  loss_ce_4: 0.7258 (0.7240)  loss_bbox_4: 1.2460 (1.2606)  loss_giou_4: 1.0806 (1.1726)  loss_ce_unscaled: 0.7174 (0.7230)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2548 (0.2582)  loss_giou_unscaled: 0.5597 (0.5918)  cardinality_error_unscaled: 2.2500 (2.2802)  loss_ce_0_unscaled: 0.7272 (0.7292)  loss_bbox_0_unscaled: 0.2725 (0.2781)  loss_giou_0_unscaled: 0.5952 (0.6289)  cardinality_error_0_unscaled: 2.2500 (2.2762)  loss_ce_1_unscaled: 0.7396 (0.7457)  loss_bbox_1_unscaled: 0.2539 (0.2563)  loss_giou_1_unscaled: 0.5713 (0.5925)  cardinality_error_1_unscaled: 2.2500 (2.2621)  loss_ce_2_unscaled: 0.7281 (0.7304)  loss_bbox_2_unscaled: 0.2422 (0.2534)  loss_giou_2_unscaled: 0.5582 (0.5870)  cardinality_error_2_unscaled: 2.2500 (2.2641)  loss_ce_3_unscaled: 0.7318 (0.7352)  loss_bbox_3_unscaled: 0.2457 (0.2558)  loss_giou_3_unscaled: 0.5614 (0.5958)  cardinality_error_3_unscaled: 2.2500 (2.2782)  loss_ce_4_unscaled: 0.7258 (0.7240)  loss_bbox_4_unscaled: 0.2492 (0.2521)  loss_giou_4_unscaled: 0.5403 (0.5863)  cardinality_error_4_unscaled: 2.2500 (2.2742)  time: 0.4775  data: 0.0684  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 40/124]  eta: 0:00:43  lr: 0.000100  class_error: 100.00  loss: 18.9251 (19.2337)  loss_ce: 0.7134 (0.7232)  loss_bbox: 1.1904 (1.2758)  loss_giou: 1.1815 (1.1739)  loss_ce_0: 0.7215 (0.7274)  loss_bbox_0: 1.2545 (1.3753)  loss_giou_0: 1.2484 (1.2553)  loss_ce_1: 0.7358 (0.7436)  loss_bbox_1: 1.2637 (1.2838)  loss_giou_1: 1.1851 (1.1947)  loss_ce_2: 0.7281 (0.7281)  loss_bbox_2: 1.2060 (1.2606)  loss_giou_2: 1.1458 (1.1759)  loss_ce_3: 0.7304 (0.7333)  loss_bbox_3: 1.1826 (1.2615)  loss_giou_3: 1.1391 (1.1737)  loss_ce_4: 0.7128 (0.7234)  loss_bbox_4: 1.2631 (1.2548)  loss_giou_4: 1.2093 (1.1693)  loss_ce_unscaled: 0.7134 (0.7232)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2381 (0.2552)  loss_giou_unscaled: 0.5907 (0.5870)  cardinality_error_unscaled: 2.2500 (2.2805)  loss_ce_0_unscaled: 0.7215 (0.7274)  loss_bbox_0_unscaled: 0.2509 (0.2751)  loss_giou_0_unscaled: 0.6242 (0.6277)  cardinality_error_0_unscaled: 2.2500 (2.2774)  loss_ce_1_unscaled: 0.7358 (0.7436)  loss_bbox_1_unscaled: 0.2527 (0.2568)  loss_giou_1_unscaled: 0.5926 (0.5974)  cardinality_error_1_unscaled: 2.2500 (2.2637)  loss_ce_2_unscaled: 0.7281 (0.7281)  loss_bbox_2_unscaled: 0.2412 (0.2521)  loss_giou_2_unscaled: 0.5729 (0.5879)  cardinality_error_2_unscaled: 2.2500 (2.2668)  loss_ce_3_unscaled: 0.7304 (0.7333)  loss_bbox_3_unscaled: 0.2365 (0.2523)  loss_giou_3_unscaled: 0.5696 (0.5869)  cardinality_error_3_unscaled: 2.2500 (2.2790)  loss_ce_4_unscaled: 0.7128 (0.7234)  loss_bbox_4_unscaled: 0.2526 (0.2510)  loss_giou_4_unscaled: 0.6047 (0.5847)  cardinality_error_4_unscaled: 2.2500 (2.2759)  time: 0.4342  data: 0.0652  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 50/124]  eta: 0:00:39  lr: 0.000100  class_error: 100.00  loss: 18.9251 (19.2890)  loss_ce: 0.7187 (0.7232)  loss_bbox: 1.2343 (1.2807)  loss_giou: 1.1758 (1.1821)  loss_ce_0: 0.7276 (0.7296)  loss_bbox_0: 1.2741 (1.3608)  loss_giou_0: 1.2725 (1.2470)  loss_ce_1: 0.7399 (0.7430)  loss_bbox_1: 1.2699 (1.2883)  loss_giou_1: 1.2076 (1.1971)  loss_ce_2: 0.7167 (0.7269)  loss_bbox_2: 1.2197 (1.2624)  loss_giou_2: 1.1748 (1.1792)  loss_ce_3: 0.7339 (0.7352)  loss_bbox_3: 1.2199 (1.2729)  loss_giou_3: 1.1182 (1.1834)  loss_ce_4: 0.7304 (0.7251)  loss_bbox_4: 1.2791 (1.2746)  loss_giou_4: 1.1003 (1.1776)  loss_ce_unscaled: 0.7187 (0.7232)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2469 (0.2561)  loss_giou_unscaled: 0.5879 (0.5910)  cardinality_error_unscaled: 2.2500 (2.2843)  loss_ce_0_unscaled: 0.7276 (0.7296)  loss_bbox_0_unscaled: 0.2548 (0.2722)  loss_giou_0_unscaled: 0.6363 (0.6235)  cardinality_error_0_unscaled: 2.2500 (2.2819)  loss_ce_1_unscaled: 0.7399 (0.7430)  loss_bbox_1_unscaled: 0.2540 (0.2577)  loss_giou_1_unscaled: 0.6038 (0.5985)  cardinality_error_1_unscaled: 2.2500 (2.2696)  loss_ce_2_unscaled: 0.7167 (0.7269)  loss_bbox_2_unscaled: 0.2439 (0.2525)  loss_giou_2_unscaled: 0.5874 (0.5896)  cardinality_error_2_unscaled: 2.2500 (2.2733)  loss_ce_3_unscaled: 0.7339 (0.7352)  loss_bbox_3_unscaled: 0.2440 (0.2546)  loss_giou_3_unscaled: 0.5591 (0.5917)  cardinality_error_3_unscaled: 2.2500 (2.2831)  loss_ce_4_unscaled: 0.7304 (0.7251)  loss_bbox_4_unscaled: 0.2558 (0.2549)  loss_giou_4_unscaled: 0.5501 (0.5888)  cardinality_error_4_unscaled: 2.2500 (2.2806)  time: 0.4798  data: 0.0988  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 60/124]  eta: 0:00:34  lr: 0.000100  class_error: 100.00  loss: 18.6333 (19.1996)  loss_ce: 0.7053 (0.7189)  loss_bbox: 1.2423 (1.2737)  loss_giou: 1.1758 (1.1822)  loss_ce_0: 0.7284 (0.7298)  loss_bbox_0: 1.2242 (1.3397)  loss_giou_0: 1.2329 (1.2398)  loss_ce_1: 0.7298 (0.7401)  loss_bbox_1: 1.2462 (1.2742)  loss_giou_1: 1.2076 (1.1951)  loss_ce_2: 0.7175 (0.7248)  loss_bbox_2: 1.1960 (1.2551)  loss_giou_2: 1.1850 (1.1817)  loss_ce_3: 0.7239 (0.7316)  loss_bbox_3: 1.2507 (1.2678)  loss_giou_3: 1.1835 (1.1837)  loss_ce_4: 0.7219 (0.7210)  loss_bbox_4: 1.2223 (1.2610)  loss_giou_4: 1.1881 (1.1791)  loss_ce_unscaled: 0.7053 (0.7189)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2485 (0.2547)  loss_giou_unscaled: 0.5879 (0.5911)  cardinality_error_unscaled: 2.3125 (2.2848)  loss_ce_0_unscaled: 0.7284 (0.7298)  loss_bbox_0_unscaled: 0.2448 (0.2679)  loss_giou_0_unscaled: 0.6165 (0.6199)  cardinality_error_0_unscaled: 2.3125 (2.2807)  loss_ce_1_unscaled: 0.7298 (0.7401)  loss_bbox_1_unscaled: 0.2492 (0.2548)  loss_giou_1_unscaled: 0.6038 (0.5976)  cardinality_error_1_unscaled: 2.3125 (2.2725)  loss_ce_2_unscaled: 0.7175 (0.7248)  loss_bbox_2_unscaled: 0.2392 (0.2510)  loss_giou_2_unscaled: 0.5925 (0.5909)  cardinality_error_2_unscaled: 2.3125 (2.2756)  loss_ce_3_unscaled: 0.7239 (0.7316)  loss_bbox_3_unscaled: 0.2501 (0.2536)  loss_giou_3_unscaled: 0.5917 (0.5919)  cardinality_error_3_unscaled: 2.3125 (2.2838)  loss_ce_4_unscaled: 0.7219 (0.7210)  loss_bbox_4_unscaled: 0.2445 (0.2522)  loss_giou_4_unscaled: 0.5941 (0.5895)  cardinality_error_4_unscaled: 2.3125 (2.2818)  time: 0.5941  data: 0.1868  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 70/124]  eta: 0:00:29  lr: 0.000100  class_error: 100.00  loss: 18.3073 (19.0531)  loss_ce: 0.6925 (0.7153)  loss_bbox: 1.2335 (1.2684)  loss_giou: 1.1818 (1.1849)  loss_ce_0: 0.7085 (0.7249)  loss_bbox_0: 1.1807 (1.3166)  loss_giou_0: 1.1873 (1.2285)  loss_ce_1: 0.7206 (0.7371)  loss_bbox_1: 1.1244 (1.2559)  loss_giou_1: 1.1701 (1.1862)  loss_ce_2: 0.7019 (0.7198)  loss_bbox_2: 1.1851 (1.2439)  loss_giou_2: 1.1836 (1.1736)  loss_ce_3: 0.7076 (0.7278)  loss_bbox_3: 1.1503 (1.2530)  loss_giou_3: 1.1291 (1.1756)  loss_ce_4: 0.6976 (0.7183)  loss_bbox_4: 1.1798 (1.2502)  loss_giou_4: 1.1768 (1.1732)  loss_ce_unscaled: 0.6925 (0.7153)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2467 (0.2537)  loss_giou_unscaled: 0.5909 (0.5925)  cardinality_error_unscaled: 2.2500 (2.2720)  loss_ce_0_unscaled: 0.7085 (0.7249)  loss_bbox_0_unscaled: 0.2361 (0.2633)  loss_giou_0_unscaled: 0.5936 (0.6143)  cardinality_error_0_unscaled: 2.2500 (2.2685)  loss_ce_1_unscaled: 0.7206 (0.7371)  loss_bbox_1_unscaled: 0.2249 (0.2512)  loss_giou_1_unscaled: 0.5850 (0.5931)  cardinality_error_1_unscaled: 2.2500 (2.2597)  loss_ce_2_unscaled: 0.7019 (0.7198)  loss_bbox_2_unscaled: 0.2370 (0.2488)  loss_giou_2_unscaled: 0.5918 (0.5868)  cardinality_error_2_unscaled: 2.2500 (2.2641)  loss_ce_3_unscaled: 0.7076 (0.7278)  loss_bbox_3_unscaled: 0.2301 (0.2506)  loss_giou_3_unscaled: 0.5646 (0.5878)  cardinality_error_3_unscaled: 2.2500 (2.2711)  loss_ce_4_unscaled: 0.6976 (0.7183)  loss_bbox_4_unscaled: 0.2360 (0.2500)  loss_giou_4_unscaled: 0.5884 (0.5866)  cardinality_error_4_unscaled: 2.2500 (2.2694)  time: 0.6049  data: 0.2006  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 80/124]  eta: 0:00:23  lr: 0.000100  class_error: 100.00  loss: 18.3313 (19.0780)  loss_ce: 0.6973 (0.7141)  loss_bbox: 1.3113 (1.2908)  loss_giou: 1.1889 (1.1883)  loss_ce_0: 0.6884 (0.7216)  loss_bbox_0: 1.1807 (1.3120)  loss_giou_0: 1.1267 (1.2153)  loss_ce_1: 0.7090 (0.7332)  loss_bbox_1: 1.2126 (1.2637)  loss_giou_1: 1.1628 (1.1833)  loss_ce_2: 0.6674 (0.7151)  loss_bbox_2: 1.2382 (1.2526)  loss_giou_2: 1.1292 (1.1730)  loss_ce_3: 0.6965 (0.7258)  loss_bbox_3: 1.1881 (1.2615)  loss_giou_3: 1.1291 (1.1743)  loss_ce_4: 0.6991 (0.7167)  loss_bbox_4: 1.2057 (1.2625)  loss_giou_4: 1.1527 (1.1740)  loss_ce_unscaled: 0.6973 (0.7141)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2623 (0.2582)  loss_giou_unscaled: 0.5944 (0.5941)  cardinality_error_unscaled: 2.1875 (2.2647)  loss_ce_0_unscaled: 0.6884 (0.7216)  loss_bbox_0_unscaled: 0.2361 (0.2624)  loss_giou_0_unscaled: 0.5633 (0.6077)  cardinality_error_0_unscaled: 2.1875 (2.2616)  loss_ce_1_unscaled: 0.7090 (0.7332)  loss_bbox_1_unscaled: 0.2425 (0.2527)  loss_giou_1_unscaled: 0.5814 (0.5916)  cardinality_error_1_unscaled: 2.1875 (2.2539)  loss_ce_2_unscaled: 0.6674 (0.7151)  loss_bbox_2_unscaled: 0.2476 (0.2505)  loss_giou_2_unscaled: 0.5646 (0.5865)  cardinality_error_2_unscaled: 2.1875 (2.2577)  loss_ce_3_unscaled: 0.6965 (0.7258)  loss_bbox_3_unscaled: 0.2376 (0.2523)  loss_giou_3_unscaled: 0.5646 (0.5872)  cardinality_error_3_unscaled: 2.1875 (2.2639)  loss_ce_4_unscaled: 0.6991 (0.7167)  loss_bbox_4_unscaled: 0.2411 (0.2525)  loss_giou_4_unscaled: 0.5764 (0.5870)  cardinality_error_4_unscaled: 2.1875 (2.2623)  time: 0.5294  data: 0.1227  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [ 90/124]  eta: 0:00:18  lr: 0.000100  class_error: 100.00  loss: 18.7384 (19.0357)  loss_ce: 0.6975 (0.7122)  loss_bbox: 1.3462 (1.2909)  loss_giou: 1.1434 (1.1808)  loss_ce_0: 0.6884 (0.7183)  loss_bbox_0: 1.3096 (1.3072)  loss_giou_0: 1.1488 (1.2151)  loss_ce_1: 0.6988 (0.7291)  loss_bbox_1: 1.3178 (1.2657)  loss_giou_1: 1.1644 (1.1860)  loss_ce_2: 0.6781 (0.7120)  loss_bbox_2: 1.2824 (1.2524)  loss_giou_2: 1.1292 (1.1700)  loss_ce_3: 0.6956 (0.7229)  loss_bbox_3: 1.3094 (1.2608)  loss_giou_3: 1.1585 (1.1711)  loss_ce_4: 0.7028 (0.7150)  loss_bbox_4: 1.2591 (1.2594)  loss_giou_4: 1.1386 (1.1669)  loss_ce_unscaled: 0.6975 (0.7122)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2692 (0.2582)  loss_giou_unscaled: 0.5717 (0.5904)  cardinality_error_unscaled: 2.1250 (2.2534)  loss_ce_0_unscaled: 0.6884 (0.7183)  loss_bbox_0_unscaled: 0.2619 (0.2614)  loss_giou_0_unscaled: 0.5744 (0.6075)  cardinality_error_0_unscaled: 2.1250 (2.2500)  loss_ce_1_unscaled: 0.6988 (0.7291)  loss_bbox_1_unscaled: 0.2636 (0.2531)  loss_giou_1_unscaled: 0.5822 (0.5930)  cardinality_error_1_unscaled: 2.1250 (2.2438)  loss_ce_2_unscaled: 0.6781 (0.7120)  loss_bbox_2_unscaled: 0.2565 (0.2505)  loss_giou_2_unscaled: 0.5646 (0.5850)  cardinality_error_2_unscaled: 2.1250 (2.2473)  loss_ce_3_unscaled: 0.6956 (0.7229)  loss_bbox_3_unscaled: 0.2619 (0.2522)  loss_giou_3_unscaled: 0.5793 (0.5855)  cardinality_error_3_unscaled: 2.1250 (2.2527)  loss_ce_4_unscaled: 0.7028 (0.7150)  loss_bbox_4_unscaled: 0.2518 (0.2519)  loss_giou_4_unscaled: 0.5693 (0.5835)  cardinality_error_4_unscaled: 2.1250 (2.2514)  time: 0.4935  data: 0.0941  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [100/124]  eta: 0:00:12  lr: 0.000100  class_error: 100.00  loss: 18.2589 (18.9510)  loss_ce: 0.6983 (0.7116)  loss_bbox: 1.2849 (1.2895)  loss_giou: 1.1079 (1.1749)  loss_ce_0: 0.6955 (0.7179)  loss_bbox_0: 1.2308 (1.2955)  loss_giou_0: 1.1229 (1.2032)  loss_ce_1: 0.7102 (0.7275)  loss_bbox_1: 1.1651 (1.2547)  loss_giou_1: 1.1136 (1.1752)  loss_ce_2: 0.6894 (0.7111)  loss_bbox_2: 1.1920 (1.2486)  loss_giou_2: 1.1061 (1.1623)  loss_ce_3: 0.7041 (0.7211)  loss_bbox_3: 1.1963 (1.2579)  loss_giou_3: 1.1119 (1.1663)  loss_ce_4: 0.7094 (0.7148)  loss_bbox_4: 1.1966 (1.2588)  loss_giou_4: 1.0718 (1.1599)  loss_ce_unscaled: 0.6983 (0.7116)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2570 (0.2579)  loss_giou_unscaled: 0.5539 (0.5875)  cardinality_error_unscaled: 2.1875 (2.2580)  loss_ce_0_unscaled: 0.6955 (0.7179)  loss_bbox_0_unscaled: 0.2462 (0.2591)  loss_giou_0_unscaled: 0.5614 (0.6016)  cardinality_error_0_unscaled: 2.1875 (2.2537)  loss_ce_1_unscaled: 0.7102 (0.7275)  loss_bbox_1_unscaled: 0.2330 (0.2509)  loss_giou_1_unscaled: 0.5568 (0.5876)  cardinality_error_1_unscaled: 2.1875 (2.2488)  loss_ce_2_unscaled: 0.6894 (0.7111)  loss_bbox_2_unscaled: 0.2384 (0.2497)  loss_giou_2_unscaled: 0.5530 (0.5811)  cardinality_error_2_unscaled: 2.1875 (2.2525)  loss_ce_3_unscaled: 0.7041 (0.7211)  loss_bbox_3_unscaled: 0.2393 (0.2516)  loss_giou_3_unscaled: 0.5559 (0.5832)  cardinality_error_3_unscaled: 2.1875 (2.2574)  loss_ce_4_unscaled: 0.7094 (0.7148)  loss_bbox_4_unscaled: 0.2393 (0.2518)  loss_giou_4_unscaled: 0.5359 (0.5799)  cardinality_error_4_unscaled: 2.1875 (2.2562)  time: 0.4918  data: 0.1119  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [110/124]  eta: 0:00:07  lr: 0.000100  class_error: 100.00  loss: 17.3849 (18.7795)  loss_ce: 0.6979 (0.7101)  loss_bbox: 1.1638 (1.2717)  loss_giou: 1.0911 (1.1655)  loss_ce_0: 0.7132 (0.7158)  loss_bbox_0: 1.0779 (1.2733)  loss_giou_0: 1.0967 (1.1922)  loss_ce_1: 0.7131 (0.7254)  loss_bbox_1: 1.0831 (1.2346)  loss_giou_1: 1.0496 (1.1623)  loss_ce_2: 0.7138 (0.7114)  loss_bbox_2: 1.1126 (1.2323)  loss_giou_2: 1.0750 (1.1556)  loss_ce_3: 0.7132 (0.7202)  loss_bbox_3: 1.0900 (1.2409)  loss_giou_3: 1.0978 (1.1597)  loss_ce_4: 0.7082 (0.7134)  loss_bbox_4: 1.1071 (1.2418)  loss_giou_4: 1.0718 (1.1532)  loss_ce_unscaled: 0.6979 (0.7101)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2328 (0.2543)  loss_giou_unscaled: 0.5455 (0.5828)  cardinality_error_unscaled: 2.3125 (2.2590)  loss_ce_0_unscaled: 0.7132 (0.7158)  loss_bbox_0_unscaled: 0.2156 (0.2547)  loss_giou_0_unscaled: 0.5484 (0.5961)  cardinality_error_0_unscaled: 2.3125 (2.2551)  loss_ce_1_unscaled: 0.7131 (0.7254)  loss_bbox_1_unscaled: 0.2166 (0.2469)  loss_giou_1_unscaled: 0.5248 (0.5812)  cardinality_error_1_unscaled: 2.2500 (2.2500)  loss_ce_2_unscaled: 0.7138 (0.7114)  loss_bbox_2_unscaled: 0.2225 (0.2465)  loss_giou_2_unscaled: 0.5375 (0.5778)  cardinality_error_2_unscaled: 2.3125 (2.2534)  loss_ce_3_unscaled: 0.7132 (0.7202)  loss_bbox_3_unscaled: 0.2180 (0.2482)  loss_giou_3_unscaled: 0.5489 (0.5799)  cardinality_error_3_unscaled: 2.3125 (2.2584)  loss_ce_4_unscaled: 0.7082 (0.7134)  loss_bbox_4_unscaled: 0.2214 (0.2484)  loss_giou_4_unscaled: 0.5359 (0.5766)  cardinality_error_4_unscaled: 2.3125 (2.2573)  time: 0.4611  data: 0.1040  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [120/124]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 16.8698 (18.6051)  loss_ce: 0.6885 (0.7075)  loss_bbox: 1.0867 (1.2557)  loss_giou: 1.0707 (1.1561)  loss_ce_0: 0.6948 (0.7136)  loss_bbox_0: 1.0172 (1.2542)  loss_giou_0: 1.0543 (1.1783)  loss_ce_1: 0.6987 (0.7225)  loss_bbox_1: 1.0205 (1.2199)  loss_giou_1: 1.0605 (1.1522)  loss_ce_2: 0.6872 (0.7082)  loss_bbox_2: 1.0214 (1.2165)  loss_giou_2: 1.0587 (1.1436)  loss_ce_3: 0.6999 (0.7175)  loss_bbox_3: 1.0522 (1.2256)  loss_giou_3: 1.0686 (1.1495)  loss_ce_4: 0.6947 (0.7114)  loss_bbox_4: 1.0348 (1.2280)  loss_giou_4: 1.0707 (1.1447)  loss_ce_unscaled: 0.6885 (0.7075)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2173 (0.2511)  loss_giou_unscaled: 0.5354 (0.5781)  cardinality_error_unscaled: 2.2500 (2.2567)  loss_ce_0_unscaled: 0.6948 (0.7136)  loss_bbox_0_unscaled: 0.2034 (0.2508)  loss_giou_0_unscaled: 0.5271 (0.5892)  cardinality_error_0_unscaled: 2.2500 (2.2531)  loss_ce_1_unscaled: 0.6987 (0.7225)  loss_bbox_1_unscaled: 0.2041 (0.2440)  loss_giou_1_unscaled: 0.5303 (0.5761)  cardinality_error_1_unscaled: 2.2500 (2.2474)  loss_ce_2_unscaled: 0.6872 (0.7082)  loss_bbox_2_unscaled: 0.2043 (0.2433)  loss_giou_2_unscaled: 0.5294 (0.5718)  cardinality_error_2_unscaled: 2.2500 (2.2515)  loss_ce_3_unscaled: 0.6999 (0.7175)  loss_bbox_3_unscaled: 0.2104 (0.2451)  loss_giou_3_unscaled: 0.5343 (0.5747)  cardinality_error_3_unscaled: 2.2500 (2.2562)  loss_ce_4_unscaled: 0.6947 (0.7114)  loss_bbox_4_unscaled: 0.2070 (0.2456)  loss_giou_4_unscaled: 0.5354 (0.5723)  cardinality_error_4_unscaled: 2.2500 (2.2552)  time: 0.4753  data: 0.1072  max mem: 35688
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [1]  [123/124]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 16.8698 (18.5869)  loss_ce: 0.6845 (0.7064)  loss_bbox: 1.0931 (1.2546)  loss_giou: 1.0707 (1.1558)  loss_ce_0: 0.6922 (0.7126)  loss_bbox_0: 1.0246 (1.2524)  loss_giou_0: 1.0543 (1.1796)  loss_ce_1: 0.6936 (0.7212)  loss_bbox_1: 1.0360 (1.2176)  loss_giou_1: 1.0605 (1.1535)  loss_ce_2: 0.6759 (0.7066)  loss_bbox_2: 1.0429 (1.2144)  loss_giou_2: 1.0587 (1.1448)  loss_ce_3: 0.6997 (0.7159)  loss_bbox_3: 1.0522 (1.2228)  loss_giou_3: 1.0686 (1.1494)  loss_ce_4: 0.6911 (0.7102)  loss_bbox_4: 1.0348 (1.2253)  loss_giou_4: 1.0707 (1.1440)  loss_ce_unscaled: 0.6845 (0.7064)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2186 (0.2509)  loss_giou_unscaled: 0.5354 (0.5779)  cardinality_error_unscaled: 2.2500 (2.2545)  loss_ce_0_unscaled: 0.6922 (0.7126)  loss_bbox_0_unscaled: 0.2049 (0.2505)  loss_giou_0_unscaled: 0.5271 (0.5898)  cardinality_error_0_unscaled: 2.2500 (2.2510)  loss_ce_1_unscaled: 0.6936 (0.7212)  loss_bbox_1_unscaled: 0.2072 (0.2435)  loss_giou_1_unscaled: 0.5303 (0.5767)  cardinality_error_1_unscaled: 2.2500 (2.2455)  loss_ce_2_unscaled: 0.6759 (0.7066)  loss_bbox_2_unscaled: 0.2086 (0.2429)  loss_giou_2_unscaled: 0.5294 (0.5724)  cardinality_error_2_unscaled: 2.2500 (2.2495)  loss_ce_3_unscaled: 0.6997 (0.7159)  loss_bbox_3_unscaled: 0.2104 (0.2446)  loss_giou_3_unscaled: 0.5343 (0.5747)  cardinality_error_3_unscaled: 2.2500 (2.2540)  loss_ce_4_unscaled: 0.6911 (0.7102)  loss_bbox_4_unscaled: 0.2070 (0.2451)  loss_giou_4_unscaled: 0.5354 (0.5720)  cardinality_error_4_unscaled: 2.2500 (2.2530)  time: 0.5026  data: 0.1279  max mem: 35688
Epoch: [1] Total time: 0:01:05 (0.5252 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 16.8698 (18.5869)  loss_ce: 0.6845 (0.7064)  loss_bbox: 1.0931 (1.2546)  loss_giou: 1.0707 (1.1558)  loss_ce_0: 0.6922 (0.7126)  loss_bbox_0: 1.0246 (1.2524)  loss_giou_0: 1.0543 (1.1796)  loss_ce_1: 0.6936 (0.7212)  loss_bbox_1: 1.0360 (1.2176)  loss_giou_1: 1.0605 (1.1535)  loss_ce_2: 0.6759 (0.7066)  loss_bbox_2: 1.0429 (1.2144)  loss_giou_2: 1.0587 (1.1448)  loss_ce_3: 0.6997 (0.7159)  loss_bbox_3: 1.0522 (1.2228)  loss_giou_3: 1.0686 (1.1494)  loss_ce_4: 0.6911 (0.7102)  loss_bbox_4: 1.0348 (1.2253)  loss_giou_4: 1.0707 (1.1440)  loss_ce_unscaled: 0.6845 (0.7064)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2186 (0.2509)  loss_giou_unscaled: 0.5354 (0.5779)  cardinality_error_unscaled: 2.2500 (2.2545)  loss_ce_0_unscaled: 0.6922 (0.7126)  loss_bbox_0_unscaled: 0.2049 (0.2505)  loss_giou_0_unscaled: 0.5271 (0.5898)  cardinality_error_0_unscaled: 2.2500 (2.2510)  loss_ce_1_unscaled: 0.6936 (0.7212)  loss_bbox_1_unscaled: 0.2072 (0.2435)  loss_giou_1_unscaled: 0.5303 (0.5767)  cardinality_error_1_unscaled: 2.2500 (2.2455)  loss_ce_2_unscaled: 0.6759 (0.7066)  loss_bbox_2_unscaled: 0.2086 (0.2429)  loss_giou_2_unscaled: 0.5294 (0.5724)  cardinality_error_2_unscaled: 2.2500 (2.2495)  loss_ce_3_unscaled: 0.6997 (0.7159)  loss_bbox_3_unscaled: 0.2104 (0.2446)  loss_giou_3_unscaled: 0.5343 (0.5747)  cardinality_error_3_unscaled: 2.2500 (2.2540)  loss_ce_4_unscaled: 0.6911 (0.7102)  loss_bbox_4_unscaled: 0.2070 (0.2451)  loss_giou_4_unscaled: 0.5354 (0.5720)  cardinality_error_4_unscaled: 2.2500 (2.2530)

End of training epoch
Total execution time = 65.171 sec
Max memory used by tensors = 37421222912 bytes
Max memory cached = 40477130752 bytes
Total memory reserved = 40477130752 bytes
Total memory allocated = 864940544 bytes
Test:  [ 0/14]  eta: 0:00:21  class_error: 100.00  loss: 39.4876 (39.4876)  loss_ce: 0.6828 (0.6828)  loss_bbox: 3.0734 (3.0734)  loss_giou: 2.5159 (2.5159)  loss_ce_0: 0.6519 (0.6519)  loss_bbox_0: 2.9293 (2.9293)  loss_giou_0: 2.9681 (2.9681)  loss_ce_1: 0.6568 (0.6568)  loss_bbox_1: 3.1307 (3.1307)  loss_giou_1: 2.9349 (2.9349)  loss_ce_2: 0.6607 (0.6607)  loss_bbox_2: 3.5729 (3.5729)  loss_giou_2: 3.0391 (3.0391)  loss_ce_3: 0.6678 (0.6678)  loss_bbox_3: 3.1070 (3.1070)  loss_giou_3: 2.8130 (2.8130)  loss_ce_4: 0.6686 (0.6686)  loss_bbox_4: 2.8191 (2.8191)  loss_giou_4: 2.5957 (2.5957)  loss_ce_unscaled: 0.6828 (0.6828)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.6147 (0.6147)  loss_giou_unscaled: 1.2580 (1.2580)  cardinality_error_unscaled: 2.1875 (2.1875)  loss_ce_0_unscaled: 0.6519 (0.6519)  loss_bbox_0_unscaled: 0.5859 (0.5859)  loss_giou_0_unscaled: 1.4840 (1.4840)  cardinality_error_0_unscaled: 2.1875 (2.1875)  loss_ce_1_unscaled: 0.6568 (0.6568)  loss_bbox_1_unscaled: 0.6261 (0.6261)  loss_giou_1_unscaled: 1.4675 (1.4675)  cardinality_error_1_unscaled: 2.1875 (2.1875)  loss_ce_2_unscaled: 0.6607 (0.6607)  loss_bbox_2_unscaled: 0.7146 (0.7146)  loss_giou_2_unscaled: 1.5195 (1.5195)  cardinality_error_2_unscaled: 2.1875 (2.1875)  loss_ce_3_unscaled: 0.6678 (0.6678)  loss_bbox_3_unscaled: 0.6214 (0.6214)  loss_giou_3_unscaled: 1.4065 (1.4065)  cardinality_error_3_unscaled: 2.1875 (2.1875)  loss_ce_4_unscaled: 0.6686 (0.6686)  loss_bbox_4_unscaled: 0.5638 (0.5638)  loss_giou_4_unscaled: 1.2978 (1.2978)  cardinality_error_4_unscaled: 2.1875 (2.1875)  time: 1.5566  data: 1.2953  max mem: 35688
Test:  [10/14]  eta: 0:00:02  class_error: 100.00  loss: 36.5075 (36.4295)  loss_ce: 0.6905 (0.7005)  loss_bbox: 2.9982 (2.9568)  loss_giou: 2.1792 (2.2770)  loss_ce_0: 0.7094 (0.6895)  loss_bbox_0: 2.8280 (2.8245)  loss_giou_0: 2.5273 (2.5105)  loss_ce_1: 0.7016 (0.6878)  loss_bbox_1: 2.9187 (2.9443)  loss_giou_1: 2.5436 (2.5117)  loss_ce_2: 0.6971 (0.6901)  loss_bbox_2: 3.4471 (3.3305)  loss_giou_2: 2.6186 (2.6453)  loss_ce_3: 0.6734 (0.6816)  loss_bbox_3: 2.8683 (2.8501)  loss_giou_3: 2.4219 (2.4218)  loss_ce_4: 0.6736 (0.6808)  loss_bbox_4: 2.7575 (2.7004)  loss_giou_4: 2.2099 (2.3263)  loss_ce_unscaled: 0.6905 (0.7005)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5996 (0.5914)  loss_giou_unscaled: 1.0896 (1.1385)  cardinality_error_unscaled: 2.2500 (2.2955)  loss_ce_0_unscaled: 0.7094 (0.6895)  loss_bbox_0_unscaled: 0.5656 (0.5649)  loss_giou_0_unscaled: 1.2636 (1.2553)  cardinality_error_0_unscaled: 2.2500 (2.2955)  loss_ce_1_unscaled: 0.7016 (0.6878)  loss_bbox_1_unscaled: 0.5837 (0.5889)  loss_giou_1_unscaled: 1.2718 (1.2559)  cardinality_error_1_unscaled: 2.2500 (2.2955)  loss_ce_2_unscaled: 0.6971 (0.6901)  loss_bbox_2_unscaled: 0.6894 (0.6661)  loss_giou_2_unscaled: 1.3093 (1.3227)  cardinality_error_2_unscaled: 2.2500 (2.2955)  loss_ce_3_unscaled: 0.6734 (0.6816)  loss_bbox_3_unscaled: 0.5737 (0.5700)  loss_giou_3_unscaled: 1.2109 (1.2109)  cardinality_error_3_unscaled: 2.2500 (2.2955)  loss_ce_4_unscaled: 0.6736 (0.6808)  loss_bbox_4_unscaled: 0.5515 (0.5401)  loss_giou_4_unscaled: 1.1049 (1.1631)  cardinality_error_4_unscaled: 2.2500 (2.2955)  time: 0.5745  data: 0.3087  max mem: 35688
Test:  [13/14]  eta: 0:00:00  class_error: 100.00  loss: 37.2613 (36.7463)  loss_ce: 0.7129 (0.7108)  loss_bbox: 2.9982 (3.0034)  loss_giou: 2.1792 (2.2472)  loss_ce_0: 0.7107 (0.7076)  loss_bbox_0: 2.9078 (2.8951)  loss_giou_0: 2.5043 (2.5006)  loss_ce_1: 0.7074 (0.7038)  loss_bbox_1: 3.0828 (3.0210)  loss_giou_1: 2.5161 (2.5029)  loss_ce_2: 0.7004 (0.7044)  loss_bbox_2: 3.4473 (3.3892)  loss_giou_2: 2.6137 (2.6380)  loss_ce_3: 0.6880 (0.6908)  loss_bbox_3: 2.9324 (2.8911)  loss_giou_3: 2.3156 (2.4074)  loss_ce_4: 0.6881 (0.6893)  loss_bbox_4: 2.7575 (2.7430)  loss_giou_4: 2.2099 (2.3009)  loss_ce_unscaled: 0.7129 (0.7108)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5996 (0.6007)  loss_giou_unscaled: 1.0896 (1.1236)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.7107 (0.7076)  loss_bbox_0_unscaled: 0.5816 (0.5790)  loss_giou_0_unscaled: 1.2522 (1.2503)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.7074 (0.7038)  loss_bbox_1_unscaled: 0.6166 (0.6042)  loss_giou_1_unscaled: 1.2580 (1.2514)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.7004 (0.7044)  loss_bbox_2_unscaled: 0.6895 (0.6778)  loss_giou_2_unscaled: 1.3068 (1.3190)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.6880 (0.6908)  loss_bbox_3_unscaled: 0.5865 (0.5782)  loss_giou_3_unscaled: 1.1578 (1.2037)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.6881 (0.6893)  loss_bbox_4_unscaled: 0.5515 (0.5486)  loss_giou_4_unscaled: 1.1049 (1.1505)  cardinality_error_4_unscaled: 2.3750 (2.3616)  time: 0.5046  data: 0.2560  max mem: 35688
Test: Total time: 0:00:07 (0.5097 s / it)
Averaged stats: class_error: 100.00  loss: 37.2613 (36.7463)  loss_ce: 0.7129 (0.7108)  loss_bbox: 2.9982 (3.0034)  loss_giou: 2.1792 (2.2472)  loss_ce_0: 0.7107 (0.7076)  loss_bbox_0: 2.9078 (2.8951)  loss_giou_0: 2.5043 (2.5006)  loss_ce_1: 0.7074 (0.7038)  loss_bbox_1: 3.0828 (3.0210)  loss_giou_1: 2.5161 (2.5029)  loss_ce_2: 0.7004 (0.7044)  loss_bbox_2: 3.4473 (3.3892)  loss_giou_2: 2.6137 (2.6380)  loss_ce_3: 0.6880 (0.6908)  loss_bbox_3: 2.9324 (2.8911)  loss_giou_3: 2.3156 (2.4074)  loss_ce_4: 0.6881 (0.6893)  loss_bbox_4: 2.7575 (2.7430)  loss_giou_4: 2.2099 (2.3009)  loss_ce_unscaled: 0.7129 (0.7108)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5996 (0.6007)  loss_giou_unscaled: 1.0896 (1.1236)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.7107 (0.7076)  loss_bbox_0_unscaled: 0.5816 (0.5790)  loss_giou_0_unscaled: 1.2522 (1.2503)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.7074 (0.7038)  loss_bbox_1_unscaled: 0.6166 (0.6042)  loss_giou_1_unscaled: 1.2580 (1.2514)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.7004 (0.7044)  loss_bbox_2_unscaled: 0.6895 (0.6778)  loss_giou_2_unscaled: 1.3068 (1.3190)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.6880 (0.6908)  loss_bbox_3_unscaled: 0.5865 (0.5782)  loss_giou_3_unscaled: 1.1578 (1.2037)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.6881 (0.6893)  loss_bbox_4_unscaled: 0.5515 (0.5486)  loss_giou_4_unscaled: 1.1049 (1.1505)  cardinality_error_4_unscaled: 2.3750 (2.3616)
Accumulating evaluation results...
DONE (t=0.04s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.095
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.128
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.128
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.093
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.134
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [  0/124]  eta: 0:04:38  lr: 0.000100  class_error: 100.00  loss: 17.2564 (17.2564)  loss_ce: 0.6600 (0.6600)  loss_bbox: 1.1436 (1.1436)  loss_giou: 0.9541 (0.9541)  loss_ce_0: 0.6863 (0.6863)  loss_bbox_0: 1.2057 (1.2057)  loss_giou_0: 1.0344 (1.0344)  loss_ce_1: 0.6865 (0.6865)  loss_bbox_1: 1.1830 (1.1830)  loss_giou_1: 1.0759 (1.0759)  loss_ce_2: 0.6484 (0.6484)  loss_bbox_2: 1.2153 (1.2153)  loss_giou_2: 1.0908 (1.0908)  loss_ce_3: 0.6576 (0.6576)  loss_bbox_3: 1.1572 (1.1572)  loss_giou_3: 0.9715 (0.9715)  loss_ce_4: 0.6608 (0.6608)  loss_bbox_4: 1.2134 (1.2134)  loss_giou_4: 1.0118 (1.0118)  loss_ce_unscaled: 0.6600 (0.6600)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2287 (0.2287)  loss_giou_unscaled: 0.4771 (0.4771)  cardinality_error_unscaled: 2.1875 (2.1875)  loss_ce_0_unscaled: 0.6863 (0.6863)  loss_bbox_0_unscaled: 0.2411 (0.2411)  loss_giou_0_unscaled: 0.5172 (0.5172)  cardinality_error_0_unscaled: 2.1875 (2.1875)  loss_ce_1_unscaled: 0.6865 (0.6865)  loss_bbox_1_unscaled: 0.2366 (0.2366)  loss_giou_1_unscaled: 0.5379 (0.5379)  cardinality_error_1_unscaled: 2.1875 (2.1875)  loss_ce_2_unscaled: 0.6484 (0.6484)  loss_bbox_2_unscaled: 0.2431 (0.2431)  loss_giou_2_unscaled: 0.5454 (0.5454)  cardinality_error_2_unscaled: 2.1875 (2.1875)  loss_ce_3_unscaled: 0.6576 (0.6576)  loss_bbox_3_unscaled: 0.2314 (0.2314)  loss_giou_3_unscaled: 0.4858 (0.4858)  cardinality_error_3_unscaled: 2.1875 (2.1875)  loss_ce_4_unscaled: 0.6608 (0.6608)  loss_bbox_4_unscaled: 0.2427 (0.2427)  loss_giou_4_unscaled: 0.5059 (0.5059)  cardinality_error_4_unscaled: 2.1875 (2.1875)  time: 2.2460  data: 1.8272  max mem: 17244
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 10/124]  eta: 0:01:20  lr: 0.000100  class_error: 100.00  loss: 17.7602 (17.8169)  loss_ce: 0.6789 (0.6756)  loss_bbox: 1.1916 (1.2385)  loss_giou: 1.0642 (1.1111)  loss_ce_0: 0.6894 (0.6861)  loss_bbox_0: 1.1987 (1.1724)  loss_giou_0: 1.0789 (1.0900)  loss_ce_1: 0.6999 (0.6899)  loss_bbox_1: 1.1830 (1.1641)  loss_giou_1: 1.0889 (1.0678)  loss_ce_2: 0.6526 (0.6578)  loss_bbox_2: 1.2359 (1.2234)  loss_giou_2: 1.0908 (1.1310)  loss_ce_3: 0.6663 (0.6632)  loss_bbox_3: 1.1572 (1.2008)  loss_giou_3: 1.0830 (1.0972)  loss_ce_4: 0.6690 (0.6688)  loss_bbox_4: 1.2066 (1.2029)  loss_giou_4: 1.0812 (1.0763)  loss_ce_unscaled: 0.6789 (0.6756)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2383 (0.2477)  loss_giou_unscaled: 0.5321 (0.5556)  cardinality_error_unscaled: 2.1875 (2.1761)  loss_ce_0_unscaled: 0.6894 (0.6861)  loss_bbox_0_unscaled: 0.2397 (0.2345)  loss_giou_0_unscaled: 0.5395 (0.5450)  cardinality_error_0_unscaled: 2.1875 (2.1761)  loss_ce_1_unscaled: 0.6999 (0.6899)  loss_bbox_1_unscaled: 0.2366 (0.2328)  loss_giou_1_unscaled: 0.5445 (0.5339)  cardinality_error_1_unscaled: 2.1875 (2.1761)  loss_ce_2_unscaled: 0.6526 (0.6578)  loss_bbox_2_unscaled: 0.2472 (0.2447)  loss_giou_2_unscaled: 0.5454 (0.5655)  cardinality_error_2_unscaled: 2.1875 (2.1761)  loss_ce_3_unscaled: 0.6663 (0.6632)  loss_bbox_3_unscaled: 0.2314 (0.2402)  loss_giou_3_unscaled: 0.5415 (0.5486)  cardinality_error_3_unscaled: 2.1875 (2.1761)  loss_ce_4_unscaled: 0.6690 (0.6688)  loss_bbox_4_unscaled: 0.2413 (0.2406)  loss_giou_4_unscaled: 0.5406 (0.5382)  cardinality_error_4_unscaled: 2.1875 (2.1761)  time: 0.7050  data: 0.3019  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 20/124]  eta: 0:01:08  lr: 0.000100  class_error: 100.00  loss: 17.4289 (17.4782)  loss_ce: 0.6805 (0.6778)  loss_bbox: 1.1700 (1.1829)  loss_giou: 1.0642 (1.0762)  loss_ce_0: 0.6837 (0.6815)  loss_bbox_0: 1.0653 (1.1408)  loss_giou_0: 1.0709 (1.0600)  loss_ce_1: 0.7000 (0.6962)  loss_bbox_1: 1.1353 (1.1362)  loss_giou_1: 1.0700 (1.0538)  loss_ce_2: 0.6791 (0.6771)  loss_bbox_2: 1.2036 (1.1990)  loss_giou_2: 1.0833 (1.1153)  loss_ce_3: 0.6729 (0.6712)  loss_bbox_3: 1.1276 (1.1629)  loss_giou_3: 1.0830 (1.0808)  loss_ce_4: 0.6690 (0.6694)  loss_bbox_4: 1.1584 (1.1417)  loss_giou_4: 1.0614 (1.0553)  loss_ce_unscaled: 0.6805 (0.6778)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2340 (0.2366)  loss_giou_unscaled: 0.5321 (0.5381)  cardinality_error_unscaled: 2.1875 (2.1726)  loss_ce_0_unscaled: 0.6837 (0.6815)  loss_bbox_0_unscaled: 0.2131 (0.2282)  loss_giou_0_unscaled: 0.5355 (0.5300)  cardinality_error_0_unscaled: 2.1875 (2.1726)  loss_ce_1_unscaled: 0.7000 (0.6962)  loss_bbox_1_unscaled: 0.2271 (0.2272)  loss_giou_1_unscaled: 0.5350 (0.5269)  cardinality_error_1_unscaled: 2.1875 (2.1726)  loss_ce_2_unscaled: 0.6791 (0.6771)  loss_bbox_2_unscaled: 0.2407 (0.2398)  loss_giou_2_unscaled: 0.5417 (0.5577)  cardinality_error_2_unscaled: 2.1875 (2.1726)  loss_ce_3_unscaled: 0.6729 (0.6712)  loss_bbox_3_unscaled: 0.2255 (0.2326)  loss_giou_3_unscaled: 0.5415 (0.5404)  cardinality_error_3_unscaled: 2.1875 (2.1726)  loss_ce_4_unscaled: 0.6690 (0.6694)  loss_bbox_4_unscaled: 0.2317 (0.2283)  loss_giou_4_unscaled: 0.5307 (0.5277)  cardinality_error_4_unscaled: 2.1875 (2.1726)  time: 0.5789  data: 0.1808  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 30/124]  eta: 0:00:55  lr: 0.000100  class_error: 100.00  loss: 17.3728 (17.4358)  loss_ce: 0.6855 (0.6781)  loss_bbox: 1.1236 (1.1629)  loss_giou: 1.0852 (1.0869)  loss_ce_0: 0.6749 (0.6823)  loss_bbox_0: 1.0653 (1.1227)  loss_giou_0: 1.0709 (1.0816)  loss_ce_1: 0.7032 (0.6964)  loss_bbox_1: 1.1188 (1.1319)  loss_giou_1: 1.0749 (1.0837)  loss_ce_2: 0.6934 (0.6814)  loss_bbox_2: 1.1000 (1.1701)  loss_giou_2: 1.1152 (1.1165)  loss_ce_3: 0.6799 (0.6743)  loss_bbox_3: 1.0842 (1.1282)  loss_giou_3: 1.1000 (1.0793)  loss_ce_4: 0.6776 (0.6741)  loss_bbox_4: 1.1010 (1.1206)  loss_giou_4: 1.0533 (1.0646)  loss_ce_unscaled: 0.6855 (0.6781)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2247 (0.2326)  loss_giou_unscaled: 0.5426 (0.5435)  cardinality_error_unscaled: 2.1875 (2.1976)  loss_ce_0_unscaled: 0.6749 (0.6823)  loss_bbox_0_unscaled: 0.2131 (0.2245)  loss_giou_0_unscaled: 0.5355 (0.5408)  cardinality_error_0_unscaled: 2.1875 (2.1976)  loss_ce_1_unscaled: 0.7032 (0.6964)  loss_bbox_1_unscaled: 0.2238 (0.2264)  loss_giou_1_unscaled: 0.5374 (0.5418)  cardinality_error_1_unscaled: 2.1875 (2.1976)  loss_ce_2_unscaled: 0.6934 (0.6814)  loss_bbox_2_unscaled: 0.2200 (0.2340)  loss_giou_2_unscaled: 0.5576 (0.5582)  cardinality_error_2_unscaled: 2.1875 (2.1976)  loss_ce_3_unscaled: 0.6799 (0.6743)  loss_bbox_3_unscaled: 0.2168 (0.2256)  loss_giou_3_unscaled: 0.5500 (0.5397)  cardinality_error_3_unscaled: 2.1875 (2.1976)  loss_ce_4_unscaled: 0.6776 (0.6741)  loss_bbox_4_unscaled: 0.2202 (0.2241)  loss_giou_4_unscaled: 0.5266 (0.5323)  cardinality_error_4_unscaled: 2.1875 (2.1976)  time: 0.5326  data: 0.1424  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 40/124]  eta: 0:00:49  lr: 0.000100  class_error: 100.00  loss: 17.7920 (17.5584)  loss_ce: 0.6799 (0.6788)  loss_bbox: 1.1576 (1.1740)  loss_giou: 1.1459 (1.1125)  loss_ce_0: 0.6779 (0.6818)  loss_bbox_0: 1.0996 (1.1296)  loss_giou_0: 1.1117 (1.1036)  loss_ce_1: 0.6865 (0.6928)  loss_bbox_1: 1.1051 (1.1220)  loss_giou_1: 1.1277 (1.0973)  loss_ce_2: 0.6903 (0.6819)  loss_bbox_2: 1.1000 (1.1517)  loss_giou_2: 1.1388 (1.1259)  loss_ce_3: 0.6833 (0.6783)  loss_bbox_3: 1.0863 (1.1299)  loss_giou_3: 1.1335 (1.1033)  loss_ce_4: 0.6776 (0.6766)  loss_bbox_4: 1.1184 (1.1319)  loss_giou_4: 1.1138 (1.0864)  loss_ce_unscaled: 0.6799 (0.6788)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2315 (0.2348)  loss_giou_unscaled: 0.5730 (0.5563)  cardinality_error_unscaled: 2.2500 (2.2165)  loss_ce_0_unscaled: 0.6779 (0.6818)  loss_bbox_0_unscaled: 0.2199 (0.2259)  loss_giou_0_unscaled: 0.5559 (0.5518)  cardinality_error_0_unscaled: 2.2500 (2.2165)  loss_ce_1_unscaled: 0.6865 (0.6928)  loss_bbox_1_unscaled: 0.2210 (0.2244)  loss_giou_1_unscaled: 0.5638 (0.5487)  cardinality_error_1_unscaled: 2.2500 (2.2149)  loss_ce_2_unscaled: 0.6903 (0.6819)  loss_bbox_2_unscaled: 0.2200 (0.2303)  loss_giou_2_unscaled: 0.5694 (0.5630)  cardinality_error_2_unscaled: 2.2500 (2.2165)  loss_ce_3_unscaled: 0.6833 (0.6783)  loss_bbox_3_unscaled: 0.2173 (0.2260)  loss_giou_3_unscaled: 0.5667 (0.5516)  cardinality_error_3_unscaled: 2.2500 (2.2134)  loss_ce_4_unscaled: 0.6776 (0.6766)  loss_bbox_4_unscaled: 0.2237 (0.2264)  loss_giou_4_unscaled: 0.5569 (0.5432)  cardinality_error_4_unscaled: 2.2500 (2.2165)  time: 0.5103  data: 0.1338  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 50/124]  eta: 0:00:41  lr: 0.000100  class_error: 100.00  loss: 17.9379 (17.5427)  loss_ce: 0.6659 (0.6748)  loss_bbox: 1.1576 (1.1627)  loss_giou: 1.1902 (1.1150)  loss_ce_0: 0.6716 (0.6799)  loss_bbox_0: 1.0561 (1.1166)  loss_giou_0: 1.1163 (1.1063)  loss_ce_1: 0.6728 (0.6886)  loss_bbox_1: 1.0630 (1.1099)  loss_giou_1: 1.1004 (1.0939)  loss_ce_2: 0.6697 (0.6796)  loss_bbox_2: 1.1044 (1.1445)  loss_giou_2: 1.1511 (1.1322)  loss_ce_3: 0.6678 (0.6770)  loss_bbox_3: 1.1718 (1.1366)  loss_giou_3: 1.1640 (1.1175)  loss_ce_4: 0.6737 (0.6748)  loss_bbox_4: 1.1327 (1.1315)  loss_giou_4: 1.1708 (1.1015)  loss_ce_unscaled: 0.6659 (0.6748)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2315 (0.2325)  loss_giou_unscaled: 0.5951 (0.5575)  cardinality_error_unscaled: 2.2500 (2.2218)  loss_ce_0_unscaled: 0.6716 (0.6799)  loss_bbox_0_unscaled: 0.2112 (0.2233)  loss_giou_0_unscaled: 0.5581 (0.5531)  cardinality_error_0_unscaled: 2.2500 (2.2218)  loss_ce_1_unscaled: 0.6728 (0.6886)  loss_bbox_1_unscaled: 0.2126 (0.2220)  loss_giou_1_unscaled: 0.5502 (0.5469)  cardinality_error_1_unscaled: 2.2500 (2.2206)  loss_ce_2_unscaled: 0.6697 (0.6796)  loss_bbox_2_unscaled: 0.2209 (0.2289)  loss_giou_2_unscaled: 0.5755 (0.5661)  cardinality_error_2_unscaled: 2.2500 (2.2218)  loss_ce_3_unscaled: 0.6678 (0.6770)  loss_bbox_3_unscaled: 0.2344 (0.2273)  loss_giou_3_unscaled: 0.5820 (0.5587)  cardinality_error_3_unscaled: 2.2500 (2.2194)  loss_ce_4_unscaled: 0.6737 (0.6748)  loss_bbox_4_unscaled: 0.2265 (0.2263)  loss_giou_4_unscaled: 0.5854 (0.5507)  cardinality_error_4_unscaled: 2.2500 (2.2218)  time: 0.5259  data: 0.1431  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 60/124]  eta: 0:00:35  lr: 0.000100  class_error: 100.00  loss: 17.6451 (17.5752)  loss_ce: 0.6534 (0.6726)  loss_bbox: 1.1162 (1.1748)  loss_giou: 1.0765 (1.1143)  loss_ce_0: 0.6716 (0.6793)  loss_bbox_0: 1.0587 (1.1243)  loss_giou_0: 1.1059 (1.1091)  loss_ce_1: 0.6836 (0.6889)  loss_bbox_1: 1.0845 (1.1202)  loss_giou_1: 1.0989 (1.0994)  loss_ce_2: 0.6729 (0.6792)  loss_bbox_2: 1.0942 (1.1429)  loss_giou_2: 1.1281 (1.1268)  loss_ce_3: 0.6677 (0.6764)  loss_bbox_3: 1.1662 (1.1427)  loss_giou_3: 1.1030 (1.1188)  loss_ce_4: 0.6611 (0.6736)  loss_bbox_4: 1.1114 (1.1337)  loss_giou_4: 1.0739 (1.0983)  loss_ce_unscaled: 0.6534 (0.6726)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2232 (0.2350)  loss_giou_unscaled: 0.5382 (0.5572)  cardinality_error_unscaled: 2.1875 (2.2244)  loss_ce_0_unscaled: 0.6716 (0.6793)  loss_bbox_0_unscaled: 0.2117 (0.2249)  loss_giou_0_unscaled: 0.5530 (0.5545)  cardinality_error_0_unscaled: 2.1875 (2.2244)  loss_ce_1_unscaled: 0.6836 (0.6889)  loss_bbox_1_unscaled: 0.2169 (0.2240)  loss_giou_1_unscaled: 0.5494 (0.5497)  cardinality_error_1_unscaled: 2.1875 (2.2234)  loss_ce_2_unscaled: 0.6729 (0.6792)  loss_bbox_2_unscaled: 0.2188 (0.2286)  loss_giou_2_unscaled: 0.5641 (0.5634)  cardinality_error_2_unscaled: 2.1875 (2.2244)  loss_ce_3_unscaled: 0.6677 (0.6764)  loss_bbox_3_unscaled: 0.2332 (0.2285)  loss_giou_3_unscaled: 0.5515 (0.5594)  cardinality_error_3_unscaled: 2.1875 (2.2223)  loss_ce_4_unscaled: 0.6611 (0.6736)  loss_bbox_4_unscaled: 0.2223 (0.2267)  loss_giou_4_unscaled: 0.5370 (0.5492)  cardinality_error_4_unscaled: 2.1875 (2.2244)  time: 0.5021  data: 0.1110  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 70/124]  eta: 0:00:29  lr: 0.000100  class_error: 100.00  loss: 17.4596 (17.5520)  loss_ce: 0.6621 (0.6740)  loss_bbox: 1.1166 (1.1665)  loss_giou: 1.1311 (1.1208)  loss_ce_0: 0.6819 (0.6802)  loss_bbox_0: 1.0974 (1.1155)  loss_giou_0: 1.1252 (1.1102)  loss_ce_1: 0.6932 (0.6911)  loss_bbox_1: 1.0845 (1.1159)  loss_giou_1: 1.1349 (1.1062)  loss_ce_2: 0.6738 (0.6798)  loss_bbox_2: 1.0891 (1.1332)  loss_giou_2: 1.1281 (1.1289)  loss_ce_3: 0.6718 (0.6770)  loss_bbox_3: 1.1102 (1.1319)  loss_giou_3: 1.1023 (1.1213)  loss_ce_4: 0.6649 (0.6741)  loss_bbox_4: 1.0726 (1.1246)  loss_giou_4: 1.0900 (1.1005)  loss_ce_unscaled: 0.6621 (0.6740)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2233 (0.2333)  loss_giou_unscaled: 0.5655 (0.5604)  cardinality_error_unscaled: 2.2500 (2.2421)  loss_ce_0_unscaled: 0.6819 (0.6802)  loss_bbox_0_unscaled: 0.2195 (0.2231)  loss_giou_0_unscaled: 0.5626 (0.5551)  cardinality_error_0_unscaled: 2.2500 (2.2421)  loss_ce_1_unscaled: 0.6932 (0.6911)  loss_bbox_1_unscaled: 0.2169 (0.2232)  loss_giou_1_unscaled: 0.5674 (0.5531)  cardinality_error_1_unscaled: 2.2500 (2.2412)  loss_ce_2_unscaled: 0.6738 (0.6798)  loss_bbox_2_unscaled: 0.2178 (0.2266)  loss_giou_2_unscaled: 0.5641 (0.5645)  cardinality_error_2_unscaled: 2.2500 (2.2421)  loss_ce_3_unscaled: 0.6718 (0.6770)  loss_bbox_3_unscaled: 0.2220 (0.2264)  loss_giou_3_unscaled: 0.5512 (0.5607)  cardinality_error_3_unscaled: 2.2500 (2.2403)  loss_ce_4_unscaled: 0.6649 (0.6741)  loss_bbox_4_unscaled: 0.2145 (0.2249)  loss_giou_4_unscaled: 0.5450 (0.5503)  cardinality_error_4_unscaled: 2.2500 (2.2421)  time: 0.5032  data: 0.1272  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 80/124]  eta: 0:00:23  lr: 0.000100  class_error: 100.00  loss: 17.1945 (17.4992)  loss_ce: 0.6740 (0.6744)  loss_bbox: 1.1166 (1.1614)  loss_giou: 1.0927 (1.1095)  loss_ce_0: 0.6873 (0.6803)  loss_bbox_0: 1.1068 (1.1187)  loss_giou_0: 1.0655 (1.1056)  loss_ce_1: 0.6808 (0.6911)  loss_bbox_1: 1.0672 (1.1147)  loss_giou_1: 1.0843 (1.0978)  loss_ce_2: 0.6819 (0.6797)  loss_bbox_2: 1.0785 (1.1301)  loss_giou_2: 1.0533 (1.1186)  loss_ce_3: 0.6773 (0.6776)  loss_bbox_3: 1.1058 (1.1340)  loss_giou_3: 1.0776 (1.1139)  loss_ce_4: 0.6758 (0.6752)  loss_bbox_4: 1.0916 (1.1236)  loss_giou_4: 1.0817 (1.0933)  loss_ce_unscaled: 0.6740 (0.6744)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2233 (0.2323)  loss_giou_unscaled: 0.5463 (0.5548)  cardinality_error_unscaled: 2.3125 (2.2500)  loss_ce_0_unscaled: 0.6873 (0.6803)  loss_bbox_0_unscaled: 0.2214 (0.2237)  loss_giou_0_unscaled: 0.5328 (0.5528)  cardinality_error_0_unscaled: 2.3125 (2.2500)  loss_ce_1_unscaled: 0.6808 (0.6911)  loss_bbox_1_unscaled: 0.2134 (0.2229)  loss_giou_1_unscaled: 0.5422 (0.5489)  cardinality_error_1_unscaled: 2.3125 (2.2492)  loss_ce_2_unscaled: 0.6819 (0.6797)  loss_bbox_2_unscaled: 0.2157 (0.2260)  loss_giou_2_unscaled: 0.5266 (0.5593)  cardinality_error_2_unscaled: 2.3125 (2.2500)  loss_ce_3_unscaled: 0.6773 (0.6776)  loss_bbox_3_unscaled: 0.2212 (0.2268)  loss_giou_3_unscaled: 0.5388 (0.5569)  cardinality_error_3_unscaled: 2.3125 (2.2485)  loss_ce_4_unscaled: 0.6758 (0.6752)  loss_bbox_4_unscaled: 0.2183 (0.2247)  loss_giou_4_unscaled: 0.5408 (0.5466)  cardinality_error_4_unscaled: 2.3125 (2.2500)  time: 0.4873  data: 0.1094  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [ 90/124]  eta: 0:00:18  lr: 0.000100  class_error: 100.00  loss: 17.1626 (17.4755)  loss_ce: 0.6751 (0.6745)  loss_bbox: 1.1501 (1.1618)  loss_giou: 0.9969 (1.1086)  loss_ce_0: 0.6751 (0.6806)  loss_bbox_0: 1.1147 (1.1142)  loss_giou_0: 1.0414 (1.1015)  loss_ce_1: 0.6850 (0.6915)  loss_bbox_1: 1.0681 (1.1072)  loss_giou_1: 1.0015 (1.0914)  loss_ce_2: 0.6823 (0.6803)  loss_bbox_2: 1.1227 (1.1281)  loss_giou_2: 1.0439 (1.1156)  loss_ce_3: 0.6815 (0.6783)  loss_bbox_3: 1.1147 (1.1356)  loss_giou_3: 1.0564 (1.1108)  loss_ce_4: 0.6758 (0.6756)  loss_bbox_4: 1.1432 (1.1279)  loss_giou_4: 1.0189 (1.0919)  loss_ce_unscaled: 0.6751 (0.6745)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2300 (0.2324)  loss_giou_unscaled: 0.4984 (0.5543)  cardinality_error_unscaled: 2.3125 (2.2596)  loss_ce_0_unscaled: 0.6751 (0.6806)  loss_bbox_0_unscaled: 0.2229 (0.2228)  loss_giou_0_unscaled: 0.5207 (0.5507)  cardinality_error_0_unscaled: 2.3125 (2.2596)  loss_ce_1_unscaled: 0.6850 (0.6915)  loss_bbox_1_unscaled: 0.2136 (0.2214)  loss_giou_1_unscaled: 0.5007 (0.5457)  cardinality_error_1_unscaled: 2.3125 (2.2582)  loss_ce_2_unscaled: 0.6823 (0.6803)  loss_bbox_2_unscaled: 0.2245 (0.2256)  loss_giou_2_unscaled: 0.5220 (0.5578)  cardinality_error_2_unscaled: 2.3125 (2.2596)  loss_ce_3_unscaled: 0.6815 (0.6783)  loss_bbox_3_unscaled: 0.2229 (0.2271)  loss_giou_3_unscaled: 0.5282 (0.5554)  cardinality_error_3_unscaled: 2.3125 (2.2582)  loss_ce_4_unscaled: 0.6758 (0.6756)  loss_bbox_4_unscaled: 0.2286 (0.2256)  loss_giou_4_unscaled: 0.5095 (0.5459)  cardinality_error_4_unscaled: 2.3125 (2.2596)  time: 0.4997  data: 0.1229  max mem: 25961
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [100/124]  eta: 0:00:12  lr: 0.000100  class_error: 100.00  loss: 16.4261 (17.3926)  loss_ce: 0.6720 (0.6736)  loss_bbox: 1.0655 (1.1496)  loss_giou: 1.0156 (1.0999)  loss_ce_0: 0.6751 (0.6806)  loss_bbox_0: 1.0395 (1.1072)  loss_giou_0: 1.0281 (1.0989)  loss_ce_1: 0.6966 (0.6913)  loss_bbox_1: 1.0209 (1.0990)  loss_giou_1: 1.0153 (1.0893)  loss_ce_2: 0.6913 (0.6803)  loss_bbox_2: 1.0471 (1.1147)  loss_giou_2: 1.0565 (1.1093)  loss_ce_3: 0.6813 (0.6782)  loss_bbox_3: 1.0560 (1.1286)  loss_giou_3: 1.1089 (1.1135)  loss_ce_4: 0.6789 (0.6753)  loss_bbox_4: 1.0557 (1.1174)  loss_giou_4: 1.0134 (1.0857)  loss_ce_unscaled: 0.6720 (0.6736)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2131 (0.2299)  loss_giou_unscaled: 0.5078 (0.5500)  cardinality_error_unscaled: 2.3125 (2.2673)  loss_ce_0_unscaled: 0.6751 (0.6806)  loss_bbox_0_unscaled: 0.2079 (0.2214)  loss_giou_0_unscaled: 0.5141 (0.5494)  cardinality_error_0_unscaled: 2.3125 (2.2673)  loss_ce_1_unscaled: 0.6966 (0.6913)  loss_bbox_1_unscaled: 0.2042 (0.2198)  loss_giou_1_unscaled: 0.5077 (0.5447)  cardinality_error_1_unscaled: 2.3125 (2.2661)  loss_ce_2_unscaled: 0.6913 (0.6803)  loss_bbox_2_unscaled: 0.2094 (0.2229)  loss_giou_2_unscaled: 0.5282 (0.5547)  cardinality_error_2_unscaled: 2.3125 (2.2673)  loss_ce_3_unscaled: 0.6813 (0.6782)  loss_bbox_3_unscaled: 0.2112 (0.2257)  loss_giou_3_unscaled: 0.5545 (0.5567)  cardinality_error_3_unscaled: 2.3125 (2.2661)  loss_ce_4_unscaled: 0.6789 (0.6753)  loss_bbox_4_unscaled: 0.2111 (0.2235)  loss_giou_4_unscaled: 0.5067 (0.5429)  cardinality_error_4_unscaled: 2.3125 (2.2673)  time: 0.5356  data: 0.1096  max mem: 34500
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [110/124]  eta: 0:00:07  lr: 0.000100  class_error: 100.00  loss: 16.4261 (17.3496)  loss_ce: 0.6547 (0.6711)  loss_bbox: 1.0610 (1.1458)  loss_giou: 1.0156 (1.0963)  loss_ce_0: 0.6668 (0.6785)  loss_bbox_0: 1.0520 (1.1087)  loss_giou_0: 1.1102 (1.1010)  loss_ce_1: 0.6725 (0.6884)  loss_bbox_1: 1.0227 (1.0958)  loss_giou_1: 1.0381 (1.0859)  loss_ce_2: 0.6550 (0.6777)  loss_bbox_2: 0.9886 (1.1109)  loss_giou_2: 1.0386 (1.1036)  loss_ce_3: 0.6640 (0.6762)  loss_bbox_3: 1.0337 (1.1244)  loss_giou_3: 1.0795 (1.1075)  loss_ce_4: 0.6647 (0.6741)  loss_bbox_4: 1.0255 (1.1177)  loss_giou_4: 1.0701 (1.0858)  loss_ce_unscaled: 0.6547 (0.6711)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2122 (0.2292)  loss_giou_unscaled: 0.5078 (0.5482)  cardinality_error_unscaled: 2.2500 (2.2613)  loss_ce_0_unscaled: 0.6668 (0.6785)  loss_bbox_0_unscaled: 0.2104 (0.2217)  loss_giou_0_unscaled: 0.5551 (0.5505)  cardinality_error_0_unscaled: 2.2500 (2.2613)  loss_ce_1_unscaled: 0.6725 (0.6884)  loss_bbox_1_unscaled: 0.2045 (0.2192)  loss_giou_1_unscaled: 0.5190 (0.5429)  cardinality_error_1_unscaled: 2.2500 (2.2601)  loss_ce_2_unscaled: 0.6550 (0.6777)  loss_bbox_2_unscaled: 0.1977 (0.2222)  loss_giou_2_unscaled: 0.5193 (0.5518)  cardinality_error_2_unscaled: 2.2500 (2.2613)  loss_ce_3_unscaled: 0.6640 (0.6762)  loss_bbox_3_unscaled: 0.2067 (0.2249)  loss_giou_3_unscaled: 0.5398 (0.5538)  cardinality_error_3_unscaled: 2.2500 (2.2601)  loss_ce_4_unscaled: 0.6647 (0.6741)  loss_bbox_4_unscaled: 0.2051 (0.2235)  loss_giou_4_unscaled: 0.5350 (0.5429)  cardinality_error_4_unscaled: 2.2500 (2.2613)  time: 0.5184  data: 0.0939  max mem: 34500
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [120/124]  eta: 0:00:02  lr: 0.000100  class_error: 100.00  loss: 16.5446 (17.3092)  loss_ce: 0.6389 (0.6708)  loss_bbox: 1.0540 (1.1377)  loss_giou: 1.0609 (1.0959)  loss_ce_0: 0.6575 (0.6787)  loss_bbox_0: 1.0513 (1.1002)  loss_giou_0: 1.1102 (1.0999)  loss_ce_1: 0.6543 (0.6879)  loss_bbox_1: 1.0227 (1.0875)  loss_giou_1: 1.0381 (1.0858)  loss_ce_2: 0.6486 (0.6779)  loss_bbox_2: 1.0334 (1.1033)  loss_giou_2: 1.0890 (1.1048)  loss_ce_3: 0.6491 (0.6761)  loss_bbox_3: 1.0450 (1.1165)  loss_giou_3: 1.0795 (1.1075)  loss_ce_4: 0.6533 (0.6739)  loss_bbox_4: 1.0791 (1.1148)  loss_giou_4: 1.1417 (1.0902)  loss_ce_unscaled: 0.6389 (0.6708)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2108 (0.2275)  loss_giou_unscaled: 0.5304 (0.5479)  cardinality_error_unscaled: 2.1875 (2.2634)  loss_ce_0_unscaled: 0.6575 (0.6787)  loss_bbox_0_unscaled: 0.2103 (0.2200)  loss_giou_0_unscaled: 0.5551 (0.5499)  cardinality_error_0_unscaled: 2.1875 (2.2634)  loss_ce_1_unscaled: 0.6543 (0.6879)  loss_bbox_1_unscaled: 0.2045 (0.2175)  loss_giou_1_unscaled: 0.5190 (0.5429)  cardinality_error_1_unscaled: 2.1875 (2.2624)  loss_ce_2_unscaled: 0.6486 (0.6779)  loss_bbox_2_unscaled: 0.2067 (0.2207)  loss_giou_2_unscaled: 0.5445 (0.5524)  cardinality_error_2_unscaled: 2.1875 (2.2634)  loss_ce_3_unscaled: 0.6491 (0.6761)  loss_bbox_3_unscaled: 0.2090 (0.2233)  loss_giou_3_unscaled: 0.5398 (0.5538)  cardinality_error_3_unscaled: 2.1875 (2.2624)  loss_ce_4_unscaled: 0.6533 (0.6739)  loss_bbox_4_unscaled: 0.2158 (0.2230)  loss_giou_4_unscaled: 0.5708 (0.5451)  cardinality_error_4_unscaled: 2.1875 (2.2634)  time: 0.5089  data: 0.1442  max mem: 34500
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Logits type: torch.float16
Boxes type: torch.float16
Epoch: [2]  [123/124]  eta: 0:00:00  lr: 0.000100  class_error: 100.00  loss: 16.4871 (17.2759)  loss_ce: 0.6391 (0.6707)  loss_bbox: 1.0274 (1.1326)  loss_giou: 1.0524 (1.0936)  loss_ce_0: 0.6578 (0.6787)  loss_bbox_0: 1.0350 (1.0975)  loss_giou_0: 1.0971 (1.1000)  loss_ce_1: 0.6625 (0.6879)  loss_bbox_1: 1.0135 (1.0835)  loss_giou_1: 1.0222 (1.0849)  loss_ce_2: 0.6506 (0.6781)  loss_bbox_2: 1.0313 (1.0998)  loss_giou_2: 1.0660 (1.1032)  loss_ce_3: 0.6520 (0.6762)  loss_bbox_3: 0.9875 (1.1113)  loss_giou_3: 1.0451 (1.1056)  loss_ce_4: 0.6533 (0.6737)  loss_bbox_4: 1.0187 (1.1098)  loss_giou_4: 1.0938 (1.0887)  loss_ce_unscaled: 0.6391 (0.6707)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2055 (0.2265)  loss_giou_unscaled: 0.5262 (0.5468)  cardinality_error_unscaled: 2.1875 (2.2656)  loss_ce_0_unscaled: 0.6578 (0.6787)  loss_bbox_0_unscaled: 0.2070 (0.2195)  loss_giou_0_unscaled: 0.5485 (0.5500)  cardinality_error_0_unscaled: 2.1875 (2.2656)  loss_ce_1_unscaled: 0.6625 (0.6879)  loss_bbox_1_unscaled: 0.2027 (0.2167)  loss_giou_1_unscaled: 0.5111 (0.5425)  cardinality_error_1_unscaled: 2.1875 (2.2646)  loss_ce_2_unscaled: 0.6506 (0.6781)  loss_bbox_2_unscaled: 0.2063 (0.2200)  loss_giou_2_unscaled: 0.5330 (0.5516)  cardinality_error_2_unscaled: 2.1875 (2.2656)  loss_ce_3_unscaled: 0.6520 (0.6762)  loss_bbox_3_unscaled: 0.1975 (0.2223)  loss_giou_3_unscaled: 0.5226 (0.5528)  cardinality_error_3_unscaled: 2.1875 (2.2646)  loss_ce_4_unscaled: 0.6533 (0.6737)  loss_bbox_4_unscaled: 0.2037 (0.2220)  loss_giou_4_unscaled: 0.5469 (0.5443)  cardinality_error_4_unscaled: 2.1875 (2.2656)  time: 0.5320  data: 0.1444  max mem: 34500
Epoch: [2] Total time: 0:01:06 (0.5379 s / it)
Averaged stats: lr: 0.000100  class_error: 100.00  loss: 16.4871 (17.2759)  loss_ce: 0.6391 (0.6707)  loss_bbox: 1.0274 (1.1326)  loss_giou: 1.0524 (1.0936)  loss_ce_0: 0.6578 (0.6787)  loss_bbox_0: 1.0350 (1.0975)  loss_giou_0: 1.0971 (1.1000)  loss_ce_1: 0.6625 (0.6879)  loss_bbox_1: 1.0135 (1.0835)  loss_giou_1: 1.0222 (1.0849)  loss_ce_2: 0.6506 (0.6781)  loss_bbox_2: 1.0313 (1.0998)  loss_giou_2: 1.0660 (1.1032)  loss_ce_3: 0.6520 (0.6762)  loss_bbox_3: 0.9875 (1.1113)  loss_giou_3: 1.0451 (1.1056)  loss_ce_4: 0.6533 (0.6737)  loss_bbox_4: 1.0187 (1.1098)  loss_giou_4: 1.0938 (1.0887)  loss_ce_unscaled: 0.6391 (0.6707)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2055 (0.2265)  loss_giou_unscaled: 0.5262 (0.5468)  cardinality_error_unscaled: 2.1875 (2.2656)  loss_ce_0_unscaled: 0.6578 (0.6787)  loss_bbox_0_unscaled: 0.2070 (0.2195)  loss_giou_0_unscaled: 0.5485 (0.5500)  cardinality_error_0_unscaled: 2.1875 (2.2656)  loss_ce_1_unscaled: 0.6625 (0.6879)  loss_bbox_1_unscaled: 0.2027 (0.2167)  loss_giou_1_unscaled: 0.5111 (0.5425)  cardinality_error_1_unscaled: 2.1875 (2.2646)  loss_ce_2_unscaled: 0.6506 (0.6781)  loss_bbox_2_unscaled: 0.2063 (0.2200)  loss_giou_2_unscaled: 0.5330 (0.5516)  cardinality_error_2_unscaled: 2.1875 (2.2656)  loss_ce_3_unscaled: 0.6520 (0.6762)  loss_bbox_3_unscaled: 0.1975 (0.2223)  loss_giou_3_unscaled: 0.5226 (0.5528)  cardinality_error_3_unscaled: 2.1875 (2.2646)  loss_ce_4_unscaled: 0.6533 (0.6737)  loss_bbox_4_unscaled: 0.2037 (0.2220)  loss_giou_4_unscaled: 0.5469 (0.5443)  cardinality_error_4_unscaled: 2.1875 (2.2656)

End of training epoch
Total execution time = 66.749 sec
Max memory used by tensors = 36175644160 bytes
Max memory cached = 40510685184 bytes
Total memory reserved = 39093010432 bytes
Total memory allocated = 896654848 bytes
Test:  [ 0/14]  eta: 0:00:31  class_error: 100.00  loss: 36.4500 (36.4500)  loss_ce: 0.6274 (0.6274)  loss_bbox: 2.6728 (2.6728)  loss_giou: 2.4432 (2.4432)  loss_ce_0: 0.6438 (0.6438)  loss_bbox_0: 2.5053 (2.5053)  loss_giou_0: 2.3775 (2.3775)  loss_ce_1: 0.6309 (0.6309)  loss_bbox_1: 2.7857 (2.7857)  loss_giou_1: 2.5323 (2.5323)  loss_ce_2: 0.6305 (0.6305)  loss_bbox_2: 3.3804 (3.3804)  loss_giou_2: 2.7647 (2.7647)  loss_ce_3: 0.6275 (0.6275)  loss_bbox_3: 2.9671 (2.9671)  loss_giou_3: 2.7384 (2.7384)  loss_ce_4: 0.6289 (0.6289)  loss_bbox_4: 2.8697 (2.8697)  loss_giou_4: 2.6237 (2.6237)  loss_ce_unscaled: 0.6274 (0.6274)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5346 (0.5346)  loss_giou_unscaled: 1.2216 (1.2216)  cardinality_error_unscaled: 2.1875 (2.1875)  loss_ce_0_unscaled: 0.6438 (0.6438)  loss_bbox_0_unscaled: 0.5011 (0.5011)  loss_giou_0_unscaled: 1.1888 (1.1888)  cardinality_error_0_unscaled: 2.1875 (2.1875)  loss_ce_1_unscaled: 0.6309 (0.6309)  loss_bbox_1_unscaled: 0.5571 (0.5571)  loss_giou_1_unscaled: 1.2661 (1.2661)  cardinality_error_1_unscaled: 2.1875 (2.1875)  loss_ce_2_unscaled: 0.6305 (0.6305)  loss_bbox_2_unscaled: 0.6761 (0.6761)  loss_giou_2_unscaled: 1.3824 (1.3824)  cardinality_error_2_unscaled: 2.1875 (2.1875)  loss_ce_3_unscaled: 0.6275 (0.6275)  loss_bbox_3_unscaled: 0.5934 (0.5934)  loss_giou_3_unscaled: 1.3692 (1.3692)  cardinality_error_3_unscaled: 2.1875 (2.1875)  loss_ce_4_unscaled: 0.6289 (0.6289)  loss_bbox_4_unscaled: 0.5739 (0.5739)  loss_giou_4_unscaled: 1.3118 (1.3118)  cardinality_error_4_unscaled: 2.1875 (2.1875)  time: 2.2705  data: 1.9906  max mem: 34500
Test:  [10/14]  eta: 0:00:02  class_error: 100.00  loss: 33.6592 (33.4881)  loss_ce: 0.6483 (0.6494)  loss_bbox: 2.5380 (2.5759)  loss_giou: 2.0299 (2.1499)  loss_ce_0: 0.6610 (0.6672)  loss_bbox_0: 2.4860 (2.4412)  loss_giou_0: 2.1021 (2.1239)  loss_ce_1: 0.6592 (0.6572)  loss_bbox_1: 2.5805 (2.6165)  loss_giou_1: 2.1786 (2.2389)  loss_ce_2: 0.6424 (0.6495)  loss_bbox_2: 3.1494 (3.0911)  loss_giou_2: 2.3443 (2.3578)  loss_ce_3: 0.6489 (0.6503)  loss_bbox_3: 2.6984 (2.7672)  loss_giou_3: 2.1734 (2.3114)  loss_ce_4: 0.6415 (0.6486)  loss_bbox_4: 2.6359 (2.6511)  loss_giou_4: 2.1705 (2.2411)  loss_ce_unscaled: 0.6483 (0.6494)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5076 (0.5152)  loss_giou_unscaled: 1.0149 (1.0749)  cardinality_error_unscaled: 2.2500 (2.2955)  loss_ce_0_unscaled: 0.6610 (0.6672)  loss_bbox_0_unscaled: 0.4972 (0.4882)  loss_giou_0_unscaled: 1.0510 (1.0620)  cardinality_error_0_unscaled: 2.2500 (2.2955)  loss_ce_1_unscaled: 0.6592 (0.6572)  loss_bbox_1_unscaled: 0.5161 (0.5233)  loss_giou_1_unscaled: 1.0893 (1.1194)  cardinality_error_1_unscaled: 2.2500 (2.2955)  loss_ce_2_unscaled: 0.6424 (0.6495)  loss_bbox_2_unscaled: 0.6299 (0.6182)  loss_giou_2_unscaled: 1.1721 (1.1789)  cardinality_error_2_unscaled: 2.2500 (2.2955)  loss_ce_3_unscaled: 0.6489 (0.6503)  loss_bbox_3_unscaled: 0.5397 (0.5534)  loss_giou_3_unscaled: 1.0867 (1.1557)  cardinality_error_3_unscaled: 2.2500 (2.2955)  loss_ce_4_unscaled: 0.6415 (0.6486)  loss_bbox_4_unscaled: 0.5272 (0.5302)  loss_giou_4_unscaled: 1.0853 (1.1205)  cardinality_error_4_unscaled: 2.2500 (2.2955)  time: 0.6441  data: 0.3753  max mem: 34500
Test:  [13/14]  eta: 0:00:00  class_error: 100.00  loss: 33.6141 (33.4974)  loss_ce: 0.6659 (0.6614)  loss_bbox: 2.5380 (2.5989)  loss_giou: 2.0291 (2.0987)  loss_ce_0: 0.6819 (0.6787)  loss_bbox_0: 2.4860 (2.4962)  loss_giou_0: 2.1021 (2.0852)  loss_ce_1: 0.6758 (0.6702)  loss_bbox_1: 2.5624 (2.6329)  loss_giou_1: 2.1157 (2.1772)  loss_ce_2: 0.6625 (0.6588)  loss_bbox_2: 3.1494 (3.1365)  loss_giou_2: 2.2630 (2.3154)  loss_ce_3: 0.6681 (0.6616)  loss_bbox_3: 2.7505 (2.8104)  loss_giou_3: 2.1532 (2.2569)  loss_ce_4: 0.6618 (0.6584)  loss_bbox_4: 2.6632 (2.7031)  loss_giou_4: 2.1201 (2.1970)  loss_ce_unscaled: 0.6659 (0.6614)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5076 (0.5198)  loss_giou_unscaled: 1.0146 (1.0493)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.6819 (0.6787)  loss_bbox_0_unscaled: 0.4972 (0.4992)  loss_giou_0_unscaled: 1.0510 (1.0426)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.6758 (0.6702)  loss_bbox_1_unscaled: 0.5125 (0.5266)  loss_giou_1_unscaled: 1.0578 (1.0886)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.6625 (0.6588)  loss_bbox_2_unscaled: 0.6299 (0.6273)  loss_giou_2_unscaled: 1.1315 (1.1577)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.6681 (0.6616)  loss_bbox_3_unscaled: 0.5501 (0.5621)  loss_giou_3_unscaled: 1.0766 (1.1285)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.6618 (0.6584)  loss_bbox_4_unscaled: 0.5326 (0.5406)  loss_giou_4_unscaled: 1.0601 (1.0985)  cardinality_error_4_unscaled: 2.3750 (2.3616)  time: 0.5688  data: 0.3169  max mem: 34500
Test: Total time: 0:00:08 (0.5762 s / it)
Averaged stats: class_error: 100.00  loss: 33.6141 (33.4974)  loss_ce: 0.6659 (0.6614)  loss_bbox: 2.5380 (2.5989)  loss_giou: 2.0291 (2.0987)  loss_ce_0: 0.6819 (0.6787)  loss_bbox_0: 2.4860 (2.4962)  loss_giou_0: 2.1021 (2.0852)  loss_ce_1: 0.6758 (0.6702)  loss_bbox_1: 2.5624 (2.6329)  loss_giou_1: 2.1157 (2.1772)  loss_ce_2: 0.6625 (0.6588)  loss_bbox_2: 3.1494 (3.1365)  loss_giou_2: 2.2630 (2.3154)  loss_ce_3: 0.6681 (0.6616)  loss_bbox_3: 2.7505 (2.8104)  loss_giou_3: 2.1532 (2.2569)  loss_ce_4: 0.6618 (0.6584)  loss_bbox_4: 2.6632 (2.7031)  loss_giou_4: 2.1201 (2.1970)  loss_ce_unscaled: 0.6659 (0.6614)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.5076 (0.5198)  loss_giou_unscaled: 1.0146 (1.0493)  cardinality_error_unscaled: 2.3750 (2.3616)  loss_ce_0_unscaled: 0.6819 (0.6787)  loss_bbox_0_unscaled: 0.4972 (0.4992)  loss_giou_0_unscaled: 1.0510 (1.0426)  cardinality_error_0_unscaled: 2.3750 (2.3616)  loss_ce_1_unscaled: 0.6758 (0.6702)  loss_bbox_1_unscaled: 0.5125 (0.5266)  loss_giou_1_unscaled: 1.0578 (1.0886)  cardinality_error_1_unscaled: 2.3750 (2.3616)  loss_ce_2_unscaled: 0.6625 (0.6588)  loss_bbox_2_unscaled: 0.6299 (0.6273)  loss_giou_2_unscaled: 1.1315 (1.1577)  cardinality_error_2_unscaled: 2.3750 (2.3616)  loss_ce_3_unscaled: 0.6681 (0.6616)  loss_bbox_3_unscaled: 0.5501 (0.5621)  loss_giou_3_unscaled: 1.0766 (1.1285)  cardinality_error_3_unscaled: 2.3750 (2.3616)  loss_ce_4_unscaled: 0.6618 (0.6584)  loss_bbox_4_unscaled: 0.5326 (0.5406)  loss_giou_4_unscaled: 1.0601 (1.0985)  cardinality_error_4_unscaled: 2.3750 (2.3616)
Accumulating evaluation results...
DONE (t=0.05s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.019
 Average Precision  (AP) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.010
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=  1 ] = 0.142
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets= 10 ] = 0.175
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=   all | maxDets=100 ] = 0.175
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.00:0.75 | area=medium | maxDets=100 ] = 0.089
 Average Recall     (AR) @[ IoU=0.00:0.75 | area= large | maxDets=100 ] = 0.196
| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=32, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Using mixed precision training
Traceback (most recent call last):
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 276, in <module>
    main(args)
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 227, in main
    train_stats = train_one_epoch(
                  ^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/engine.py", line 78, in train_one_epoch
    outputs = model(samples)
              ^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/detr.py", line 64, in forward
    hs = self.transformer(self.input_proj(src), mask, self.query_embed.weight, pos[-1])[0]
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/transformer.py", line 56, in forward
    memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/transformer.py", line 77, in forward
    output = layer(output, src_mask=mask,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/transformer.py", line 184, in forward
    return self.forward_post(src, src_mask, src_key_padding_mask, pos)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/transformer.py", line 155, in forward_post
    src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/functional.py", line 5444, in multi_head_attention_forward
    attn_output_weights = dropout(attn_output_weights, p=dropout_p)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/functional.py", line 1268, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.20 GiB. GPU 0 has a total capacity of 39.39 GiB of which 642.56 MiB is free. Including non-PyTorch memory, this process has 38.76 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 962.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=64, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Using mixed precision training
Traceback (most recent call last):
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 276, in <module>
    main(args)
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 227, in main
    train_stats = train_one_epoch(
                  ^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/engine.py", line 78, in train_one_epoch
    outputs = model(samples)
              ^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/detr.py", line 60, in forward
    features, pos = self.backbone(samples)
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 101, in forward
    xs = self[0](tensor_list)
         ^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 73, in forward
    xs = self.body(tensor_list.tensors)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py", line 69, in forward
    x = module(x)
        ^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/resnet.py", line 155, in forward
    out = self.bn3(out)
          ^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 55, in forward
    return x * scale + bias
           ~~~~~~~~~~^~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.07 GiB. GPU 0 has a total capacity of 39.39 GiB of which 86.56 MiB is free. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 36.71 GiB is allocated by PyTorch, and 1.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=128, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Using mixed precision training
Traceback (most recent call last):
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 276, in <module>
    main(args)
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 227, in main
    train_stats = train_one_epoch(
                  ^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/engine.py", line 78, in train_one_epoch
    outputs = model(samples)
              ^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/detr.py", line 60, in forward
    features, pos = self.backbone(samples)
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 101, in forward
    xs = self[0](tensor_list)
         ^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 73, in forward
    xs = self.body(tensor_list.tensors)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py", line 69, in forward
    x = module(x)
        ^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/resnet.py", line 158, in forward
    identity = self.downsample(x)
               ^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 55, in forward
    return x * scale + bias
           ~~~~~~~~~~^~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 9.35 GiB. GPU 0 has a total capacity of 39.39 GiB of which 3.63 GiB is free. Including non-PyTorch memory, this process has 35.76 GiB memory in use. Of the allocated memory 27.91 GiB is allocated by PyTorch, and 7.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
| distributed init (rank 0): env://
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
git:
  sha: 017073257028dc0f557aa64b9ce7145045932825, status: clean, branch: amp

Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=256, weight_decay=0.0001, epochs=3, lr_drop=200, clip_max_norm=0.1, frozen_weights=None, backbone='resnet50', dilation=False, position_embedding='sine', enc_layers=6, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, aux_loss=True, set_cost_class=1, set_cost_bbox=5, set_cost_giou=2, mask_loss_coef=1, dice_loss_coef=1, bbox_loss_coef=5, giou_loss_coef=2, eos_coef=0.1, dataset_file='hgp', coco_path=None, coco_panoptic_path=None, remove_difficult=False, output_dir='', device='cuda', seed=42, resume='', start_epoch=0, eval=False, num_workers=2, world_size=1, dist_url='env://', fast_dev_run=None, section=None, use_amp=True, rank=0, gpu=0, distributed=True, dist_backend='nccl')
number of params: 41284121
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Dataset-root specified: /global/u2/m/marcolz/DETR/hgp_detr/HGP
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Using mixed precision training
Traceback (most recent call last):
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 276, in <module>
    main(args)
  File "/global/homes/m/marcolz/DETR/hgp_detr/main.py", line 227, in main
    train_stats = train_one_epoch(
                  ^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/engine.py", line 78, in train_one_epoch
    outputs = model(samples)
              ^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/detr.py", line 60, in forward
    features, pos = self.backbone(samples)
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 101, in forward
    xs = self[0](tensor_list)
         ^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 73, in forward
    xs = self.body(tensor_list.tensors)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torchvision/models/_utils.py", line 69, in forward
    x = module(x)
        ^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/marcolz/.conda/envs/detr_12.2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/u2/m/marcolz/DETR/hgp_detr/models/backbone.py", line 55, in forward
    return x * scale + bias
           ~~~~~~~~~~^~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.69 GiB. GPU 0 has a total capacity of 39.39 GiB of which 6.42 GiB is free. Including non-PyTorch memory, this process has 32.97 GiB memory in use. Of the allocated memory 32.14 GiB is allocated by PyTorch, and 22.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
